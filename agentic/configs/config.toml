[model]
name = "qwen3:14b"
#name = "gpt-oss:20b"
# url = "http://192.168.29.147:11500/v1"
url = "http://localhost:11434/v1"
api_key = "ollama"
timeout = 300.0

[settings]
auto_approve = true
stream = true

[reasoning]
show_thinking = true
thinking_color = "pink"
retry_count = 2

[tools]
default_tools = [

    # MCP tools are loaded automatically from [mcp] section
 
    ]

[paths]
project_root = "."
test_dir = "test"
docs_dir = "docs"

[mlflow]
enabled = false
tracking_uri = "http://localhost:5000"
experiment_name = "BuddyAI"
enable_tracing = true

[mcp]
enabled = true
servers = [
    # Filesystem MCP server
{ 
    name = "filesystem",
    command = ["npx"],
    args = [
        "-y",
        "mcp-filesystem-server",
        "/home/pranav-pc/projects/applied-GenAI-lab"
    ],
    description = "File operations - read, write, list, search files"
},

        # Filesystem MCP server
    { 
        name = "Chrome DevTools", 
        command = ["npx"], 
        args =["chrome-devtools-mcp@latest"],
        description = "Provides coding agents with programmatic access to Chrome DevTools for comprehensive browser control, inspection, and debugging."
    },

#     # Sequential thinking MCP server (acts as planner)
#     { 
#         name = "thinking", 
#         command = ["npx", "@modelcontextprotocol/server-sequential-thinking"], 
#         args = [],
#         description = "Structured problem solving and step-by-step thinking"
#     },
#     # Context7 documentation server
#     { 
#         name = "context7", 
#         command = ["npx", "@upstash/context7-mcp"], 
#         args = [],
#         description = "Library documentation and code examples"
#     }
# ]
