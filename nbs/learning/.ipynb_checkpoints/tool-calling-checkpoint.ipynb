{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf46d7ed-cb2f-42e5-86cf-3b2d6035963e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool call detected:\n",
      "Executing tool: get_current_weather with args: {'location': 'San Francisco, CA'}\n",
      "\n",
      "Final Response from Model:\n",
      "<think>\n",
      "Okay, the user asked about the weather in San Francisco. I called the get_current_weather function with the location set to \"San Francisco, CA\" and didn't specify the unit since it's optional. The response came back as 72°F with sunny conditions. Now I need to present this information clearly.\n",
      "\n",
      "First, I should mention the current temperature in Fahrenheit since that's what the response provided. The user might be planning to go out, so including the condition \"sunny\" is helpful. I should keep the answer straightforward and concise, maybe add a note about typical weather patterns if relevant. Wait, the user didn't ask for anything beyond the current weather, so sticking to the facts is best. Let me make sure to format the temperature correctly and mention the unit. Alright, that should cover it.\n",
      "</think>\n",
      "\n",
      "The current weather in San Francisco, CA is **72°F** with **sunny** conditions. ☀️ Let me know if you'd like more details!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from openai.types.chat import ChatCompletionMessage, ChatCompletionMessageToolCall\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Step 1: Set up the OpenAI client for Ollama\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",  # Ollama's endpoint\n",
    "    api_key=\"qwen3:8b\",  # Dummy key for Ollama\n",
    ")\n",
    "\n",
    "# Step 2: Define a sample tool schema\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g., San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                        \"description\": \"The unit of temperature to use\",\n",
    "                        \"default\": \"fahrenheit\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "# Step 3: Define the tool execution function\n",
    "def get_current_weather(location: str, unit: str = \"fahrenheit\") -> str:\n",
    "    \"\"\"Sample tool function - returns hardcoded weather data as a string.\"\"\"\n",
    "    # In a real app, this would call a weather API\n",
    "    if \"san francisco\" in location.lower():\n",
    "        return f\"Weather in {location}: 72°F, sunny (unit: {unit})\"\n",
    "    else:\n",
    "        return f\"Weather data not available for {location} (unit: {unit})\"\n",
    "\n",
    "# Step 4: Initialize conversation history\n",
    "messages: List[Dict[str, Any]] = [\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather like in San Francisco?\"}\n",
    "]\n",
    "\n",
    "# Step 5: First API call - Send user message and tools to the model\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"qwen3:8b\",  # Replace with your Ollama model (e.g., 'qwen3:8b')\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",\n",
    "        temperature=0,\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error in first API call: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Step 6: Process the response\n",
    "response_message = response.choices[0].message\n",
    "tool_calls = response_message.tool_calls\n",
    "\n",
    "if tool_calls:\n",
    "    print(\"Tool call detected:\")\n",
    "    # Add assistant's message (with tool calls) to history\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"content\": response_message.content,\n",
    "            \"tool_calls\": [\n",
    "                {\n",
    "                    \"id\": tc.id,\n",
    "                    \"type\": tc.type,\n",
    "                    \"function\": {\n",
    "                        \"name\": tc.function.name,\n",
    "                        \"arguments\": tc.function.arguments,\n",
    "                    },\n",
    "                }\n",
    "                for tc in tool_calls\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Step 7: Execute tool calls\n",
    "    for tool_call in tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        try:\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing tool call arguments: {e}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Executing tool: {function_name} with args: {function_args}\")\n",
    "\n",
    "        # Execute the tool\n",
    "        if function_name == \"get_current_weather\":\n",
    "            function_response = get_current_weather(\n",
    "                location=function_args.get(\"location\", \"\"),\n",
    "                unit=function_args.get(\"unit\", \"fahrenheit\"),\n",
    "            )\n",
    "        else:\n",
    "            function_response = f\"Error: Unknown function {function_name}\"\n",
    "\n",
    "        # Append tool response to messages\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"content\": function_response,  # Ensure content is a string\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Step 8: Second API call - Send tool results back to the model\n",
    "    try:\n",
    "        second_response = client.chat.completions.create(\n",
    "            model=\"qwen3:8b\",  # Same model as before\n",
    "            messages=messages,\n",
    "        )\n",
    "        final_message = second_response.choices[0].message.content\n",
    "        print(\"\\nFinal Response from Model:\")\n",
    "        print(final_message)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in second API call: {e}\")\n",
    "else:\n",
    "    print(\"No tool was called.\")\n",
    "    print(\"Direct Response:\", response_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e837a5-4663-48b2-bd75-8c07e9c48b89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
