{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55c3ff87-9def-43db-aae9-c1f0be04ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp configs.manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91354cc5-d16f-43d8-8897-80d16d2c99a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import os\n",
    "import toml\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Optional\n",
    "from dataclasses import dataclass, field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c64092a-e4be-41cf-87bd-d4db44564530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    \"\"\"Model configuration\"\"\"\n",
    "    name: str = \"qwen3:8b\"\n",
    "    url: str = \"http://localhost:11434/v1\"\n",
    "    api_key: str = \"ollama\"\n",
    "    temperature: float = 0.7\n",
    "    max_tokens: Optional[int] = None\n",
    "    timeout: int = 60\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SettingsConfig:\n",
    "    \"\"\"General settings configuration\"\"\"\n",
    "    auto_approve: bool = False\n",
    "    stream: bool = True\n",
    "    debug: bool = False\n",
    "    log_level: str = \"INFO\"\n",
    "    max_history: int = 100\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ToolsConfig:\n",
    "    \"\"\"Tools configuration\"\"\"\n",
    "    default_tools: list = field(default_factory=lambda: [\n",
    "        \"fs_read\", \"fs_write\", \"execute_bash\", \"code_interpreter\"\n",
    "    ])\n",
    "    dangerous_tools: list = field(default_factory=lambda: [\n",
    "        \"execute_bash\", \"fs_write\"\n",
    "    ])\n",
    "    require_approval: list = field(default_factory=lambda: [\n",
    "        \"execute_bash\", \"fs_write\", \"code_interpreter\"\n",
    "    ])\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ReasoningConfig:\n",
    "    \"\"\"Reasoning and thinking configuration\"\"\"\n",
    "    show_thinking: bool = True\n",
    "    thinking_color: str = \"pink\"\n",
    "    save_thinking: bool = False\n",
    "    retry_count: int = 2\n",
    "    max_reasoning_steps: int = 10\n",
    "\n",
    "@dataclass\n",
    "class MCPConfig:\n",
    "    enabled: bool = False\n",
    "    servers: list = field(default_factory=lambda: [\n",
    "    ])\n",
    "    \n",
    "@dataclass\n",
    "class AgenticConfig:\n",
    "    \"\"\"Complete agentic configuration\"\"\"\n",
    "    model: ModelConfig = field(default_factory=ModelConfig)\n",
    "    settings: SettingsConfig = field(default_factory=SettingsConfig)\n",
    "    tools: ToolsConfig = field(default_factory=ToolsConfig)\n",
    "    reasoning: ReasoningConfig = field(default_factory=ReasoningConfig)\n",
    "    mcp: MCPConfig = field(default_factory=MCPConfig)\n",
    "\n",
    "\n",
    "class ConfigManager:\n",
    "    \"\"\"configuration manager\"\"\"\n",
    "    \n",
    "    def __init__(self, config_path: Optional[str] = None):\n",
    "        self.config_path = config_path or self._get_default_config_path()\n",
    "        self.config = self._load_config()\n",
    "    \n",
    "    def _get_default_config_path(self) -> str:\n",
    "        \"\"\"Get default config file path\"\"\"\n",
    "        current_dir = Path(__file__).parent\n",
    "        return str(current_dir / \"config.toml\")\n",
    "    \n",
    "    def _load_config(self) -> AgenticConfig:\n",
    "        \"\"\"Load configuration from file\"\"\"\n",
    "        try:\n",
    "            if os.path.exists(self.config_path):\n",
    "                with open(self.config_path, 'r') as f:\n",
    "                    config_data = toml.load(f)\n",
    "                \n",
    "                return AgenticConfig(\n",
    "                    model=ModelConfig(**config_data.get('model', {})),\n",
    "                    settings=SettingsConfig(**config_data.get('settings', {})),\n",
    "                    tools=ToolsConfig(**config_data.get('tools', {})),\n",
    "                    reasoning=ReasoningConfig(**config_data.get('reasoning', {})),\n",
    "                    mcp=MCPConfig(**config_data.get('mcp', {}))\n",
    "                )\n",
    "            else:\n",
    "                # Create default config file\n",
    "                default_config = AgenticConfig()\n",
    "                self._save_config(default_config)\n",
    "                return default_config\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Failed to load config from {self.config_path}: {e}\")\n",
    "            return AgenticConfig()\n",
    "    \n",
    "    def _save_config(self, config: AgenticConfig):\n",
    "        \"\"\"Save configuration to file\"\"\"\n",
    "        try:\n",
    "            config_data = {\n",
    "                'model': {\n",
    "                    'name': config.model.name,\n",
    "                    'url': config.model.url,\n",
    "                    'api_key': config.model.api_key,\n",
    "                    'temperature': config.model.temperature,\n",
    "                    'max_tokens': config.model.max_tokens,\n",
    "                    'timeout': config.model.timeout\n",
    "                },\n",
    "                'settings': {\n",
    "                    'auto_approve': config.settings.auto_approve,\n",
    "                    'stream': config.settings.stream,\n",
    "                    'debug': config.settings.debug,\n",
    "                    'log_level': config.settings.log_level,\n",
    "                    'max_history': config.settings.max_history\n",
    "                },\n",
    "                'tools': {\n",
    "                    'default_tools': config.tools.default_tools,\n",
    "                    'dangerous_tools': config.tools.dangerous_tools,\n",
    "                    'require_approval': config.tools.require_approval\n",
    "                },\n",
    "                'reasoning': {\n",
    "                    'show_thinking': config.reasoning.show_thinking,\n",
    "                    'thinking_color': config.reasoning.thinking_color,\n",
    "                    'save_thinking': config.reasoning.save_thinking,\n",
    "                    'retry_count': config.reasoning.retry_count,\n",
    "                    'max_reasoning_steps': config.reasoning.max_reasoning_steps\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Ensure directory exists\n",
    "            os.makedirs(os.path.dirname(self.config_path), exist_ok=True)\n",
    "            \n",
    "            with open(self.config_path, 'w') as f:\n",
    "                toml.dump(config_data, f)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Failed to save config to {self.config_path}: {e}\")\n",
    "    \n",
    "    def get_model_config(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get model configuration as dict\"\"\"\n",
    "        return {\n",
    "            'name': self.config.model.name,\n",
    "            'url': self.config.model.url,\n",
    "            'api_key': self.config.model.api_key,\n",
    "            'temperature': self.config.model.temperature,\n",
    "            'max_tokens': self.config.model.max_tokens,\n",
    "            'timeout': self.config.model.timeout\n",
    "        }\n",
    "    \n",
    "    def get_settings_config(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get settings configuration as dict\"\"\"\n",
    "        return {\n",
    "            'auto_approve': self.config.settings.auto_approve,\n",
    "            'stream': self.config.settings.stream,\n",
    "            'debug': self.config.settings.debug,\n",
    "            'log_level': self.config.settings.log_level,\n",
    "            'max_history': self.config.settings.max_history\n",
    "        }\n",
    "    \n",
    "    def get_tools_config(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get tools configuration as dict\"\"\"\n",
    "        return {\n",
    "            'default_tools': self.config.tools.default_tools,\n",
    "            'dangerous_tools': self.config.tools.dangerous_tools,\n",
    "            'require_approval': self.config.tools.require_approval\n",
    "        }\n",
    "    \n",
    "    def get_reasoning_config(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get reasoning configuration as dict\"\"\"\n",
    "        return {\n",
    "            'show_thinking': self.config.reasoning.show_thinking,\n",
    "            'thinking_color': self.config.reasoning.thinking_color,\n",
    "            'save_thinking': self.config.reasoning.save_thinking,\n",
    "            'retry_count': self.config.reasoning.retry_count,\n",
    "            'max_reasoning_steps': self.config.reasoning.max_reasoning_steps\n",
    "        }\n",
    "    \n",
    "    def update_config(self, section: str, updates: Dict[str, Any]):\n",
    "        \"\"\"Update configuration section\"\"\"\n",
    "        if section == 'model':\n",
    "            for key, value in updates.items():\n",
    "                if hasattr(self.config.model, key):\n",
    "                    setattr(self.config.model, key, value)\n",
    "        elif section == 'settings':\n",
    "            for key, value in updates.items():\n",
    "                if hasattr(self.config.settings, key):\n",
    "                    setattr(self.config.settings, key, value)\n",
    "        elif section == 'tools':\n",
    "            for key, value in updates.items():\n",
    "                if hasattr(self.config.tools, key):\n",
    "                    setattr(self.config.tools, key, value)\n",
    "        elif section == 'reasoning':\n",
    "            for key, value in updates.items():\n",
    "                if hasattr(self.config.reasoning, key):\n",
    "                    setattr(self.config.reasoning, key, value)\n",
    "        elif section == 'mcp':\n",
    "            for key, value in updates.items():\n",
    "                if hasattr(self.config.mcp, key):\n",
    "                    setattr(self.config.mcp, key, value)\n",
    "        \n",
    "        # Save updated config\n",
    "        self._save_config(self.config)\n",
    "    \n",
    "    def reset_to_defaults(self):\n",
    "        \"\"\"Reset configuration to defaults\"\"\"\n",
    "        self.config = AgenticConfig()\n",
    "        self._save_config(self.config)\n",
    "\n",
    "\n",
    "# Global config manager instance\n",
    "_config_manager = None\n",
    "\n",
    "\n",
    "def get_config_manager() -> ConfigManager:\n",
    "    \"\"\"Get global config manager instance\"\"\"\n",
    "    global _config_manager\n",
    "    if _config_manager is None:\n",
    "        _config_manager = ConfigManager()\n",
    "    return _config_manager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8812081d-f94a-4dd7-9ab6-24193820cff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MCPConfig(enabled=True, servers=[{'name': 'filesystem', 'command': ['npx', '@modelcontextprotocol/server-filesystem'], 'args': ['/home/pranav-pc/projects/applied-GenAI-lab'], 'description': 'File operations - read, write, list, search files'}, {'name': 'thinking', 'command': ['npx', '@modelcontextprotocol/server-sequential-thinking'], 'args': [], 'description': 'Structured problem solving and step-by-step thinking'}, {'name': 'context7', 'command': ['npx', '@upstash/context7-mcp'], 'args': [], 'description': 'Library documentation and code examples'}, {'name': 'browser', 'command': ['npx', 'puppeteer-mcp-server'], 'args': [], 'description': 'Web browser automation and scraping'}])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from agentic.configs.manager import get_config_manager\n",
    "get_config_manager().config.mcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d7ef81-d1a9-4094-b5e4-1d777a3ca14d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
