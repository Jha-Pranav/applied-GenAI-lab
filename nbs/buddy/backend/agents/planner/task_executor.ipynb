{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad0cc815-f09a-4b1f-b48a-eae8cb65bf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp agent.planner.task_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319ad33a-cfdc-4f6a-9a27-8425b8b57c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import json\n",
    "from typing import Optional, List, Tuple\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from rich.console import Console\n",
    "\n",
    "from agentic.agent.debater import create_debate\n",
    "from agentic.tools.introspect import IntrospectTool\n",
    "from agentic.tools.base import ToolMetadata, ToolCategory\n",
    "\n",
    "from agentic.agent.planner.models import (\n",
    "    Task, ActionStep, ActionResult, IntrospectionResult, \n",
    "    TaskExecutionResult, ExecutionStatus\n",
    ")\n",
    "from agentic.agent.introspector import IntrospectAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f219bf84-4096-46d6-8fea-44326fcc47b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export \n",
    "class TaskExecutor:\n",
    "    \"\"\"Handles task execution with introspection and retries\"\"\"\n",
    "    \n",
    "    def __init__(self, agent, console: Console, max_retries: int = 3):\n",
    "        self.agent = agent\n",
    "        self.console = console\n",
    "        self.max_retries = max_retries\n",
    "        self.introspect_agent = IntrospectAgent(agent, console)\n",
    "    \n",
    "    async def execute_task(self, task: Task) -> TaskExecutionResult:\n",
    "        \"\"\"Execute all actions in a task with full tracking\"\"\"\n",
    "        start_time = datetime.now()\n",
    "        self.console.print(f\"\\nüîÑ Executing Task: {task.name}\")\n",
    "        \n",
    "        if task.needs_debate:\n",
    "            self.console.print(\"üó£Ô∏è Initiating debate for decision making...\")\n",
    "            debate_context = f\"Task: {task.description}\\nOptions to consider: {', '.join(task.potential_options)}\"\n",
    "            debate_result = await create_debate(topic=task.name, context=debate_context)\n",
    "            self.console.print(f\"Debate result: {debate_result}\")\n",
    "        \n",
    "        task_result = TaskExecutionResult(\n",
    "            task_id=task.id,\n",
    "            task_name=task.name,\n",
    "            status=ExecutionStatus.IN_PROGRESS,\n",
    "            execution_time=0.0,\n",
    "            success_criteria_met=False,\n",
    "            artifacts_created=[]\n",
    "        )\n",
    "        \n",
    "        overall_success = True\n",
    "        \n",
    "        for action in task.actions:\n",
    "            self.console.print(f\"\\n  üìå Step {action.step}: {action.purpose}\")\n",
    "            \n",
    "            action_result, introspection_result = self._execute_action_with_retries(task, action)\n",
    "            \n",
    "            task_result.actions_executed.append(action_result)\n",
    "            if introspection_result:\n",
    "                task_result.introspection_results.append(introspection_result)\n",
    "            \n",
    "            # Update artifacts (ensure it's a list)\n",
    "            if not isinstance(task_result.artifacts_created, list):\n",
    "                task_result.artifacts_created = []\n",
    "                \n",
    "            artifacts = action_result.artifacts_created\n",
    "            # Ensure artifacts is always a list\n",
    "            if not isinstance(artifacts, list):\n",
    "                if isinstance(artifacts, str):\n",
    "                    artifacts = [artifacts]\n",
    "                elif artifacts is None or isinstance(artifacts, bool):\n",
    "                    artifacts = []\n",
    "                else:\n",
    "                    artifacts = [str(artifacts)]\n",
    "            \n",
    "            task_result.artifacts_created.extend(artifacts)\n",
    "            \n",
    "            if action_result.status != ExecutionStatus.SUCCESS:\n",
    "                self.console.print(f\"  ‚ùå Step {action.step} failed after {self.max_retries} retries\")\n",
    "                overall_success = False\n",
    "                break\n",
    "            else:\n",
    "                self.console.print(f\"  ‚úÖ Step {action.step} completed successfully\")\n",
    "        \n",
    "        # Finalize task result\n",
    "        end_time = datetime.now()\n",
    "        task_result.execution_time = (end_time - start_time).total_seconds()\n",
    "        task_result.status = ExecutionStatus.SUCCESS if overall_success else ExecutionStatus.FAILED\n",
    "        task_result.success_criteria_met = overall_success\n",
    "        \n",
    "        return task_result\n",
    "    \n",
    "    def _execute_action_with_retries(self, task: Task, action: ActionStep) -> Tuple[ActionResult, Optional[IntrospectionResult]]:\n",
    "        \"\"\"Execute single action with introspection and retries\"\"\"\n",
    "        \n",
    "        action_result = ActionResult(\n",
    "            action_id=f\"{task.id}_step_{action.step}\",\n",
    "            tool_used=\"agent\",\n",
    "            result=\"\",\n",
    "            execution_time=0.0,\n",
    "            status=ExecutionStatus.PENDING,\n",
    "            artifacts_created=[]\n",
    "        )\n",
    "        \n",
    "        introspection_result = None\n",
    "        retry_feedback = \"\"\n",
    "        \n",
    "        for attempt in range(self.max_retries):\n",
    "            self.console.print(f\"    üîÑ Attempt {attempt + 1}/{self.max_retries}\")\n",
    "            \n",
    "            try:\n",
    "                start_time = datetime.now()\n",
    "                \n",
    "                self.console.print(f\"    üöÄ Executing action: {action.purpose}\")\n",
    "                \n",
    "                result = self._execute_single_action(action, retry_feedback, attempt + 1, retry_feedback)\n",
    "                \n",
    "                end_time = datetime.now()\n",
    "                execution_time = (end_time - start_time).total_seconds()\n",
    "                \n",
    "                self.console.print(f\"    üì§ Action result length: {len(str(result))} chars\")\n",
    "                self.console.print(f\"    üì§ Action result preview: {str(result)[:200]}...\")\n",
    "                \n",
    "                action_result.result = result\n",
    "                action_result.execution_time = execution_time\n",
    "                action_result.status = ExecutionStatus.SUCCESS\n",
    "                \n",
    "                new_artifacts = self._detect_new_artifacts()\n",
    "                action_result.artifacts_created = new_artifacts if isinstance(new_artifacts, list) else []\n",
    "                \n",
    "                self.console.print(f\"    üìù ActionStep completed in {execution_time:.2f}s\")\n",
    "                if action_result.artifacts_created:\n",
    "                    if len(action_result.artifacts_created) <= 3:\n",
    "                        self.console.print(f\"    üìÅ New artifacts: {action_result.artifacts_created}\")\n",
    "                    else:\n",
    "                        shown = action_result.artifacts_created[:3]\n",
    "                        remaining = len(action_result.artifacts_created) - 3\n",
    "                        self.console.print(f\"    üìÅ New artifacts: {shown} ... (+{remaining} more)\")\n",
    "                else:\n",
    "                    self.console.print(f\"    üìÅ New artifacts: []\")\n",
    "                \n",
    "                if action.introspect_after:\n",
    "                    self.console.print(f\"    üîç Starting introspection...\")\n",
    "                    introspection_result = self._introspect_action(task, action, result)\n",
    "                    \n",
    "                    if introspection_result.success:\n",
    "                        self.console.print(f\"    ‚úÖ Introspection passed (score: {introspection_result.score})\")\n",
    "                        return action_result, introspection_result\n",
    "                    else:\n",
    "                        self.console.print(f\"    ‚ö†Ô∏è Introspection failed (score: {introspection_result.score})\")\n",
    "                        self.console.print(f\"    üí¨ Failure reason: {introspection_result.feedback}\")\n",
    "                        if attempt < self.max_retries - 1:\n",
    "                            action_result.status = ExecutionStatus.RETRYING\n",
    "                            retry_feedback = introspection_result.feedback\n",
    "                            self.console.print(f\"    üîÑ Retrying with feedback: {retry_feedback}\")\n",
    "                            continue\n",
    "                else:\n",
    "                    self.console.print(f\"    ‚è≠Ô∏è Skipping introspection (not required)\")\n",
    "                    return action_result, None\n",
    "                    \n",
    "            except Exception as e:\n",
    "                self.console.print(f\"    ‚ùå ActionStep execution error: {e}\")\n",
    "                import traceback\n",
    "                self.console.print(f\"    üìã Full traceback: {traceback.format_exc()}\")\n",
    "                action_result.error_message = str(e)\n",
    "                action_result.status = ExecutionStatus.FAILED\n",
    "                \n",
    "                if attempt < self.max_retries - 1:\n",
    "                    action_result.status = ExecutionStatus.RETRYING\n",
    "                    retry_feedback = f\"Previous attempt failed with error: {str(e)}\"\n",
    "                    continue\n",
    "        \n",
    "        action_result.status = ExecutionStatus.FAILED\n",
    "        return action_result, introspection_result\n",
    "    \n",
    "    def _execute_single_action(self, action: ActionStep, retry_feedback: str = \"\", attempt: int = 1, validation_error: str = \"\") -> str:\n",
    "        \"\"\"Execute single action using Agent's tool system\"\"\"\n",
    "        \n",
    "        retry_guidance = \"\"\n",
    "        if attempt > 1:\n",
    "            if attempt == 2:\n",
    "                retry_guidance = f\"\"\"\n",
    "RETRY GUIDANCE (Attempt {attempt}/3):\n",
    "Previous attempt failed. Analyze the error and apply targeted corrections while maintaining the same general approach.\n",
    "\n",
    "FAILURE ANALYSIS:\n",
    "{validation_error if validation_error else retry_feedback}\n",
    "\n",
    "CORRECTIVE ACTIONS REQUIRED:\n",
    "- Address the specific error mentioned above\n",
    "- Maintain the same tool usage pattern but fix parameter issues\n",
    "- Ensure all expected outputs are properly created\n",
    "\"\"\"\n",
    "            elif attempt >= 3:\n",
    "                retry_guidance = f\"\"\"\n",
    "RETRY GUIDANCE (Attempt {attempt}/3 - FINAL ATTEMPT):\n",
    "Multiple failures detected. CRITICAL: Switch to alternative approach immediately.\n",
    "\n",
    "PREVIOUS FAILURES:\n",
    "{validation_error if validation_error else retry_feedback}\n",
    "\n",
    "ALTERNATIVE STRATEGY REQUIRED:\n",
    "- DO NOT repeat the same failing method\n",
    "- Use different tools or approaches if available\n",
    "- Simplify the implementation if complexity is causing issues\n",
    "- Focus on core functionality first, then add features\n",
    "\"\"\"\n",
    "        \n",
    "        enriched_prompt = f\"\"\"\n",
    "SYSTEM CONTEXT:\n",
    "{action.system_prompt}\n",
    "\n",
    "MISSION OBJECTIVE:\n",
    "{action.user_prompt}\n",
    "\n",
    "EXECUTION SPECIFICATION:\n",
    "‚Ä¢ Primary Goal: {action.purpose}\n",
    "‚Ä¢ Required Steps: {' ‚Üí '.join(action.sub_steps)}\n",
    "‚Ä¢ Execution Mode: {action.execution_mode}\n",
    "‚Ä¢ Quality Standard: Production-grade implementation\n",
    "\n",
    "{retry_guidance}\n",
    "\n",
    "{f\"PREVIOUS ATTEMPT FEEDBACK: {retry_feedback}\" if retry_feedback else \"\"}\n",
    "\n",
    "EXECUTION REQUIREMENTS:\n",
    "1. Use appropriate tools (fs_write, execute_bash, etc.) for file operations\n",
    "2. Create all expected outputs with proper content and structure\n",
    "3. Follow best practices for code quality and documentation\n",
    "4. Ensure error handling and validation where applicable\n",
    "5. Provide clear, actionable output for verification\n",
    "\n",
    "TOOL USAGE EXAMPLES:\n",
    "- fs_write: Use with command=\"create\", path=\"file.py\", file_text=\"content\"\n",
    "- execute_bash: Use with command=\"mkdir -p directory\" or similar\n",
    "\n",
    "Execute this action systematically and report detailed results.\n",
    "\"\"\"\n",
    "        \n",
    "        result = self.agent.run(enriched_prompt, stream=False, max_iterations=5)\n",
    "        return result.get(\"content\", \"\")\n",
    "    \n",
    "    def _introspect_action(self, task: Task, action: ActionStep, result: str) -> IntrospectionResult:\n",
    "        \"\"\"Use IntrospectAgent to validate action success\"\"\"\n",
    "        \n",
    "        self.console.print(f\"    üîç Starting introspection for step {action.step}\")\n",
    "        \n",
    "        try:\n",
    "            task_context = {\n",
    "                \"task_id\": task.id,\n",
    "                \"description\": task.description,\n",
    "                \"purpose\": action.purpose\n",
    "            }\n",
    "            \n",
    "            # Run introspection synchronously\n",
    "            introspect_result = self.introspect_agent.evaluate_execution(\n",
    "                task_context=task_context,\n",
    "                execution_result=result,\n",
    "                success_criteria=task.success_criteria,\n",
    "                expected_outputs=task.expected_outputs\n",
    "            )\n",
    "            \n",
    "            self.console.print(f\"    üìä Introspection result: {introspect_result}\")\n",
    "            \n",
    "            if introspect_result and 'overall_score' in introspect_result:\n",
    "                score = introspect_result['overall_score']\n",
    "                success = introspect_result.get('success', False)\n",
    "                feedback = introspect_result.get('feedback_for_retry', 'No feedback provided')\n",
    "                next_action = introspect_result.get('next_action', 'proceed' if success else 'retry')\n",
    "                recommendations = introspect_result.get('recommendations', [])\n",
    "                reasoning = introspect_result.get('reasoning', '')\n",
    "                \n",
    "                self.console.print(f\"    ‚úÖ Evaluation - Score: {score}, Success: {success}\")\n",
    "                self.console.print(f\"    üí≠ Reasoning: {reasoning}\")\n",
    "                \n",
    "                return IntrospectionResult(\n",
    "                    success=success,\n",
    "                    score=score,\n",
    "                    feedback=feedback,\n",
    "                    next_action=next_action,\n",
    "                    recommendations=recommendations\n",
    "                )\n",
    "            else:\n",
    "                self.console.print(f\"    ‚ùå Invalid introspection result format\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.console.print(f\"    ‚ö†Ô∏è Introspection error: {e}\")\n",
    "            import traceback\n",
    "            self.console.print(f\"    üìã Full traceback: {traceback.format_exc()}\")\n",
    "        \n",
    "        return IntrospectionResult(\n",
    "            success=False,\n",
    "            score=0.0,\n",
    "            feedback=\"Introspection failed - see logs for details\",\n",
    "            next_action=\"retry\",\n",
    "            recommendations=[\"Fix introspection system\"]\n",
    "        )\n",
    "    \n",
    "    def _detect_new_artifacts(self) -> List[str]:\n",
    "        \"\"\"Detect newly created files/artifacts\"\"\"\n",
    "        current_files = set()\n",
    "        current_dir = Path(\".\")\n",
    "        \n",
    "        exclude_patterns = {\n",
    "            '.venv', '__pycache__', '.git', 'node_modules', \n",
    "            '.pytest_cache', '.mypy_cache', 'execution_cache'\n",
    "        }\n",
    "        \n",
    "        for file_path in current_dir.glob(\"**/*\"):\n",
    "            if file_path.is_file() and not file_path.name.startswith('.'):\n",
    "                if any(part in exclude_patterns for part in file_path.parts):\n",
    "                    continue\n",
    "                if file_path.suffix in {'.pyc', '.pyo', '.log', '.tmp'}:\n",
    "                    continue\n",
    "                current_files.add(str(file_path))\n",
    "        \n",
    "        return list(current_files)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f33234f-991e-4235-a37f-1c9ec4eb9c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
