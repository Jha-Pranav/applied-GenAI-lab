{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a855603-179f-4778-89a2-81554cdc4f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp frontend.client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1b69779-0a2e-4564-a1b0-bf5ad616de97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from openai import OpenAI\n",
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "from rich.theme import Theme\n",
    "from agentic.backend.tools.manager import ToolManager\n",
    "from agentic.backend.tools.fs_read import FsReadParams\n",
    "from agentic.backend.tools.fs_write import FsWriteParams\n",
    "from agentic.backend.schemas import ToolCall,  ExecuteBashParams, IntrospectParams, TodoParams\n",
    "from agentic.backend.llm_factory import LLMClient\n",
    "from pydantic import ValidationError\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "from agentic.configs.prompts import get_system_prompt\n",
    "from agentic.configs.loader import get_model_config, get_settings_config, get_tools_config, get_reasoning_config\n",
    "# from agentic.backend.tracing import get_tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be75ef93-d99a-4a64-9772-5cc9b2ef05bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "RESET = \"\\033[0m\"\n",
    "SYSTEM_PROMPT = get_system_prompt()\n",
    "\n",
    "\n",
    "# Define a custom theme that removes backgrounds\n",
    "custom_theme = Theme({\n",
    "    \"markdown.code\": \"default\",        # remove background from inline code\n",
    "    \"markdown.code_block\": \"default\",  # remove background from code blocks\n",
    "    \"markdown.h1\": \"bold\",             # keep bold but no background\n",
    "    \"markdown.h2\": \"bold\",\n",
    "    \"markdown.h3\": \"bold\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95dd42c0-d934-4184-be56-df332532f1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are Buddy, an autonomous AI assistant built for comprehensive software development.\n",
      "            You are running under the `buddy chat` CLI command.\n",
      "            \n",
      "            ---\n",
      "            \n",
      "            # Identity & Mission\n",
      "            - **Role:** Autonomous software development assistant\n",
      "            - **Personality:** Precise, structured, and concise (avoid unnecessary verbosity)\n",
      "            - **Goal:** Deliver correct, efficient, and safe solutions, while minimizing user effort\n",
      "            - **Output:** Always use valid Markdown syntax (headers, bullet points, tables, code blocks)\n",
      "            \n",
      "            ---\n",
      "            \n",
      "            # Core Capabilities\n",
      "            \n",
      "            ## Intelligence\n",
      "            - **Adaptive Task Planning** â€“ Decide when to use `task_planner` based on request complexity\n",
      "            - **Advanced File Operations** â€“ 2-mode `fs_read` (discover for file listing/fuzzy search, extract for content with regex/context) with optimized performance\n",
      "            - **Code Execution** â€“ Python interpreter with plotting and result visualization\n",
      "            - **Quality Analysis** â€“ Security, maintainability, and performance scoring for repositories\n",
      "            - **Documentation** â€“ `nbdev`-powered documentation with examples\n",
      "            - **Self-Improvement** â€“ Action scoring (1â€“10), decision validation, multi-perspective analysis\n",
      "            - **Task Monitoring** â€“ Track progress and validate success criteria\n",
      "            \n",
      "            ## Autonomous Features\n",
      "            - **Self-Monitoring** â€“ Critique each action for safety, efficiency, completeness\n",
      "            - **Decision Validation** â€“ Multi-perspective debate for important design choices\n",
      "            - **Quality Assurance** â€“ Security scans, performance checks, best-practice enforcement\n",
      "            \n",
      "            ---\n",
      "            \n",
      "            # Tool Suite\n",
      "            - `task_planner`: Analyze complex requests, create structured execution plans\n",
      "            - `task_monitor`: Track task progress and success criteria\n",
      "            - `fs_read`: Optimized file reading with 2 modes (discover: list files with fuzzy search; extract: read content with regex/context), supports .gitignore exclusions, fast iteration, and chaining\n",
      "            - `fs_write`: Single-file edits (create or edit with replace/insert/append/prepend/delete_lines), Git-diff preview, user confirmation, chaining-ready output\n",
      "            - `execute_bash`: Safe shell execution with suggestions & formatted output\n",
      "            - `code_interpreter`: Python execution, plotting, package installation\n",
      "            - `code_quality`: Security/maintainability/performance analysis\n",
      "            - `doc_generator`: `nbdev` documentation with HTML examples\n",
      "            - `memory_manager`: Token compression & conversation optimization\n",
      "            - `introspect`: Self-critique & improvement suggestions\n",
      "            - `debate_agent`: Multi-perspective decision-making (via `task_planner` tasks)\n",
      "            \n",
      "            ---\n",
      "            \n",
      "            # Decision-Making Framework\n",
      "            \n",
      "            ## Complexity Assessment\n",
      "            - **Simple:** Single operation, clear outcome, â‰¤2 tools â†’ Execute directly (âš ï¸ **do not overthink**)\n",
      "            - **Moderate:** Multi-step, requires coordination (3â€“5 tools) â†’ Call `task_planner` **immediately**\n",
      "            - **Complex:** Multi-component, integration-heavy, architecture/design decisions â†’ Call `task_planner` **immediately**\n",
      "            \n",
      "            ### Examples of Complex Requests\n",
      "            - Keywords: \"build\", \"create\", \"automate\", \"pipeline\", \"system\", \"framework\", \"setup\", \"develop\"\n",
      "            - Multiple technologies, multi-step workflows, or architecture decisions\n",
      "            \n",
      "            ## Routing Logic\n",
      "            1. Assess complexity first.  \n",
      "            2. **If Moderate/Complex:** Call  \n",
      "               `task_planner(request=\"[full user request]\")`  \n",
      "               before using any other tool.  \n",
      "            3. **If Simple + Clear:** Execute directly â€” **do not overthink.**  \n",
      "            4. **If Simple + Unclear:** Ask clarifying questions, then execute.  \n",
      "            5. **Escalate:** Stop and switch to `task_planner` if hidden complexity emerges mid-execution.\n",
      "            \n",
      "            ## File Handling Policy\n",
      "            - **Reading:** Always start searching recursively from the project root directory, not just the current directory.  \n",
      "              - If file is not found, ask the user to provide a file path or filename.  \n",
      "              - Never assume a path â€” verify before reading.\n",
      "            \n",
      "            ## Code Generation Policy\n",
      "            - When generating code or creating a project:\n",
      "              - Inspect project structure first to determine the most appropriate location.\n",
      "              - Save new code files in a logical directory (e.g., `src/`, `app/`, or relevant module path).\n",
      "              - Present a preview (diff or snippet) before writing, asking user for confirmation.\n",
      "            \n",
      "            ## Code Interpreter Policy\n",
      "            - Use `code_interpreter` **only for small, ephemeral computations or quick experiments**.\n",
      "            - After execution, always ask:\n",
      "              > \"Would you like to save this code to a file for future use?\"\n",
      "            \n",
      "            ## Debate Agent Usage\n",
      "            - Never call `debate_agent` directly for complex requests.\n",
      "            - `task_planner` should create a dedicated debate task (T000) that uses `debate_agent`.\n",
      "            - Direct `debate_agent` calls are allowed **only** for small pros/cons comparisons.\n",
      "            \n",
      "            ---\n",
      "            \n",
      "            # Execution Workflow\n",
      "            \n",
      "            ## Task Planner First (Moderate/Complex)\n",
      "            1. Confirm request clarity â€” ask for missing details if needed.\n",
      "            2. Call `task_planner` with the complete user request.\n",
      "            3. Auto-chain tasks using the task_executor.\n",
      "            4. Use `task_monitor` to track and report progress.\n",
      "            5. Summarize plan with âœ… / âŒ markers before execution.\n",
      "            \n",
      "            ## Failure Recovery\n",
      "            - **On Complexity Discovery:**  \n",
      "              > \"This turned out more complex than expected â€” escalating to `task_planner`.\"\n",
      "            - **On Tool Failure:**  \n",
      "                  1. Retry with the same tool  \n",
      "                  2. Fallback to `execute_bash` if no tool is appropriate and the task is shell-friendly  \n",
      "                  3. Offer concise manual CLI alternative  \n",
      "                  4. If repeated failure â†’ run `introspect` to adapt the strategy\n",
      "            \n",
      "            ---\n",
      "            \n",
      "            # Safety & Confirmation\n",
      "            - âœ… Confirm before destructive or irreversible actions (deletion, overwriting, mass refactoring)\n",
      "            - âœ… Read-only operations may run without confirmation\n",
      "            - âœ… Ask clarifying questions when:\n",
      "              - Request is vague, incomplete, or multi-interpretable\n",
      "              - Risk of incorrect execution is high\n",
      "            \n",
      "            ---\n",
      "            \n",
      "            # Output Formatting\n",
      "            - Use Markdown consistently:\n",
      "              - `#`, `##`, `###` for section headers\n",
      "              - âœ… / âŒ for status indicators\n",
      "              - Numbered steps for workflows\n",
      "              - Tables for comparisons\n",
      "              - Code blocks ``` for commands and code snippets\n",
      "            - Keep responses terminal-friendly and compatible with `rich` color rendering.\n",
      "            \n",
      "            ---\n",
      "            \n",
      "            # Critical Rules\n",
      "            1. **Task Planner Precedence:** Always call `task_planner` first for moderate/complex requests.\n",
      "            2. **Stop-on-Complexity:** Escalate to `task_planner` if complexity is discovered mid-execution.\n",
      "            3. **Debate Handling:** Never call `debate_agent` directly for complex cases; use `task_planner` to create debate tasks.\n",
      "            4. **Clarification First:** Never assume â€” ask when in doubt.\n",
      "            5. **Explain Routing:** Justify why you chose direct execution or planning.\n",
      "            6. **Fallback Chain:** tool â†’ bash â†’ manual suggestion (concise).\n",
      "            7. **Self-Check:** After any multi-step execution (>3 steps), run `introspect` before reporting success.\n",
      "            \n",
      "            ---\n",
      "            \n",
      "            <system_context>\n",
      "            - **OS:** Linux x86_64\n",
      "            - **Python:** 3.12.9\n",
      "            - **Directory:** /home/pranav-pc/projects/applied-GenAI-lab/nbs/buddy/frontend\n",
      "            - **Project:** {'git_repo': False, 'python_project': False, 'nbdev_project': False, 'node_project': False, 'docker_project': False}\n",
      "            </system_context>\n",
      "            \n",
      "            ---\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(SYSTEM_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31a3ef55-176d-420a-8caa-700997b5876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class BuddyClient:\n",
    "    def __init__(self, model=None, base_url=None, api_key=None):\n",
    "        # Load config defaults\n",
    "        settings_config = get_settings_config()\n",
    "        \n",
    "        # Initialize LLM client\n",
    "        self.llm_client = LLMClient(model, base_url, api_key)\n",
    "        \n",
    "        # Store config settings\n",
    "        self.auto_approve = settings_config.get('auto_approve', False)\n",
    "        \n",
    "        self.tool_manager = ToolManager()\n",
    "        self.conversation_history = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]  # Session history\n",
    "        \n",
    "        # Initialize console for rich markdown rendering\n",
    "        self.console = Console(theme=custom_theme)\n",
    "        \n",
    "        # Initialize MLflow tracing\n",
    "        # self.tracer = get_tracer()\n",
    "        # self.tracer.start_session()\n",
    "    \n",
    "    def chat(self, message, tools=None, stream=None):\n",
    "        \"\"\"Enhanced chat with OpenAI tool calling and Pydantic validation\"\"\"\n",
    "        if tools is None:\n",
    "            tools_config = get_tools_config()\n",
    "            tools = tools_config.get('default_tools', [\n",
    "                \"fs_read\", \"fs_write\", \"execute_bash\", \"code_interpreter\", \n",
    "                \"code_quality\", \"doc_generator\", \"memory_manager\", \n",
    "                \"introspect\", \"debate_agent\", \"task_planner\", \"task_monitor\", \"task_executor\"\n",
    "            ])\n",
    "        \n",
    "        if stream is None:\n",
    "            settings_config = get_settings_config()\n",
    "            stream = settings_config.get('stream', True)\n",
    "        \n",
    "        # Add user message to history\n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": message})\n",
    "        \n",
    "        # Get retry count from reasoning config\n",
    "        reasoning_config = get_reasoning_config()\n",
    "        max_retries = reasoning_config.get('retry_count', 2)\n",
    "        retry_count = 0\n",
    "        result = None\n",
    "        \n",
    "        while retry_count <= max_retries:\n",
    "            try:\n",
    "                # Get OpenAI-formatted tools\n",
    "                openai_tools = self.tool_manager.get_tools(tools)\n",
    "                \n",
    "                response = self.llm_client.create_completion(\n",
    "                    messages=self.conversation_history,\n",
    "                    tools=openai_tools,\n",
    "                    stream=stream\n",
    "                )\n",
    "                \n",
    "                # Store the response for tracing\n",
    "                self._last_response = response\n",
    "                \n",
    "                if stream:\n",
    "                    result = self.llm_client.handle_streaming_response(response, self.console)\n",
    "                else:\n",
    "                    result = self.llm_client.process_response(response,self.console)\n",
    "                    \n",
    "                # Execute tool calls if any\n",
    "                if result.get(\"tool_calls\"):\n",
    "                    executed_calls = self._execute_tool_calls(result[\"tool_calls\"])\n",
    "                    result[\"tool_calls\"] = executed_calls\n",
    "\n",
    "                \n",
    "                # Add assistant response to history\n",
    "                assistant_message = {\"role\": \"assistant\", \"content\": result.get(\"content\", \"\")}\n",
    "                if result.get(\"tool_calls\"):\n",
    "                    assistant_message[\"tool_calls\"] = result[\"tool_calls\"]\n",
    "                self.conversation_history.append(assistant_message)\n",
    "                \n",
    "                # If no tool calls, conversation is complete\n",
    "                if not result.get(\"tool_calls\"):\n",
    "                    break\n",
    "                \n",
    "                # Add tool results to history\n",
    "                for tool_call in result.get(\"tool_calls\", []):\n",
    "                    if hasattr(tool_call, 'get') and tool_call.get(\"result\"):\n",
    "                        self.conversation_history.append({\n",
    "                            \"role\": \"tool\",\n",
    "                            \"tool_call_id\": tool_call.get(\"id\", \"\"),\n",
    "                            \"content\": str(tool_call[\"result\"])\n",
    "                        })\n",
    "                \n",
    "            except Exception as e:\n",
    "                retry_count += 1\n",
    "                if retry_count <= max_retries:\n",
    "                    print(f\"âš ï¸ Error in conversation (attempt {retry_count}/{max_retries + 1}): {e}\")\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"âš ï¸ Error in conversation (final attempt): {e}\")\n",
    "                    break\n",
    "        \n",
    "        return result or {\"content\": \"Error: Unable to complete request\", \"tool_calls\": []}\n",
    "    \n",
    "    def clear_history(self):\n",
    "        \"\"\"Clear conversation history\"\"\"\n",
    "        self.conversation_history = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
    "        print(\"ğŸ—‘ï¸ Conversation history cleared\")\n",
    "    \n",
    "    def show_history(self):\n",
    "        \"\"\"Show conversation history\"\"\"\n",
    "        print(\"\\nğŸ“œ Conversation History:\")\n",
    "        for i, msg in enumerate(self.conversation_history[1:], 1):  # Skip system message\n",
    "            role = msg[\"role\"].upper()\n",
    "            content = msg.get(\"content\", \"\")[:100] + \"...\" if len(msg.get(\"content\", \"\")) > 100 else msg.get(\"content\", \"\")\n",
    "            print(f\"{i}. {role}: {content}\")\n",
    "        print()\n",
    "\n",
    "    \n",
    "    def _execute_tool_calls(self, tool_calls: List[Dict]):\n",
    "        \"\"\"Execute tool calls with Pydantic validation and user permission\"\"\"\n",
    "        executed_calls = []\n",
    "        \n",
    "        for tool_call in tool_calls:\n",
    "            try:\n",
    "                function_name = tool_call[\"function\"][\"name\"]\n",
    "                arguments_str = tool_call[\"function\"][\"arguments\"]\n",
    "                \n",
    "                # Parse arguments\n",
    "                try:\n",
    "                    arguments = json.loads(arguments_str)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"\\nâš ï¸ Invalid JSON in tool call: {e}\")\n",
    "                    print(\"ğŸ”„ Skipping this tool call...\")\n",
    "                    continue\n",
    "                \n",
    "                # Validate with Pydantic\n",
    "                if not self._validate_tool_call(function_name, arguments):\n",
    "                    print(f\"âš ï¸ Skipping {function_name} due to validation errors\")\n",
    "                    continue\n",
    "                \n",
    "                # Show command and get permission\n",
    "                if not self._get_permission(function_name, arguments):\n",
    "                    print(\"âŒ Command cancelled\")\n",
    "                    continue\n",
    "                \n",
    "                # Execute the tool\n",
    "                result = self.tool_manager.execute_tool(function_name, arguments)\n",
    "                \n",
    "                # Format and display result\n",
    "                formatted_result = self._format_tool_result(function_name, result)\n",
    "                print(f\"âœ… {formatted_result}\")\n",
    "                \n",
    "                # Store result for conversation continuity\n",
    "                tool_call[\"result\"] = result\n",
    "                executed_calls.append(tool_call)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"\\nâš ï¸ Tool execution error: {e}\")\n",
    "                print(\"ğŸ”„ Skipping this tool call...\")\n",
    "                continue\n",
    "        \n",
    "        return executed_calls\n",
    "    \n",
    "    def _get_permission(self, function_name: str, arguments: Dict[str, Any]) -> bool:\n",
    "        \"\"\"Get user permission before executing commands\"\"\"\n",
    "        if self.auto_approve:\n",
    "            # Show beautiful tool display even with auto-approve\n",
    "            self._display_tool_call(function_name, arguments, trusted=True)\n",
    "            return True\n",
    "        \n",
    "        # Show beautiful tool display\n",
    "        self._display_tool_call(function_name, arguments, trusted=False)\n",
    "        \n",
    "        while True:\n",
    "            response = input(\"Execute? (y)es/(n)o/(t)rust always: \").lower().strip()\n",
    "            if response in ['y', 'yes']:\n",
    "                return True\n",
    "            elif response in ['n', 'no']:\n",
    "                return False\n",
    "            elif response in ['t', 'trust']:\n",
    "                self.auto_approve = True\n",
    "                print(\"âœ… Auto-approval enabled for this session\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"Please enter 'y', 'n', or 't'\")\n",
    "    \n",
    "    def _display_tool_call(self, function_name: str, arguments: Dict[str, Any], trusted: bool = False):\n",
    "        \"\"\"Display tool call in Amazon Q style\"\"\"\n",
    "        trust_text = \" (trusted)\" if trusted else \"\"\n",
    "        description = self._get_command_description(function_name, arguments)\n",
    "        command_preview = self._get_command_preview(function_name, arguments)\n",
    "        \n",
    "        print(f\"\\nğŸ› ï¸  Using tool: {function_name}{trust_text}\")\n",
    "        print(\" â‹®\")\n",
    "        print(\" â— I will run the following:\")\n",
    "        print(f\"{command_preview}\")\n",
    "        print(\" â‹®\")\n",
    "        print(f\" â†³ Purpose: {description}\")\n",
    "        if not trusted:\n",
    "            print()  # Extra line before prompt\n",
    "    \n",
    "    def _get_command_description(self, function_name: str, arguments: Dict[str, Any]) -> str:\n",
    "        \"\"\"Generate one-sentence description of what the command does\"\"\"\n",
    "        if function_name == \"fs_read\":\n",
    "            ops = arguments.get(\"operations\", [])\n",
    "            if ops and ops[0].get(\"mode\") == \"discover\":\n",
    "                return \"Lists files in a directory by query and pattern.\"\n",
    "            elif ops and ops[0].get(\"mode\") == \"extract\":\n",
    "                return \"Extracts content from files matching a query.\"\n",
    "        elif function_name == \"fs_write\":\n",
    "            cmd = arguments.get(\"command\")\n",
    "            if cmd == \"create\":\n",
    "                return \"Creates a new file with the specified content\"\n",
    "            elif cmd == \"str_replace\":\n",
    "                return \"Replaces text in an existing file\"\n",
    "            elif cmd == \"append\":\n",
    "                return \"Adds content to the end of an existing file\"\n",
    "        elif function_name == \"execute_bash\":\n",
    "            return f\"Runs the bash command: {arguments.get('command')}\"\n",
    "        elif function_name == \"code_interpreter\":\n",
    "            return f\"Executes Python code: {arguments.get('code', '')[:50]}...\"\n",
    "        elif function_name == \"code_quality\":\n",
    "            return f\"Analyzes code quality for repository: {arguments.get('repo_path')}\"\n",
    "        elif function_name == \"doc_generator\":\n",
    "            return f\"Generates documentation for: {arguments.get('repo_path')}\"\n",
    "        elif function_name == \"memory_manager\":\n",
    "            return f\"Manages conversation memory: {arguments.get('action')}\"\n",
    "        elif function_name == \"introspect\":\n",
    "            return f\"Self-analysis: {arguments.get('action')}\"\n",
    "        elif function_name == \"debate_agent\":\n",
    "            return f\"Multi-perspective analysis of: {arguments.get('decision')}\"\n",
    "        elif function_name == \"todo\":\n",
    "            action = arguments.get(\"action\")\n",
    "            if action == \"plan\":\n",
    "                return \"Breaks down a complex task into smaller steps\"\n",
    "            elif action == \"execute\":\n",
    "                return \"Executes the next step in the task plan\"\n",
    "        \n",
    "        return \"Executes the specified operation\"\n",
    "    \n",
    "    def _get_command_preview(self, function_name: str, arguments: Dict[str, Any]) -> str:\n",
    "        \"\"\"Generate a preview of the actual command\"\"\"\n",
    "        if function_name == \"fs_read\":\n",
    "            ops = arguments.get(\"operations\", [])\n",
    "            if ops:\n",
    "                op = ops[0]\n",
    "                if op.get(\"mode\") == \"Directory\":\n",
    "                    return f\"ls {op.get('path', '.')}\"\n",
    "                elif op.get(\"mode\") == \"Line\":\n",
    "                    return f\"cat {op.get('path')}\"\n",
    "                elif op.get(\"mode\") == \"Search\":\n",
    "                    return f\"grep '{op.get('pattern')}' {op.get('path')}\"\n",
    "        elif function_name == \"fs_write\":\n",
    "            cmd = arguments.get(\"command\")\n",
    "            path = arguments.get(\"path\")\n",
    "            if cmd == \"create\":\n",
    "                return f\"echo 'content' > {path}\"\n",
    "            elif cmd == \"str_replace\":\n",
    "                return f\"sed -i 's/old/new/g' {path}\"\n",
    "            elif cmd == \"append\":\n",
    "                return f\"echo 'content' >> {path}\"\n",
    "        elif function_name == \"execute_bash\":\n",
    "            return arguments.get(\"command\", \"\")\n",
    "        elif function_name == \"code_interpreter\":\n",
    "            return f\"python -c \\\"{arguments.get('code', '')[:30]}...\\\"\"\n",
    "        elif function_name == \"todo\":\n",
    "            return f\"todo {arguments.get('action')} '{arguments.get('task')}'\"\n",
    "        elif function_name == \"introspect\":\n",
    "            return \"buddy --introspect\"\n",
    "        \n",
    "        return f\"{function_name}({', '.join(f'{k}={v}' for k, v in arguments.items())})\"\n",
    "    \n",
    "    def _validate_tool_call(self, function_name: str, arguments: Dict[str, Any]) -> bool:\n",
    "        \"\"\"Validate tool call parameters with Pydantic\"\"\"\n",
    "        try:\n",
    "            if function_name == \"fs_read\":\n",
    "                FsReadParams(**arguments)\n",
    "            elif function_name == \"fs_write\":\n",
    "                FsWriteParams(**arguments)\n",
    "            elif function_name == \"execute_bash\":\n",
    "                ExecuteBashParams(**arguments)\n",
    "            elif function_name == \"introspect\":\n",
    "                IntrospectParams(**arguments)\n",
    "            elif function_name == \"todo\":\n",
    "                TodoParams(**arguments)\n",
    "            else:\n",
    "                # For new tools, skip validation for now\n",
    "                return True\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except ValidationError as e:\n",
    "            error_msg = str(e)\n",
    "            if \"Input should be 'Line', 'Directory' or 'Search'\" in error_msg:\n",
    "                print(f\"\\nâš ï¸ Invalid mode for {function_name}. Use 'Line' to read files, 'Directory' to list directories, 'Search' to find patterns.\")\n",
    "            else:\n",
    "                print(f\"\\nâš ï¸ Validation error for {function_name}: {e}\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"\\nâš ï¸ Unexpected validation error for {function_name}: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def _format_tool_result(self, function_name: str, result: Dict[str, Any]) -> str:\n",
    "        \"\"\"Format tool results for display\"\"\"\n",
    "        if \"error\" in result:\n",
    "            return f\"Error: {result['error']}\"\n",
    "        \n",
    "        if function_name == \"fs_read\":\n",
    "            if \"results\" in result:\n",
    "                formatted = []\n",
    "                for res in result[\"results\"]:\n",
    "                    if \"items\" in res:\n",
    "                        items = res[\"items\"]\n",
    "                        file_count = sum(1 for item in items if item.get('type') == 'file')\n",
    "                        dir_count = sum(1 for item in items if item.get('type') == 'directory')\n",
    "                        formatted.append(f\"Directory {res['path']}: {file_count} files, {dir_count} directories\")\n",
    "                    elif \"content\" in res:\n",
    "                        lines = len(res[\"content\"].split('\\n'))\n",
    "                        formatted.append(f\"File {res['path']}: {lines} lines\")\n",
    "                    elif \"matches\" in res:\n",
    "                        match_count = len(res[\"matches\"])\n",
    "                        formatted.append(f\"Search in {res['path']}: {match_count} matches\")\n",
    "                return \"; \".join(formatted)\n",
    "        \n",
    "        elif function_name == \"execute_bash\":\n",
    "            if \"stdout\" in result:\n",
    "                output = result[\"stdout\"].strip()\n",
    "                return f\"Exit {result.get('exit_status', 0)}: {output[:100]}{'...' if len(output) > 100 else ''}\"\n",
    "        \n",
    "        elif function_name == \"fs_write\":\n",
    "            if \"success\" in result:\n",
    "                return result[\"message\"]\n",
    "        \n",
    "        elif function_name == \"code_interpreter\":\n",
    "            if \"success\" in result:\n",
    "                plots = f\", {result['plot_count']} plots\" if result.get('plot_count', 0) > 0 else \"\"\n",
    "                return f\"Code executed in {result['execution_time']}s{plots}\"\n",
    "        \n",
    "        elif function_name == \"code_quality\":\n",
    "            if \"summary\" in result:\n",
    "                return f\"Quality analysis: {result['summary'].get('quality_score', 0)}/100 ({result['summary'].get('grade', 'N/A')})\"\n",
    "        \n",
    "        elif function_name == \"todo\":\n",
    "            if \"steps\" in result:\n",
    "                return f\"Created plan with {len(result['steps'])} steps\"\n",
    "            elif \"step\" in result:\n",
    "                return f\"Executed step: {result['step']['description']}\"\n",
    "        \n",
    "        return str(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132020bf-180a-449d-a34b-61fda82f6045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #0000ff; text-decoration-color: #0000ff\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ âœ¨ Welcome to Buddy âœ¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #0000ff; text-decoration-color: #0000ff\">â”‚</span>                                                                                                                 <span style=\"color: #0000ff; text-decoration-color: #0000ff\">â”‚</span>\n",
       "<span style=\"color: #0000ff; text-decoration-color: #0000ff\">â”‚</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ğŸ¤– Buddy CLI</span><span style=\"color: #ffffff; text-decoration-color: #ffffff\"> - Advanced Autonomous AI Assistant</span>                                                                <span style=\"color: #0000ff; text-decoration-color: #0000ff\">â”‚</span>\n",
       "<span style=\"color: #0000ff; text-decoration-color: #0000ff\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">ğŸ§  Model: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">gpt-oss:20b</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\"> (http://192.168.29.147:11500/v1)</span>                                                         <span style=\"color: #0000ff; text-decoration-color: #0000ff\">â”‚</span>\n",
       "<span style=\"color: #0000ff; text-decoration-color: #0000ff\">â”‚</span>                                                                                                                 <span style=\"color: #0000ff; text-decoration-color: #0000ff\">â”‚</span>\n",
       "<span style=\"color: #0000ff; text-decoration-color: #0000ff\">â”‚</span>                                                                                                                 <span style=\"color: #0000ff; text-decoration-color: #0000ff\">â”‚</span>\n",
       "<span style=\"color: #0000ff; text-decoration-color: #0000ff\">â”‚</span>                                                                                                                 <span style=\"color: #0000ff; text-decoration-color: #0000ff\">â”‚</span>\n",
       "<span style=\"color: #0000ff; text-decoration-color: #0000ff\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[94mâ•­â”€\u001b[0m\u001b[94mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[94m âœ¨ Welcome to Buddy âœ¨ \u001b[0m\u001b[94mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[94mâ”€â•®\u001b[0m\n",
       "\u001b[94mâ”‚\u001b[0m                                                                                                                 \u001b[94mâ”‚\u001b[0m\n",
       "\u001b[94mâ”‚\u001b[0m  \u001b[1;36mğŸ¤– Buddy CLI\u001b[0m\u001b[97m - Advanced Autonomous AI Assistant\u001b[0m                                                                \u001b[94mâ”‚\u001b[0m\n",
       "\u001b[94mâ”‚\u001b[0m  \u001b[1;37mğŸ§  Model: \u001b[0m\u001b[92mgpt-oss:20b\u001b[0m\u001b[2;37m (http://192.168.29.147:11500/v1)\u001b[0m                                                         \u001b[94mâ”‚\u001b[0m\n",
       "\u001b[94mâ”‚\u001b[0m                                                                                                                 \u001b[94mâ”‚\u001b[0m\n",
       "\u001b[94mâ”‚\u001b[0m                                                                                                                 \u001b[94mâ”‚\u001b[0m\n",
       "\u001b[94mâ”‚\u001b[0m                                                                                                                 \u001b[94mâ”‚\u001b[0m\n",
       "\u001b[94mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> ğŸ› ï¸  Core Tools:   </span><span style=\"color: #008000; text-decoration-color: #008000\"> fs_read, fs_write, execute_bash           </span>\n",
       "<span style=\"font-weight: bold\"> ğŸ§ª Analysis:     </span><span style=\"color: #008000; text-decoration-color: #008000\"> code_interpreter, code_quality, analyzer  </span>\n",
       "<span style=\"font-weight: bold\"> ğŸ§  Intelligence: </span><span style=\"color: #008000; text-decoration-color: #008000\"> introspect, debate_agent, memory_manager  </span>\n",
       "<span style=\"font-weight: bold\"> ğŸ“‹ Planning:     </span><span style=\"color: #008000; text-decoration-color: #008000\"> task_planner, task_executor, task_monitor </span>\n",
       "<span style=\"font-weight: bold\"> ğŸ“š Utilities:    </span><span style=\"color: #008000; text-decoration-color: #008000\"> doc_generator, todo                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m \u001b[0m\u001b[1mğŸ› ï¸  Core Tools:  \u001b[0m\u001b[1m \u001b[0m\u001b[32m \u001b[0m\u001b[32mfs_read, fs_write, execute_bash          \u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[1m \u001b[0m\u001b[1mğŸ§ª Analysis:    \u001b[0m\u001b[1m \u001b[0m\u001b[32m \u001b[0m\u001b[32mcode_interpreter, code_quality, analyzer \u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[1m \u001b[0m\u001b[1mğŸ§  Intelligence:\u001b[0m\u001b[1m \u001b[0m\u001b[32m \u001b[0m\u001b[32mintrospect, debate_agent, memory_manager \u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[1m \u001b[0m\u001b[1mğŸ“‹ Planning:    \u001b[0m\u001b[1m \u001b[0m\u001b[32m \u001b[0m\u001b[32mtask_planner, task_executor, task_monitor\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[1m \u001b[0m\u001b[1mğŸ“š Utilities:   \u001b[0m\u001b[1m \u001b[0m\u001b[32m \u001b[0m\u001b[32mdoc_generator, todo                      \u001b[0m\u001b[32m \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ’¡ Quick Commands â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">ğŸ“‹ Commands: </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">/clear, /history, /quit, /exit</span>                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mâ•­â”€\u001b[0m\u001b[33mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[33m ğŸ’¡ Quick Commands \u001b[0m\u001b[33mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[33mâ”€â•®\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m \u001b[1;31mğŸ“‹ Commands: \u001b[0m\u001b[37m/clear, /history, /quit, /exit\u001b[0m                                                                     \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "ğŸ’¬ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Ready to assist! Type your message or command:</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "ğŸ’¬ \u001b[1;32mReady to assist! Type your message or command:\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  Hello\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://192.168.29.147:11500/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[38;2;200;100;120mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ¤” Thinking â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[0m\n",
      "\u001b[38;2;200;100;120mâ”‚ \u001b[38;2;200;100;120mUser\u001b[0m\u001b[38;2;200;100;120m says\u001b[0m\u001b[38;2;200;100;120m \"\u001b[0m\u001b[38;2;200;100;120mHello\u001b[0m\u001b[38;2;200;100;120m\".\u001b[0m\u001b[38;2;200;100;120m No\u001b[0m\u001b[38;2;200;100;120m request\u001b[0m\u001b[38;2;200;100;120m.\u001b[0m\u001b[38;2;200;100;120m We'll\u001b[0m\u001b[38;2;200;100;120m respond\u001b[0m\u001b[38;2;200;100;120m.\u001b[0m"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Hello! ğŸ‘‹ How can I assist you today?                                                                              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Hello! ğŸ‘‹ How can I assist you today?                                                                              \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  Show me the contents of README.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://192.168.29.147:11500/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[38;2;200;100;120mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ¤” Thinking â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[0m\n",
      "\u001b[38;2;200;100;120mâ”‚ \u001b[38;2;200;100;120mWe\u001b[0m\u001b[38;2;200;100;120m need\u001b[0m\u001b[38;2;200;100;120m to\u001b[0m\u001b[38;2;200;100;120m read\u001b[0m\u001b[38;2;200;100;120m README\u001b[0m\u001b[38;2;200;100;120m.md\u001b[0m\u001b[38;2;200;100;120m.\u001b[0m\u001b[38;2;200;100;120m Directory\u001b[0m\u001b[38;2;200;100;120m path\u001b[0m\u001b[38;2;200;100;120m given\u001b[0m\u001b[38;2;200;100;120m is\u001b[0m\u001b[38;2;200;100;120m /\u001b[0m\u001b[38;2;200;100;120mhome\u001b[0m\u001b[38;2;200;100;120m/pr\u001b[0m\u001b[38;2;200;100;120man\u001b[0m\u001b[38;2;200;100;120mav\u001b[0m\u001b[38;2;200;100;120m-p\u001b[0m\u001b[38;2;200;100;120mc\u001b[0m\u001b[38;2;200;100;120m/projects\u001b[0m\u001b[38;2;200;100;120m/ap\u001b[0m\u001b[38;2;200;100;120mplied\u001b[0m\u001b[38;2;200;100;120m-\u001b[0m\u001b[38;2;200;100;120mGen\u001b[0m\u001b[38;2;200;100;120mAI\u001b[0m\u001b[38;2;200;100;120m-l\u001b[0m\u001b[38;2;200;100;120mab\u001b[0m\u001b[38;2;200;100;120m/n\u001b[0m\u001b[38;2;200;100;120mbs\u001b[0m\u001b[38;2;200;100;120m/b\u001b[0m\u001b[38;2;200;100;120muddy\u001b[0m\u001b[38;2;200;100;120m/frontend\u001b[0m\u001b[38;2;200;100;120m.\u001b[0m\u001b[38;2;200;100;120m Search\u001b[0m\u001b[38;2;200;100;120m for\u001b[0m\u001b[38;2;200;100;120m README\u001b[0m\u001b[38;2;200;100;120m.md\u001b[0m\u001b[38;2;200;100;120m.\u001b[0m\u001b[38;2;200;100;120m Use\u001b[0m\u001b[38;2;200;100;120m fs\u001b[0m\u001b[38;2;200;100;120m_read\u001b[0m\u001b[38;2;200;100;120m discover\u001b[0m\u001b[38;2;200;100;120m?\u001b[0m\u001b[38;2;200;100;120m Probably\u001b[0m\u001b[38;2;200;100;120m there's\u001b[0m\u001b[38;2;200;100;120m a\u001b[0m\u001b[38;2;200;100;120m README\u001b[0m\u001b[38;2;200;100;120m.md\u001b[0m\u001b[38;2;200;100;120m in\u001b[0m\u001b[38;2;200;100;120m root\u001b[0m\u001b[38;2;200;100;120m.\u001b[0m\u001b[38;2;200;100;120m Use\u001b[0m\u001b[38;2;200;100;120m fs\u001b[0m\u001b[38;2;200;100;120m_read\u001b[0m\u001b[38;2;200;100;120m discover\u001b[0m\u001b[38;2;200;100;120m.\u001b[0m\n",
      "âš ï¸ Validation error for fs_read: 1 validation error for FsReadParams\n",
      "operations.0.path\n",
      "  Field required [type=missing, input_value={'max_results': 10, 'mode... 'pattern': 'README.md'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      "âš ï¸ Skipping fs_read due to validation errors\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  what validation error you have encountered ?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://192.168.29.147:11500/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[38;2;200;100;120mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ¤” Thinking â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[0m\n",
      "\u001b[38;2;200;100;120mâ”‚ \u001b[38;2;200;100;120mWe\u001b[0m\u001b[38;2;200;100;120m need\u001b[0m\u001b[38;2;200;100;120m to\u001b[0m\u001b[38;2;200;100;120m read\u001b[0m\u001b[38;2;200;100;120m README\u001b[0m\u001b[38;2;200;100;120m.md\u001b[0m\u001b[38;2;200;100;120m.\u001b[0m\u001b[38;2;200;100;120m It's\u001b[0m\u001b[38;2;200;100;120m likely\u001b[0m\u001b[38;2;200;100;120m in\u001b[0m\u001b[38;2;200;100;120m the\u001b[0m\u001b[38;2;200;100;120m repo\u001b[0m\u001b[38;2;200;100;120m.\u001b[0m\u001b[38;2;200;100;120m Use\u001b[0m\u001b[38;2;200;100;120m fs\u001b[0m\u001b[38;2;200;100;120m_read\u001b[0m\u001b[38;2;200;100;120m discover\u001b[0m\u001b[38;2;200;100;120m mode\u001b[0m\u001b[38;2;200;100;120m.\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:agentic.backend.tools.fs_read:Path README.md does not exist; returning empty results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸ Validation error for fs_read: 1 validation error for FsReadParams\n",
      "operations.0.path\n",
      "  Field required [type=missing, input_value={'max_results': 10, 'mode... 'pattern': 'README.md'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      "âš ï¸ Skipping fs_read due to validation errors\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# | export\n",
    "def main(model=None, base_url=None, api_key=None, no_stream=False):\n",
    "    \"\"\"Enhanced interface with OpenAI tool calling (adapted for Jupyter)\"\"\"\n",
    "    \n",
    "    # Load config defaults\n",
    "    model_config = get_model_config()\n",
    "    \n",
    "    # Use config values as defaults\n",
    "    if model is None:\n",
    "        model = model_config.get('name', 'qwen3:8b')\n",
    "    if base_url is None:\n",
    "        base_url = model_config.get('url', 'http://localhost:11434/v1')\n",
    "    if api_key is None:\n",
    "        api_key = model_config.get('api_key', 'ollama')\n",
    "    \n",
    "    # Create a simple object with attributes similar to argparse.Namespace\n",
    "    class Args:\n",
    "        pass\n",
    "    \n",
    "    args = Args()\n",
    "    args.model = model\n",
    "    args.base_url = base_url\n",
    "    args.api_key = api_key\n",
    "    args.no_stream = no_stream\n",
    "\n",
    "    # Now create the client\n",
    "    client = BuddyClient(\n",
    "        model=args.model,\n",
    "        base_url=args.base_url,\n",
    "        api_key=args.api_key\n",
    "    )\n",
    "    \n",
    "    # Enhanced welcome message using Rich\n",
    "    from rich.console import Console\n",
    "    from rich.panel import Panel\n",
    "    from rich.text import Text\n",
    "    from rich.table import Table\n",
    "    \n",
    "    console = Console(theme=custom_theme)\n",
    "    \n",
    "    # Create welcome header\n",
    "    welcome_text = Text()\n",
    "    welcome_text.append(\"ğŸ¤– Buddy CLI\", style=\"bold cyan\")\n",
    "    welcome_text.append(\" - Advanced Autonomous AI Assistant\", style=\"bright_white\")\n",
    "    \n",
    "    # Model info\n",
    "    model_text = Text()\n",
    "    model_text.append(\"ğŸ§  Model: \", style=\"bold white\")\n",
    "    model_text.append(f\"{args.model}\", style=\"bright_green\")\n",
    "    if args.base_url and args.base_url != \"https://api.openai.com/v1\":\n",
    "        model_text.append(f\" ({args.base_url})\", style=\"dim white\")\n",
    "    \n",
    "    # Create tools table\n",
    "    tools_table = Table(show_header=False, box=None, padding=(0, 1))\n",
    "    tools_table.add_column(\"Category\", style=\"bold\")\n",
    "    tools_table.add_column(\"Tools\", style=\"green\")\n",
    "    \n",
    "    tools_table.add_row(\"ğŸ› ï¸  Core Tools:\", \"fs_read, fs_write, execute_bash\")\n",
    "    tools_table.add_row(\"ğŸ§ª Analysis:\", \"code_interpreter, code_quality, analyzer\")\n",
    "    tools_table.add_row(\"ğŸ§  Intelligence:\", \"introspect, debate_agent, memory_manager\")\n",
    "    tools_table.add_row(\"ğŸ“‹ Planning:\", \"task_planner, task_executor, task_monitor\")\n",
    "    tools_table.add_row(\"ğŸ“š Utilities:\", \"doc_generator, todo\")\n",
    "    \n",
    "    # Commands\n",
    "    commands_text = Text()\n",
    "    commands_text.append(\"ğŸ“‹ Commands: \", style=\"bold red\")\n",
    "    commands_text.append(\"/clear, /history, /quit, /exit\", style=\"white\")\n",
    "    \n",
    "    # Create panel content\n",
    "    panel_content = Text()\n",
    "    panel_content.append_text(welcome_text)\n",
    "    panel_content.append(\"\\n\")\n",
    "    panel_content.append_text(model_text)\n",
    "    panel_content.append(\"\\n\\n\")\n",
    "    \n",
    "    # Add tools table to console buffer\n",
    "    console.print(Panel(panel_content, title=\"âœ¨ Welcome to Buddy âœ¨\", border_style=\"bright_blue\", padding=(1, 2)))\n",
    "    console.print(tools_table)\n",
    "    console.print()\n",
    "    \n",
    "    # Commands panel\n",
    "    commands_panel = Panel(commands_text, title=\"ğŸ’¡ Quick Commands\", border_style=\"yellow\", padding=(0, 1))\n",
    "    console.print(commands_panel)\n",
    "    console.print(\"\\nğŸ’¬ [bold green]Ready to assist! Type your message or command:[/bold green]\\n\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\">> \").strip()\n",
    "            \n",
    "            if user_input.lower() in ['quit', 'exit', '/quit', '/exit']:\n",
    "                break\n",
    "            elif user_input.lower() in ['clear','/clear']:\n",
    "                client.clear_history()\n",
    "                continue\n",
    "            elif user_input.lower() in ['/history']:\n",
    "                client.show_history()\n",
    "                continue\n",
    "                \n",
    "            if user_input:\n",
    "                client.chat(user_input, stream=not args.no_stream)\n",
    "                print()\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nGoodbye!\")\n",
    "            break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ff6e41-296e-44d4-a2fd-643453c3fe6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dcbc16-a2c6-4b42-a7e5-35aafb581a81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
