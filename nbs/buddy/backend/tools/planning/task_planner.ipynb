{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3814531e-c26a-449f-8ab8-d91c368bf98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp tools.task_planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27bedf0e-0c6d-49c8-8f42-447f0cebb1d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AgentTaskAnalyzer' from 'agentic.analyzer' (/home/pranav-pc/projects/applied-GenAI-lab/agentic/backend/analyzer.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Any\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magentic\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseTool\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magentic\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01manalyzer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AgentTaskAnalyzer\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mTaskPlannerTool\u001b[39;00m(BaseTool):\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'AgentTaskAnalyzer' from 'agentic.analyzer' (/home/pranav-pc/projects/applied-GenAI-lab/agentic/backend/analyzer.py)"
     ]
    }
   ],
   "source": [
    "# | export\n",
    "\"\"\"\n",
    "Task Planner BaseTool - Complete Task Analyzer Integration with Caching\n",
    "\"\"\"\n",
    "import json\n",
    "import hashlib\n",
    "import os\n",
    "from typing import Dict, Any\n",
    "from agentic.tools.base import BaseTool\n",
    "from agentic.analyzer import AgentTaskAnalyzer\n",
    "\n",
    "class TaskPlannerTool(BaseTool):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cache_dir = \"/tmp/buddy_cache\"\n",
    "        os.makedirs(self.cache_dir, exist_ok=True)\n",
    "    \n",
    "    def _get_cache_key(self, request: str) -> str:\n",
    "        \"\"\"Generate cache key from request\"\"\"\n",
    "        return hashlib.md5(request.encode()).hexdigest()\n",
    "    \n",
    "    def _get_cache_path(self, cache_key: str) -> str:\n",
    "        \"\"\"Get cache file path\"\"\"\n",
    "        return os.path.join(self.cache_dir, f\"task_plan_{cache_key}.json\")\n",
    "    \n",
    "    def _load_from_cache(self, request: str) -> Dict[str, Any]:\n",
    "        \"\"\"Load cached plan if exists\"\"\"\n",
    "        cache_key = self._get_cache_key(request)\n",
    "        cache_path = self._get_cache_path(cache_key)\n",
    "        \n",
    "        if os.path.exists(cache_path):\n",
    "            try:\n",
    "                with open(cache_path, 'r') as f:\n",
    "                    cached_result = json.load(f)\n",
    "                print(f\"üì¶ Loaded cached plan from {cache_path}\")\n",
    "                return cached_result\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  Cache load failed: {e}\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _save_to_cache(self, request: str, result: Dict[str, Any]) -> None:\n",
    "        \"\"\"Save plan to cache\"\"\"\n",
    "        cache_key = self._get_cache_key(request)\n",
    "        cache_path = self._get_cache_path(cache_key)\n",
    "        \n",
    "        try:\n",
    "            with open(cache_path, 'w') as f:\n",
    "                json.dump(result, f, indent=2)\n",
    "            print(f\"üíæ Cached plan to {cache_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Cache save failed: {e}\")\n",
    "    def get_parameters_schema(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"task_planner\",\n",
    "                \"description\": \"PRIORITY TOOL: Analyze complex requests and create detailed execution plans with task breakdown, framework selection via debate, and success criteria. ALWAYS pass the complete user input, not summaries. Has ABSOLUTE PRECEDENCE over other tools for moderate to complex requests. Creates debate tasks instead of calling debate_agent directly.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"request\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The complete user request to analyze and plan (never use summaries)\"\n",
    "                        },\n",
    "                        \"model\": {\n",
    "                            \"type\": \"string\", \n",
    "                            \"description\": \"LLM model for analysis\",\n",
    "                            \"default\": \"qwen3:14b\"\n",
    "                        },\n",
    "                        \"base_url\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"LLM base URL\",\n",
    "                            \"default\": \"http://192.168.29.147:11500/v1\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"request\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _needs_elaboration(self, request: str) -> bool:\n",
    "        \"\"\"Check if request needs more details\"\"\"\n",
    "        # Simple heuristics to detect vague requests\n",
    "        vague_indicators = [\n",
    "            len(request.split()) < 5,  # Very short requests\n",
    "            any(word in request.lower() for word in ['something', 'anything', 'stuff', 'thing']),\n",
    "            request.count('?') > 2,  # Too many questions\n",
    "            not any(word in request.lower() for word in ['create', 'build', 'make', 'develop', 'implement', 'setup', 'configure'])\n",
    "        ]\n",
    "        return any(vague_indicators)\n",
    "\n",
    "    def _ask_for_elaboration(self, request: str) -> Dict[str, Any]:\n",
    "        \"\"\"Ask user to elaborate on vague request\"\"\"\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"status\": \"needs_elaboration\",\n",
    "            \"message\": \"I need more details to create an effective plan. Could you please elaborate on:\",\n",
    "            \"clarification_needed\": [\n",
    "                \"What specific outcome do you want to achieve?\",\n",
    "                \"What technologies or frameworks should be used?\",\n",
    "                \"Are there any constraints or requirements I should know about?\",\n",
    "                \"What is the scope and complexity level you're aiming for?\"\n",
    "            ],\n",
    "            \"original_request\": request,\n",
    "            \"suggestion\": \"Please provide a more detailed description of what you want to accomplish, and I'll create a comprehensive execution plan for you.\"\n",
    "        }\n",
    "\n",
    "    def execute(self, request: str, model: str = \"qwen3:14b\", base_url: str = \"http://192.168.29.147:11500/v1\") -> Dict[str, Any]:\n",
    "        \"\"\"Execute complete task planning with elaboration check - accepts full user input\"\"\"\n",
    "        try:\n",
    "            # Check if request needs elaboration\n",
    "            if self._needs_elaboration(request):\n",
    "                return self._ask_for_elaboration(request)\n",
    "            \n",
    "            # Check cache first\n",
    "            cached_result = self._load_from_cache(request)\n",
    "            if cached_result:\n",
    "                return cached_result\n",
    "            \n",
    "            # Initialize with full analyzer capabilities\n",
    "            analyzer = AgentTaskAnalyzer(model=model, base_url=base_url)\n",
    "            \n",
    "            # Get complete analysis using the full user request\n",
    "            result = analyzer.analyze(request)\n",
    "            \n",
    "            # Display beautiful analysis (this will show in Buddy output)\n",
    "            analyzer.display_result(result)\n",
    "            \n",
    "            # Return structured plan for Buddy to use\n",
    "            plan_result = {\n",
    "                \"success\": True,\n",
    "                \"status\": \"success\",\n",
    "                \"analysis_complete\": True,\n",
    "                \"complexity\": result.input_complexity.value,\n",
    "                \"total_tasks\": len(result.tasks),\n",
    "                \"total_actions\": result.execution_plan.total_actions,\n",
    "                \"frameworks_selected\": result.recommended_frameworks,\n",
    "                \"tools_needed\": [tool.value for tool in result.buddy_tools_needed],\n",
    "                \"execution_plan\": {\n",
    "                    \"sequential_phases\": result.execution_plan.sequential_phases,\n",
    "                    \"parallel_groups\": result.execution_plan.parallel_groups,\n",
    "                    \"critical_path\": result.execution_plan.critical_path\n",
    "                },\n",
    "                \"tasks\": [\n",
    "                    {\n",
    "                        \"id\": task.id,\n",
    "                        \"name\": task.name,\n",
    "                        \"description\": task.description,\n",
    "                        \"complexity\": task.complexity.value,\n",
    "                        \"tools\": [tool.value for tool in task.buddy_tools],\n",
    "                        \"frameworks\": task.frameworks,\n",
    "                        \"actions\": task.actions,\n",
    "                        \"success_criteria\": task.success_criteria,\n",
    "                        \"dependencies\": task.dependencies,\n",
    "                        \"expected_outputs\": task.expected_outputs,\n",
    "                        \"execution_mode\": task.execution_mode.value\n",
    "                    }\n",
    "                    for task in result.tasks\n",
    "                ],\n",
    "                \"success_criteria\": result.success_criteria,\n",
    "                \"plan_summary\": f\"‚úÖ Created {len(result.tasks)} tasks with {result.execution_plan.total_actions} actions. Complexity: {result.input_complexity.value}. Ready for execution!\",\n",
    "                \"next_steps\": \"Execute tasks in the order specified in execution_plan.sequential_phases using the recommended tools.\",\n",
    "                \"original_request\": request,  # Store original request for task_executor\n",
    "                \"requires_execution\": True  # Flag to trigger automatic task_executor\n",
    "            }\n",
    "            \n",
    "            # Cache the result\n",
    "            self._save_to_cache(request, plan_result)\n",
    "            \n",
    "            return plan_result\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"status\": \"error\",\n",
    "                \"error\": str(e),\n",
    "                \"plan_summary\": f\"‚ùå Failed to create execution plan: {e}\",\n",
    "                \"next_steps\": \"Try breaking down the request into simpler parts or check the request format.\"\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7f5bd2-75f4-4db3-a42f-bc7531a9ea74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
