# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/buddy/backend/agents/debater.ipynb.

# %% auto 0
__all__ = ['DebateRole', 'DebateConfig', 'DebateAgent', 'create_debate']

# %% ../../nbs/buddy/backend/agents/debater.ipynb 1
from enum import Enum
from dataclasses import dataclass
from typing import List, Dict, Any, Optional
import asyncio
from ..core.agent import Agent, AgentConfig
from ..llms.client import LLMClient


# %% ../../nbs/buddy/backend/agents/debater.ipynb 2
class DebateRole(Enum):
    ADVOCATE = "advocate"
    CRITIC = "critic"
    EXPERT = "expert"
    MODERATOR = "moderator"

@dataclass
class DebateConfig:
    topic: str
    context: str
    max_rounds: int = 2
    time_limit: Optional[int] = None

class DebateAgent(Agent):
    """Multi-agent debate system for structured decision making"""

    def __init__(self, config: AgentConfig, role: DebateRole, debate_config: DebateConfig):
        super().__init__(config)
        self.role = role
        self.debate_config = debate_config
        self.debate_history: List[Dict[str, str]] = []

        self.role_prompts = {
            DebateRole.ADVOCATE: f"You are advocating FOR the position: {debate_config.topic}. Present strong arguments with evidence.",
            DebateRole.CRITIC: f"You are arguing AGAINST the position: {debate_config.topic}. Challenge with counterarguments and evidence.",
            DebateRole.EXPERT: f"You are a domain expert analyzing: {debate_config.topic}. Provide balanced technical insights.",
            DebateRole.MODERATOR: f"You moderate the debate on: {debate_config.topic}. Synthesize arguments and provide final verdict."
        }

    async def opening_statement(self) -> str:
        """Generate opening statement based on role"""
        prompt = f"""
{self.role_prompts[self.role]}

Context: {self.debate_config.context}

Provide your opening statement:
- State your main position clearly
- Provide 2-3 key arguments supporting your stance
- Preview technical evidence or examples to back your claims
"""
        messages = [{"role": "user", "content": prompt}]
        response = self.llm_client.create_completion(messages=messages, stream=True)
        result = self.llm_client.handle_streaming_response(response)

        text = result.get("content", "") if isinstance(result, dict) else str(result)
        self.debate_history.append({"role": self.role.value, "type": "opening", "content": text})
        return text

    async def respond_to_debate(self, previous_statements: List[Dict]) -> str:
        """Respond to previous debate statements with context"""
        # Format previous statements for context
        debate_context = "\n\n".join(
            [f"{stmt['role'].capitalize()} ({stmt['type']}): {stmt['content']}" 
             for stmt in previous_statements]
        )

        prompt = f"""
{self.role_prompts[self.role]}

Context: {self.debate_config.context}

Previous debate statements:
{debate_context}

Respond to the ongoing debate (250-300 words):
- Address specific points raised by other agents
- Reinforce or refute arguments with technical reasoning
- Provide concise, evidence-based arguments
"""
        messages = [{"role": "user", "content": prompt}]
        response = self.llm_client.create_completion(messages=messages, stream=True)
        result = self.llm_client.handle_streaming_response(response)

        text = result.get("content", "") if isinstance(result, dict) else str(result)
        self.debate_history.append({"role": self.role.value, "type": "response", "content": text})
        return text

    async def final_verdict(self, all_statements: List[Dict]) -> str:
        """Generate final verdict (moderator only)"""
        if self.role != DebateRole.MODERATOR:
            return ""

        context = "\n\n".join(
            [f"{stmt['role'].capitalize()} ({stmt['type']}): {stmt['content']}" 
             for stmt in all_statements]
        )

        prompt = f"""
{self.role_prompts[self.role]}

Context: {self.debate_config.context}

All debate statements:
{context}

Provide the final verdict (200-250 words):
1. Summarize key arguments from each side
2. Identify the strongest points made
3. Provide a final recommendation with clear reasoning
4. Discuss implementation considerations
"""
        messages = [{"role": "user", "content": prompt}]
        response = self.llm_client.create_completion(messages=messages, stream=True)
        result = self.llm_client.handle_streaming_response(response)

        text = result.get("content", "") if isinstance(result, dict) else str(result)
        self.debate_history.append({"role": self.role.value, "type": "verdict", "content": text})
        return text

async def create_debate(topic: str, context: str, max_rounds: int = 2) -> Dict[str, Any]:
    """Create and run a structured debate"""
    debate_config = DebateConfig(topic=topic, context=context, max_rounds=max_rounds)

    base_config = AgentConfig(name="debate_agent", model="qwen3:14b")
    agents = {
        DebateRole.ADVOCATE: DebateAgent(base_config, DebateRole.ADVOCATE, debate_config),
        DebateRole.CRITIC: DebateAgent(base_config, DebateRole.CRITIC, debate_config),
        DebateRole.EXPERT: DebateAgent(base_config, DebateRole.EXPERT, debate_config),
        DebateRole.MODERATOR: DebateAgent(base_config, DebateRole.MODERATOR, debate_config),
    }

    all_statements: List[Dict] = []

    # Opening statements
    for role in [DebateRole.ADVOCATE, DebateRole.CRITIC, DebateRole.EXPERT]:
        statement = await agents[role].opening_statement()
        all_statements.append({"role": role.value, "type": "opening", "content": statement})

    # Discussion rounds
    for round_num in range(max_rounds):
        for role in [DebateRole.ADVOCATE, DebateRole.CRITIC, DebateRole.EXPERT]:
            response = await agents[role].respond_to_debate(all_statements)
            all_statements.append({"role": role.value, "type": f"round_{round_num+1}", "content": response})

    # Final verdict
    verdict = await agents[DebateRole.MODERATOR].final_verdict(all_statements)
    return verdict
    # return {
    #     "topic": topic,
    #     "context": context,
    #     "statements": all_statements,
    #     "verdict": verdict,
    #     "rounds": max_rounds,
    # }
