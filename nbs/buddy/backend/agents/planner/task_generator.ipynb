{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46f66251-d324-4e26-a1c3-68698805a5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp agent.planner.task_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75def6dc-5631-43cc-aa5b-5a2838e567e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import json\n",
    "import re\n",
    "from typing import Optional\n",
    "from rich.console import Console\n",
    "from agentic.agent.planner.models import Task, ProjectBreakdown, ProjectContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "108479c4-03b7-4648-bba1-bb86bcd6787e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Console' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# | export\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mTaskGenerator\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;250;43m    \u001b[39;49m\u001b[33;43;03m\"\"\"Handles task generation and validation\"\"\"\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsole\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mConsole\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mTaskGenerator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mTaskGenerator\u001b[39;00m:\n\u001b[32m      3\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Handles task generation and validation\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, agent, console: \u001b[43mConsole\u001b[49m):\n\u001b[32m      6\u001b[39m         \u001b[38;5;28mself\u001b[39m.agent = agent\n\u001b[32m      7\u001b[39m         \u001b[38;5;28mself\u001b[39m.console = console\n",
      "\u001b[31mNameError\u001b[39m: name 'Console' is not defined"
     ]
    }
   ],
   "source": [
    "# | export\n",
    "class TaskGenerator:\n",
    "    \"\"\"Handles task generation and validation\"\"\"\n",
    "    \n",
    "    def __init__(self, agent, console: Console):\n",
    "        self.agent = agent\n",
    "        self.console = console\n",
    "    \n",
    "    def generate_next_task(self, context: ProjectContext, breakdown: ProjectBreakdown, estimated_total: int) -> Optional[Task]:\n",
    "        \"\"\"Generate single next task using project breakdown context\"\"\"\n",
    "        \n",
    "        context_prompt = self._build_context_prompt(context)\n",
    "        execution_context = self._get_execution_context(context)\n",
    "        \n",
    "        completed_count = len(context.execution_history)\n",
    "        next_task_id = f\"T{completed_count + 1:03d}\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "CRITICAL: You MUST generate EXACTLY ONE task object (not an array). Generate the NEXT logical task in the project sequence.\n",
    "\n",
    "CURRENT PROGRESS: {completed_count} tasks completed out of estimated {estimated_total}\n",
    "\n",
    "{execution_context}\n",
    "\n",
    "PROJECT BREAKDOWN CONTEXT:\n",
    "Summary: {breakdown.project_summary}\n",
    "Phases: {', '.join(breakdown.phases)}\n",
    "Key Deliverables: {', '.join(breakdown.key_deliverables)}\n",
    "Technical Approach: {breakdown.technical_approach}\n",
    "\n",
    "ORIGINAL REQUEST: {context.original_request}\n",
    "\n",
    "{context_prompt}\n",
    "\n",
    "Based on the project breakdown and what has been completed, generate the NEXT SINGLE TASK. \n",
    "\n",
    "TASK PROGRESSION LOGIC:\n",
    "- If 0-2 tasks completed: Focus on project setup, requirements analysis, structure creation\n",
    "- If 3-5 tasks completed: Focus on core implementation, main components\n",
    "- If 6-8 tasks completed: Focus on integration, data handling, advanced features  \n",
    "- If 9+ tasks completed: Focus on testing, optimization, deployment\n",
    "\n",
    "Generate a task that logically follows the completed work and moves toward the key deliverables.\n",
    "\n",
    "RESPOND WITH SINGLE TASK OBJECT:\n",
    "{{\n",
    "  \"id\": \"{next_task_id}\",\n",
    "  \"name\": \"Next Task Name\",\n",
    "  \"description\": \"Task description aligned with project phases\",\n",
    "  \"dependencies\": [],\n",
    "  \"actions\": [\n",
    "    {{\n",
    "      \"step\": 1,\n",
    "      \"purpose\": \"Main action purpose\",\n",
    "      \"sub_steps\": [\"Specific step 1\", \"Specific step 2\"],\n",
    "      \"introspect_after\": true,\n",
    "      \"system_prompt\": \"You are a developer. CONTEXT: {breakdown.project_summary}. Your task is to...\",\n",
    "      \"user_prompt\": \"Based on the project requirements, please...\",\n",
    "      \"introspect_prompt\": \"Validate that the task was completed by checking...\",\n",
    "      \"execution_mode\": \"sequential\"\n",
    "    }}\n",
    "  ],\n",
    "  \"success_criteria\": \"Specific success criteria\",\n",
    "  \"expected_outputs\": [\"output1.py\"],\n",
    "  \"potential_options\": [],\n",
    "  \"needs_debate\": false\n",
    "}}\n",
    "\n",
    "IMPORTANT: Always generate a valid task object. Only return null if truly no more work is needed (which should be rare for complex projects).\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.agent.run(prompt).get(\"content\", \"\")\n",
    "            \n",
    "            # Save raw response for debugging\n",
    "            with open(\"task_generation_raw.txt\", 'w') as f:\n",
    "                f.write(response)\n",
    "            \n",
    "            # Parse and validate task\n",
    "            response = response.strip()\n",
    "            \n",
    "            # Only return None if explicitly null AND we have enough tasks\n",
    "            if response.lower() == \"null\":\n",
    "                if context.total_tasks_completed >= 5:\n",
    "                    return None\n",
    "                else:\n",
    "                    self.console.print(\"⚠️ LLM returned null but project needs more tasks. Regenerating...\")\n",
    "                    return self._force_generate_next_task(context, breakdown, estimated_total)\n",
    "            \n",
    "            # Try to extract JSON from response\n",
    "            json_match = re.search(r'\\{.*\\}', response, re.DOTALL)\n",
    "            if json_match:\n",
    "                json_str = json_match.group()\n",
    "                task_data = json.loads(json_str)\n",
    "            else:\n",
    "                task_data = json.loads(response)\n",
    "                \n",
    "        except json.JSONDecodeError as e:\n",
    "            self.console.print(f\"❌ JSON parsing failed: {e}\")\n",
    "            task_data = self._extract_task_from_text(response, context)\n",
    "            if not task_data:\n",
    "                self.console.print(\"❌ Failed to extract task from response\")\n",
    "                return None\n",
    "        \n",
    "        # If LLM returns array, take only the first task\n",
    "        if isinstance(task_data, list):\n",
    "            if len(task_data) > 0:\n",
    "                task_data = task_data[0]\n",
    "                self.console.print(\"⚠️ LLM returned multiple tasks, using only the first one\")\n",
    "            else:\n",
    "                self.console.print(\"⚠️ LLM returned empty task array\")\n",
    "                return None\n",
    "        \n",
    "        # Validate required fields\n",
    "        if not isinstance(task_data, dict) or 'name' not in task_data:\n",
    "            self.console.print(\"⚠️ Invalid task format returned by LLM\")\n",
    "            return None\n",
    "        \n",
    "        task = Task(**task_data)\n",
    "        task.id = f\"T{len(context.execution_history) + 1:03d}\"\n",
    "        \n",
    "        # Check for task repetition\n",
    "        for prev_task in context.execution_history:\n",
    "            if task.name.lower().strip() == prev_task.task_name.lower().strip():\n",
    "                self.console.print(f\"⚠️ Task '{task.name}' appears to be a repeat. Skipping.\")\n",
    "                return None\n",
    "        \n",
    "        return task\n",
    "    \n",
    "    def regenerate_task_with_feedback(self, context: ProjectContext, breakdown: ProjectBreakdown, feedback: str) -> Optional[Task]:\n",
    "        \"\"\"Regenerate task incorporating introspection feedback\"\"\"\n",
    "        context_prompt = self._build_context_prompt(context)\n",
    "        execution_context = self._get_execution_context(context)\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "CRITICAL: The previously generated task was rejected. Generate a BETTER task incorporating the feedback.\n",
    "\n",
    "FEEDBACK FROM VALIDATION: {feedback}\n",
    "\n",
    "{execution_context}\n",
    "\n",
    "PROJECT BREAKDOWN CONTEXT:\n",
    "Summary: {breakdown.project_summary}\n",
    "Phases: {', '.join(breakdown.phases)}\n",
    "Key Deliverables: {', '.join(breakdown.key_deliverables)}\n",
    "\n",
    "{context_prompt}\n",
    "\n",
    "Generate ONE improved task that addresses the validation feedback. Ensure it's unique and not a repeat.\n",
    "\n",
    "RESPOND WITH SINGLE TASK OBJECT OR NULL:\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            agent_response = self.agent.run(prompt)\n",
    "            response = agent_response.get(\"content\", \"\") if isinstance(agent_response, dict) else str(agent_response)\n",
    "            \n",
    "            if response.strip().lower() == \"null\":\n",
    "                return None\n",
    "                \n",
    "            task_data = json.loads(response.strip())\n",
    "            \n",
    "        except json.JSONDecodeError:\n",
    "            task_data = self._extract_task_from_text(response.strip(), context)\n",
    "            if not task_data:\n",
    "                raise ValueError(\"Failed to parse JSON and extract task fields. Please provide valid JSON format with required fields: id, name, description, actions.\")\n",
    "            \n",
    "            if isinstance(task_data, list) and len(task_data) > 0:\n",
    "                task_data = task_data[0]\n",
    "            elif isinstance(task_data, list):\n",
    "                return None\n",
    "                \n",
    "            if not isinstance(task_data, dict) or 'name' not in task_data:\n",
    "                return None\n",
    "                \n",
    "            task = Task(**task_data)\n",
    "            task.id = f\"T{len(context.execution_history) + 1:03d}\"\n",
    "            \n",
    "            return task\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.console.print(f\"❌ Task regeneration failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _force_generate_next_task(self, context: ProjectContext, breakdown: ProjectBreakdown, estimated_total: int) -> Optional[Task]:\n",
    "        \"\"\"Force generation of next task when LLM returns null prematurely\"\"\"\n",
    "        \n",
    "        completed_count = len(context.execution_history)\n",
    "        next_task_id = f\"T{completed_count + 1:03d}\"\n",
    "        \n",
    "        # Determine what type of task is needed based on progress\n",
    "        if completed_count < 3:\n",
    "            task_type = \"setup and structure\"\n",
    "            example_tasks = [\"Create project structure\", \"Setup dependencies\", \"Configure environment\"]\n",
    "        elif completed_count < 6:\n",
    "            task_type = \"core implementation\"\n",
    "            example_tasks = [\"Implement main scraper\", \"Add rate limiting\", \"Create data models\"]\n",
    "        else:\n",
    "            task_type = \"integration and testing\"\n",
    "            example_tasks = [\"Add error handling\", \"Create tests\", \"Setup deployment\"]\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "CRITICAL: The project needs more tasks to be complete. You MUST generate a task.\n",
    "\n",
    "CURRENT STATUS: Only {completed_count} tasks completed - this is insufficient for a complete web scraping framework.\n",
    "\n",
    "REQUIRED TASK TYPE: {task_type}\n",
    "EXAMPLES: {', '.join(example_tasks)}\n",
    "\n",
    "PROJECT CONTEXT:\n",
    "- Original Request: {context.original_request}\n",
    "- Project Summary: {breakdown.project_summary}\n",
    "- Completed Tasks: {[t.task_name for t in context.execution_history]}\n",
    "\n",
    "Generate a {task_type} task that is essential for completing the web scraping framework.\n",
    "\n",
    "RESPOND WITH TASK OBJECT:\n",
    "{{\n",
    "  \"id\": \"{next_task_id}\",\n",
    "  \"name\": \"Essential Task Name\",\n",
    "  \"description\": \"Description of essential task\",\n",
    "  \"dependencies\": [],\n",
    "  \"actions\": [\n",
    "    {{\n",
    "      \"step\": 1,\n",
    "      \"purpose\": \"Main purpose\",\n",
    "      \"sub_steps\": [\"Step 1\", \"Step 2\"],\n",
    "      \"introspect_after\": true,\n",
    "      \"system_prompt\": \"You are a developer working on a web scraping framework. Complete this essential task.\",\n",
    "      \"user_prompt\": \"Implement the required functionality for the web scraping framework.\",\n",
    "      \"introspect_prompt\": \"Validate that the implementation is correct and functional.\",\n",
    "      \"execution_mode\": \"sequential\"\n",
    "    }}\n",
    "  ],\n",
    "  \"success_criteria\": \"Task completion criteria\",\n",
    "  \"expected_outputs\": [\"output.py\"],\n",
    "  \"potential_options\": [],\n",
    "  \"needs_debate\": false\n",
    "}}\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.agent.run(prompt).get(\"content\", \"\")\n",
    "            \n",
    "            json_match = re.search(r'\\{.*\\}', response, re.DOTALL)\n",
    "            if json_match:\n",
    "                task_data = json.loads(json_match.group())\n",
    "            else:\n",
    "                task_data = json.loads(response.strip())\n",
    "            \n",
    "            if isinstance(task_data, dict) and 'name' in task_data:\n",
    "                task = Task(**task_data)\n",
    "                task.id = next_task_id\n",
    "                return task\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.console.print(f\"❌ Force task generation failed: {e}\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _build_context_prompt(self, context: ProjectContext) -> str:\n",
    "        \"\"\"Build comprehensive context from execution history\"\"\"\n",
    "        if not context.execution_history:\n",
    "            return \"PREVIOUS CONTEXT: This is the first task.\"\n",
    "        \n",
    "        context_parts = [\"EXECUTION HISTORY:\"]\n",
    "        \n",
    "        for i, task_result in enumerate(context.execution_history, 1):\n",
    "            status_emoji = \"✅\" if task_result.status == \"success\" else \"❌\"\n",
    "            context_parts.append(f\"{i}. {task_result.task_name} (ID: {task_result.task_id}) - {status_emoji} {task_result.status}\")\n",
    "            context_parts.append(f\"   Description: {task_result.task_name}\")\n",
    "            if task_result.artifacts_created:\n",
    "                if len(task_result.artifacts_created) <= 3:\n",
    "                    context_parts.append(f\"   Artifacts: {', '.join(task_result.artifacts_created)}\")\n",
    "                else:\n",
    "                    shown = ', '.join(task_result.artifacts_created[:3])\n",
    "                    remaining = len(task_result.artifacts_created) - 3\n",
    "                    context_parts.append(f\"   Artifacts: {shown} ... (+{remaining} more)\")\n",
    "        \n",
    "        context_parts.append(f\"\\nTOTAL ARTIFACTS: {len(context.current_artifacts)}\")\n",
    "        context_parts.append(f\"PROJECT STATUS: {context.project_status}\")\n",
    "        context_parts.append(f\"PROGRESS: {context.total_tasks_completed}/{len(context.execution_history)} tasks completed\")\n",
    "        \n",
    "        return \"\\n\".join(context_parts)\n",
    "    \n",
    "    def _get_execution_context(self, context: ProjectContext) -> str:\n",
    "        \"\"\"Generate minimal context for next task generation\"\"\"\n",
    "        if not context.execution_history:\n",
    "            return \"CONTEXT: This is the first task.\"\n",
    "        \n",
    "        last_task = context.execution_history[-1].task_name\n",
    "        artifacts_count = len(context.current_artifacts)\n",
    "        \n",
    "        return f\"CONTEXT: Last completed task: '{last_task}'. Total artifacts created: {artifacts_count}.\"\n",
    "    \n",
    "    def _extract_task_from_text(self, text: str, context: ProjectContext) -> Optional[dict]:\n",
    "        \"\"\"Extract task fields from malformed JSON/text as fallback\"\"\"\n",
    "        \n",
    "        json_match = re.search(r'\\{.*\\}', text, re.DOTALL)\n",
    "        if json_match:\n",
    "            try:\n",
    "                return json.loads(json_match.group())\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        task_data = {}\n",
    "        \n",
    "        if match := re.search(r'\"?id\"?\\s*:\\s*\"?([^\",\\n]+)\"?', text, re.IGNORECASE):\n",
    "            task_data[\"id\"] = match.group(1).strip('\"')\n",
    "        \n",
    "        if match := re.search(r'\"?name\"?\\s*:\\s*\"([^\"]+)\"', text, re.IGNORECASE):\n",
    "            task_data[\"name\"] = match.group(1)\n",
    "        \n",
    "        if match := re.search(r'\"?description\"?\\s*:\\s*\"([^\"]+)\"', text, re.IGNORECASE):\n",
    "            task_data[\"description\"] = match.group(1)\n",
    "        \n",
    "        if \"name\" in task_data:\n",
    "            task_data.setdefault(\"id\", f\"T{len(context.execution_history) + 1:03d}\")\n",
    "            task_data.setdefault(\"description\", task_data[\"name\"])\n",
    "            task_data.setdefault(\"dependencies\", [])\n",
    "            task_data.setdefault(\"success_criteria\", f\"Complete {task_data['name']}\")\n",
    "            task_data.setdefault(\"expected_outputs\", [])\n",
    "            task_data.setdefault(\"potential_options\", [])\n",
    "            task_data.setdefault(\"needs_debate\", False)\n",
    "            \n",
    "            task_data.setdefault(\"actions\", [{\n",
    "                \"step\": 1,\n",
    "                \"purpose\": task_data[\"name\"],\n",
    "                \"sub_steps\": [],\n",
    "                \"introspect_after\": True,\n",
    "                \"system_prompt\": f\"You are an AI assistant. Complete the task: {task_data['name']}\",\n",
    "                \"user_prompt\": task_data[\"description\"],\n",
    "                \"introspect_prompt\": f\"Validate that {task_data['name']} was completed successfully\",\n",
    "                \"execution_mode\": \"sequential\"\n",
    "            }])\n",
    "            \n",
    "            return task_data\n",
    "        \n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870a00db-431a-4aa3-9295-44d02204d3ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
