{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee8913fb-05d3-4d61-92b4-11902e9958bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from typing import Any, Dict, List,Optional, Literal\n",
    "from dataclasses import dataclass\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32a0f88d-14e3-4a04-a65a-3bbd692bc47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'xyz',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': 'Let me call a tool.',\n",
       "    'tool_calls': [{'id': 'tool1',\n",
       "      'type': 'function',\n",
       "      'function': {'name': 'get_weather',\n",
       "       'arguments': '{\"location\": \"London\"}'}}]}}],\n",
       " 'created': 123456789,\n",
       " 'model': 'gpt-4',\n",
       " 'object': 'chat.completion'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"id\": \"xyz\",\n",
    "  \"choices\": [\n",
    "    {\n",
    "      \"index\": 0,\n",
    "      \"message\": {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Let me call a tool.\",\n",
    "        \"tool_calls\": [\n",
    "          {\n",
    "            \"id\": \"tool1\",\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "              \"name\": \"get_weather\",\n",
    "              \"arguments\": \"{\\\"location\\\": \\\"London\\\"}\"\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"created\": 123456789,\n",
    "  \"model\": \"gpt-4\",\n",
    "  \"object\": \"chat.completion\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80ccb0e9-00e4-4582-acb9-f1580cc809fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatCompletionToolCallFunction(BaseModel):\n",
    "    \"\"\"The function that the model called\"\"\"\n",
    "    arguments: str  # A JSON string of the arguments to call the function with\n",
    "    name: str       # The name of the function to call\n",
    "\n",
    "class ChatCompletionToolCall(BaseModel):\n",
    "    \"\"\"A tool call generated by the model\"\"\"\n",
    "    id: str\n",
    "    function: ChatCompletionToolCallFunction\n",
    "    type: Literal[\"function\"]\n",
    "\n",
    "class ChatCompletionMessage(BaseModel):\n",
    "    \"\"\"A chat completion message generated by the model\"\"\"\n",
    "    content: Optional[str] = None\n",
    "    role: Literal[\"assistant\"]\n",
    "    tool_calls: Optional[List[ChatCompletionToolCall]] = None\n",
    "\n",
    "class ChatCompletionChoice(BaseModel):\n",
    "    \"\"\"A chat completion choice\"\"\"\n",
    "    finish_reason: Optional[str] = None\n",
    "    index: int\n",
    "    message: ChatCompletionMessage\n",
    "\n",
    "class ChatCompletion(BaseModel):\n",
    "    \"\"\"Represents a chat completion response\"\"\"\n",
    "    id: str\n",
    "    choices: List[ChatCompletionChoice]\n",
    "    created: int\n",
    "    model: str\n",
    "    object: Literal[\"chat.completion\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40bad656-77c2-4f68-8972-f8656ec13b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HTTPClient:\n",
    "    \"\"\"Simplified version of OpenAI's HTTP client\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str, base_url: str):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = base_url\n",
    "    \n",
    "    def post(self, endpoint: str, json_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Make HTTP POST request\"\"\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"User-Agent\": \"OpenAI/Python\"\n",
    "        }\n",
    "        \n",
    "        url = f\"{self.base_url}{endpoint}\"\n",
    "        print(f\"INTERNAL: POST {url}\")\n",
    "        print(f\"INTERNAL: Headers: {list(headers.keys())}\")\n",
    "        \n",
    "        response = requests.post(url, headers=headers, json=json_data)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"HTTP {response.status_code}: {response.text}\")\n",
    "        \n",
    "        return response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09fceebc-3f2c-4cd3-9da2-84178f7166c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Completions:\n",
    "    \"\"\"Handles the /chat/completions endpoint\"\"\"\n",
    "    \n",
    "    def __init__(self, http_client: HTTPClient):\n",
    "        self._client = http_client\n",
    "    \n",
    "    def create(\n",
    "        self,\n",
    "        *,\n",
    "        messages: List[Dict[str, Any]],\n",
    "        model: str,\n",
    "        tools: Optional[List[Dict[str, Any]]] = None,\n",
    "        tool_choice: Optional[str] = None,\n",
    "        **kwargs\n",
    "    ) -> ChatCompletion:\n",
    "        \"\"\"Create a chat completion\"\"\"\n",
    "        \n",
    "        print(\"INTERNAL: Building request payload...\")\n",
    "        \n",
    "        # 1. Build request body\n",
    "        body = {\n",
    "            \"messages\": messages,\n",
    "            \"model\": model,\n",
    "            **kwargs\n",
    "        }\n",
    "        \n",
    "        if tools is not None:\n",
    "            body[\"tools\"] = tools\n",
    "        \n",
    "        if tool_choice is not None:\n",
    "            body[\"tool_choice\"] = tool_choice\n",
    "        \n",
    "        print(f\"INTERNAL: Request body keys: {list(body.keys())}\")\n",
    "        \n",
    "        # 2. Make HTTP request\n",
    "        print(\"INTERNAL: Making HTTP request...\")\n",
    "        raw_response = self._client.post(\"/chat/completions\", body)\n",
    "        \n",
    "        # 3. Parse response into typed objects\n",
    "        print(\"INTERNAL: Parsing response into ChatCompletion object...\")\n",
    "        return self._parse_response(raw_response)\n",
    "    \n",
    "    def _parse_response(self, raw_response: Dict[str, Any]) -> ChatCompletion:\n",
    "        \"\"\"Parse raw JSON response into ChatCompletion object\"\"\"\n",
    "        \n",
    "        print(\"INTERNAL: Parsing choices array...\")\n",
    "        choices = []\n",
    "        \n",
    "        for choice_data in raw_response[\"choices\"]:\n",
    "            message_data = choice_data[\"message\"]\n",
    "            \n",
    "            # Parse tool_calls if present\n",
    "            tool_calls = None\n",
    "            if \"tool_calls\" in message_data and message_data[\"tool_calls\"]:\n",
    "                print(f\"INTERNAL: Found {len(message_data['tool_calls'])} tool calls\")\n",
    "                tool_calls = []\n",
    "                \n",
    "                for tc_data in message_data[\"tool_calls\"]:\n",
    "                    print(f\"INTERNAL: Parsing tool call: {tc_data['function']['name']}\")\n",
    "                    \n",
    "                    # Create function object\n",
    "                    function = ChatCompletionToolCallFunction(\n",
    "                        name=tc_data[\"function\"][\"name\"],\n",
    "                        arguments=tc_data[\"function\"][\"arguments\"]  # Keep as JSON string!\n",
    "                    )\n",
    "                    \n",
    "                    # Create tool call object\n",
    "                    tool_call = ChatCompletionToolCall(\n",
    "                        id=tc_data[\"id\"],\n",
    "                        type=tc_data[\"type\"],\n",
    "                        function=function\n",
    "                    )\n",
    "                    \n",
    "                    tool_calls.append(tool_call)\n",
    "            \n",
    "            # Create message object\n",
    "            message = ChatCompletionMessage(\n",
    "                role=message_data[\"role\"],\n",
    "                content=message_data.get(\"content\"),\n",
    "                tool_calls=tool_calls\n",
    "            )\n",
    "            \n",
    "            # Create choice object\n",
    "            choice = ChatCompletionChoice(\n",
    "                index=choice_data[\"index\"],\n",
    "                message=message,\n",
    "                finish_reason=choice_data.get(\"finish_reason\")\n",
    "            )\n",
    "            \n",
    "            choices.append(choice)\n",
    "        \n",
    "        # Create main completion object\n",
    "        completion = ChatCompletion(\n",
    "            id=raw_response[\"id\"],\n",
    "            choices=choices,\n",
    "            created=raw_response[\"created\"],\n",
    "            model=raw_response[\"model\"],\n",
    "            object=raw_response[\"object\"]\n",
    "        )\n",
    "        \n",
    "        print(\"INTERNAL: ChatCompletion object created successfully\")\n",
    "        return completion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46e6386b-2f0c-456b-9254-bbbf1fa6ef67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chat:\n",
    "    \"\"\"Chat resource\"\"\"\n",
    "    \n",
    "    def __init__(self, http_client: HTTPClient):\n",
    "        self.completions = Completions(http_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "801f07ca-c325-4dd7-a0c7-5e86895d23ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenAI:\n",
    "    \"\"\"Main OpenAI client\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str = None, base_url: str = \"https://api.openai.com/v1\"):\n",
    "        if api_key is None:\n",
    "            import os\n",
    "            api_key = os.getenv(\"OPENAI_API_KEY\", \"dummy\")\n",
    "        \n",
    "        self._http_client = HTTPClient(api_key, base_url)\n",
    "        self.chat = Chat(self._http_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7430daaf-892f-43ab-8349-6d8d665ba5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def demo_internal_parsing():\n",
    "    \"\"\"Show how OpenAI library internally parses tool_calls\"\"\"\n",
    "    \n",
    "    print(\"OPENAI LIBRARY INTERNAL PARSING DEMO\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Mock raw response from API (what HTTP client receives)\n",
    "    raw_api_response = {\n",
    "        \"id\": \"chatcmpl-123\",\n",
    "        \"object\": \"chat.completion\",\n",
    "        \"created\": 1677652288,\n",
    "        \"model\": \"gpt-4\",\n",
    "        \"choices\": [\n",
    "            {\n",
    "                \"index\": 0,\n",
    "                \"message\": {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": None,\n",
    "                    \"tool_calls\": [\n",
    "                        {\n",
    "                            \"id\": \"call_abc123\",\n",
    "                            \"type\": \"function\",\n",
    "                            \"function\": {\n",
    "                                \"name\": \"get_weather\",\n",
    "                                \"arguments\": '{\"city\": \"Paris\", \"units\": \"celsius\"}'\n",
    "                            }\n",
    "                        },\n",
    "                        {\n",
    "                            \"id\": \"call_def456\", \n",
    "                            \"type\": \"function\",\n",
    "                            \"function\": {\n",
    "                                \"name\": \"calculate\",\n",
    "                                \"arguments\": '{\"expression\": \"15 + 25\"}'\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                \"finish_reason\": \"tool_calls\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    print(\"1. Raw API Response (JSON):\")\n",
    "    print(json.dumps(raw_api_response, indent=2))\n",
    "    \n",
    "    # Show internal parsing\n",
    "    completions = Completions(None)  # No HTTP client needed for parsing demo\n",
    "    completion = completions._parse_response(raw_api_response)\n",
    "    \n",
    "    print(\"\\n2. Parsed into Python objects:\")\n",
    "    print(f\"Completion ID: {completion.id}\")\n",
    "    print(f\"Model: {completion.model}\")\n",
    "    print(f\"Choices count: {len(completion.choices)}\")\n",
    "    \n",
    "    message = completion.choices[0].message\n",
    "    print(f\"Message role: {message.role}\")\n",
    "    print(f\"Message content: {message.content}\")\n",
    "    print(f\"Tool calls count: {len(message.tool_calls) if message.tool_calls else 0}\")\n",
    "    \n",
    "    # Show tool_calls access\n",
    "    if message.tool_calls:\n",
    "        print(\"\\n3. Accessing tool_calls:\")\n",
    "        for i, tool_call in enumerate(message.tool_calls):\n",
    "            print(f\"\\nTool Call {i+1}:\")\n",
    "            print(f\"  tool_call.id = '{tool_call.id}'\")\n",
    "            print(f\"  tool_call.type = '{tool_call.type}'\")\n",
    "            print(f\"  tool_call.function.name = '{tool_call.function.name}'\")\n",
    "            print(f\"  tool_call.function.arguments = '{tool_call.function.arguments}'\")\n",
    "            print(f\"  type(tool_call.function.arguments) = {type(tool_call.function.arguments)}\")\n",
    "            \n",
    "            # Show JSON parsing\n",
    "            args = json.loads(tool_call.function.arguments)\n",
    "            print(f\"  json.loads(arguments) = {args}\")\n",
    "            print(f\"  type(parsed_args) = {type(args)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cfb5383-676b-46bc-a0dc-446af28b5b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI LIBRARY INTERNAL PARSING DEMO\n",
      "==================================================\n",
      "1. Raw API Response (JSON):\n",
      "{\n",
      "  \"id\": \"chatcmpl-123\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1677652288,\n",
      "  \"model\": \"gpt-4\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": null,\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"id\": \"call_abc123\",\n",
      "            \"type\": \"function\",\n",
      "            \"function\": {\n",
      "              \"name\": \"get_weather\",\n",
      "              \"arguments\": \"{\\\"city\\\": \\\"Paris\\\", \\\"units\\\": \\\"celsius\\\"}\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"id\": \"call_def456\",\n",
      "            \"type\": \"function\",\n",
      "            \"function\": {\n",
      "              \"name\": \"calculate\",\n",
      "              \"arguments\": \"{\\\"expression\\\": \\\"15 + 25\\\"}\"\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"finish_reason\": \"tool_calls\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "INTERNAL: Parsing choices array...\n",
      "INTERNAL: Found 2 tool calls\n",
      "INTERNAL: Parsing tool call: get_weather\n",
      "INTERNAL: Parsing tool call: calculate\n",
      "INTERNAL: ChatCompletion object created successfully\n",
      "\n",
      "2. Parsed into Python objects:\n",
      "Completion ID: chatcmpl-123\n",
      "Model: gpt-4\n",
      "Choices count: 1\n",
      "Message role: assistant\n",
      "Message content: None\n",
      "Tool calls count: 2\n",
      "\n",
      "3. Accessing tool_calls:\n",
      "\n",
      "Tool Call 1:\n",
      "  tool_call.id = 'call_abc123'\n",
      "  tool_call.type = 'function'\n",
      "  tool_call.function.name = 'get_weather'\n",
      "  tool_call.function.arguments = '{\"city\": \"Paris\", \"units\": \"celsius\"}'\n",
      "  type(tool_call.function.arguments) = <class 'str'>\n",
      "  json.loads(arguments) = {'city': 'Paris', 'units': 'celsius'}\n",
      "  type(parsed_args) = <class 'dict'>\n",
      "\n",
      "Tool Call 2:\n",
      "  tool_call.id = 'call_def456'\n",
      "  tool_call.type = 'function'\n",
      "  tool_call.function.name = 'calculate'\n",
      "  tool_call.function.arguments = '{\"expression\": \"15 + 25\"}'\n",
      "  type(tool_call.function.arguments) = <class 'str'>\n",
      "  json.loads(arguments) = {'expression': '15 + 25'}\n",
      "  type(parsed_args) = <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "demo_internal_parsing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90394af4-c539-4f61-9fe9-eab3208d1f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_with_actual_client():\n",
    "    \"\"\"Demo using the recreated OpenAI client\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DEMO WITH RECREATED OPENAI CLIENT\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Use our recreated client (pointing to Ollama for demo)\n",
    "    client = OpenAI(\n",
    "        api_key=\"ollama\",\n",
    "        base_url=\"http://localhost:11434/v1\"\n",
    "    )\n",
    "    \n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_weather\",\n",
    "                \"description\": \"Get weather\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"city\": {\"type\": \"string\"}\n",
    "                    },\n",
    "                    \"required\": [\"city\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        # This shows the complete internal flow\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"llama3.2:1b\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": \"What's the weather in Tokyo?\"}\n",
    "            ],\n",
    "            tools=tools\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nResult type: {type(completion)}\")\n",
    "        print(f\"Message: {completion.choices[0].message.content}\")\n",
    "        \n",
    "        if completion.choices[0].message.tool_calls:\n",
    "            for tc in completion.choices[0].message.tool_calls:\n",
    "                print(f\"Tool call: {tc.function.name}({tc.function.arguments})\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error (expected if Ollama not running): {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50ce9fcf-fb54-4302-958b-1d73cbf9ea10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DEMO WITH RECREATED OPENAI CLIENT\n",
      "============================================================\n",
      "INTERNAL: Building request payload...\n",
      "INTERNAL: Request body keys: ['messages', 'model', 'tools']\n",
      "INTERNAL: Making HTTP request...\n",
      "INTERNAL: POST http://localhost:11434/v1/chat/completions\n",
      "INTERNAL: Headers: ['Authorization', 'Content-Type', 'User-Agent']\n",
      "INTERNAL: Parsing response into ChatCompletion object...\n",
      "INTERNAL: Parsing choices array...\n",
      "INTERNAL: Found 1 tool calls\n",
      "INTERNAL: Parsing tool call: get_weather\n",
      "INTERNAL: ChatCompletion object created successfully\n",
      "\n",
      "Result type: <class '__main__.ChatCompletion'>\n",
      "Message: \n",
      "Tool call: get_weather({\"city\":\"Tokyo\"})\n"
     ]
    }
   ],
   "source": [
    "# Show with actual client\n",
    "demo_with_actual_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40526672-3bdc-4c08-b98f-76760993f243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_key_implementation_details():\n",
    "    \"\"\"Show the key implementation details\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"KEY IMPLEMENTATION DETAILS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\"\"\n",
    "1. PYDANTIC MODELS:\n",
    "   - OpenAI uses Pydantic for type validation\n",
    "   - ChatCompletionToolCall, ChatCompletionMessage, etc.\n",
    "   - Automatic JSON parsing and validation\n",
    "\n",
    "2. ARGUMENTS HANDLING:\n",
    "   - arguments field is ALWAYS stored as string\n",
    "   - No automatic JSON parsing by the library\n",
    "   - You must call json.loads() yourself\n",
    "\n",
    "3. OBJECT HIERARCHY:\n",
    "   ChatCompletion\n",
    "   └── choices: List[ChatCompletionChoice]\n",
    "       └── message: ChatCompletionMessage\n",
    "           └── tool_calls: List[ChatCompletionToolCall]\n",
    "               └── function: ChatCompletionToolCallFunction\n",
    "                   ├── name: str\n",
    "                   └── arguments: str  # JSON string!\n",
    "\n",
    "4. PARSING FLOW:\n",
    "   Raw JSON → Pydantic models → Python objects\n",
    "   \n",
    "5. THE CRITICAL POINT:\n",
    "   tool_call.function.arguments is intentionally kept as a string\n",
    "   This allows the library to be agnostic about argument types\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27c4c66f-2358-429e-8732-40b7ed4dd073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "KEY IMPLEMENTATION DETAILS\n",
      "============================================================\n",
      "\n",
      "1. PYDANTIC MODELS:\n",
      "   - OpenAI uses Pydantic for type validation\n",
      "   - ChatCompletionToolCall, ChatCompletionMessage, etc.\n",
      "   - Automatic JSON parsing and validation\n",
      "\n",
      "2. ARGUMENTS HANDLING:\n",
      "   - arguments field is ALWAYS stored as string\n",
      "   - No automatic JSON parsing by the library\n",
      "   - You must call json.loads() yourself\n",
      "\n",
      "3. OBJECT HIERARCHY:\n",
      "   ChatCompletion\n",
      "   └── choices: List[ChatCompletionChoice]\n",
      "       └── message: ChatCompletionMessage\n",
      "           └── tool_calls: List[ChatCompletionToolCall]\n",
      "               └── function: ChatCompletionToolCallFunction\n",
      "                   ├── name: str\n",
      "                   └── arguments: str  # JSON string!\n",
      "\n",
      "4. PARSING FLOW:\n",
      "   Raw JSON → Pydantic models → Python objects\n",
      "\n",
      "5. THE CRITICAL POINT:\n",
      "   tool_call.function.arguments is intentionally kept as a string\n",
      "   This allows the library to be agnostic about argument types\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Show implementation details\n",
    "show_key_implementation_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0ddec5-2263-42de-8377-92b0f9620354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
