{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf998cdc-0e43-4f6b-a49e-356c2feb7227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp core.agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32ceb513-a7e0-4a12-b3db-0968785c69b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Failed to load config from /home/pranav-pc/projects/applied-GenAI-lab/agentic/configs/config.toml: SettingsConfig.__init__() got an unexpected keyword argument 'temperature'\n"
     ]
    }
   ],
   "source": [
    "# | export\n",
    "from typing import List, Dict, Any, Optional, Callable\n",
    "from dataclasses import dataclass, field\n",
    "from abc import ABC, abstractmethod\n",
    "import json\n",
    "from agentic.llms.client import LLMClient\n",
    "from agentic.configs.prompt_manager import get_system_prompt\n",
    "from agentic.configs.loader import get_model_config, get_settings_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "599b7390-c9c5-4b67-9d41-fa917fa2c50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@dataclass\n",
    "class Message:\n",
    "    role: str\n",
    "    content: str\n",
    "    tool_calls: Optional[List[Dict]] = None\n",
    "    tool_call_id: Optional[str] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AgentConfig:\n",
    "    name: str\n",
    "    instructions: str = \"\"\n",
    "    model: Optional[str] = None\n",
    "    tools: List[str] = field(default_factory=list)\n",
    "    temperature: float = 0.7\n",
    "    max_tokens: Optional[int] = None\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    \"\"\"Core Agent class with tool execution and conversation management\"\"\"\n",
    "    \n",
    "    def __init__(self, config: AgentConfig, llm_client: Optional[LLMClient] = None):\n",
    "        self.config = config\n",
    "        self.llm_client = llm_client or self._create_default_llm_client()\n",
    "        self.conversation_history: List[Message] = []\n",
    "        self.tools_registry: Dict[str, Callable] = {}\n",
    "        self.guardrails: List[Callable] = []\n",
    "        \n",
    "        # Initialize with system message\n",
    "        system_prompt = config.instructions or get_system_prompt()\n",
    "        self.conversation_history.append(Message(role=\"system\", content=system_prompt))\n",
    "    \n",
    "    def _create_default_llm_client(self) -> LLMClient:\n",
    "        \"\"\"Create default LLM client from config\"\"\"\n",
    "        model_config = get_model_config()\n",
    "        return LLMClient(\n",
    "            model=self.config.model or model_config.get('name'),\n",
    "            base_url=model_config.get('url'),\n",
    "            api_key=model_config.get('api_key')\n",
    "        )\n",
    "    \n",
    "    def add_tool(self, name: str, tool_func: Callable):\n",
    "        \"\"\"Register a tool with the agent\"\"\"\n",
    "        self.tools_registry[name] = tool_func\n",
    "    \n",
    "    def add_guardrail(self, guardrail_func: Callable):\n",
    "        \"\"\"Add a guardrail function\"\"\"\n",
    "        self.guardrails.append(guardrail_func)\n",
    "    \n",
    "    def run(self, message: str, **kwargs) -> Dict[str, Any]:\n",
    "        \"\"\"Execute agent with message and return response\"\"\"\n",
    "        # Apply guardrails\n",
    "        for guardrail in self.guardrails:\n",
    "            if not guardrail(message):\n",
    "                return {\"content\": \"Request blocked by guardrails\", \"blocked\": True}\n",
    "        \n",
    "        # Add user message\n",
    "        self.conversation_history.append(Message(role=\"user\", content=message))\n",
    "        \n",
    "        # Get available tools\n",
    "        available_tools = self._get_available_tools()\n",
    "        \n",
    "        # Create completion\n",
    "        messages = self._format_messages_for_llm()\n",
    "        stream = kwargs.get('stream', True)\n",
    "        response = self.llm_client.create_completion(\n",
    "            messages=messages,\n",
    "            tools=available_tools,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "        # Process response based on streaming mode\n",
    "        if stream:\n",
    "            result = self.llm_client.handle_streaming_response(response)\n",
    "        else:\n",
    "            result = self.llm_client.process_response(response)\n",
    "        \n",
    "        # Execute tool calls if any\n",
    "        if result.get(\"tool_calls\"):\n",
    "            executed_calls = self._execute_tool_calls(result[\"tool_calls\"])\n",
    "            result[\"tool_calls\"] = executed_calls\n",
    "        \n",
    "        # Add to conversation history\n",
    "        assistant_message = Message(\n",
    "            role=\"assistant\", \n",
    "            content=result.get(\"content\", \"\"),\n",
    "            tool_calls=result.get(\"tool_calls\")\n",
    "        )\n",
    "        self.conversation_history.append(assistant_message)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _get_available_tools(self) -> List[Dict]:\n",
    "        \"\"\"Get OpenAI-formatted tools for the configured tool names\"\"\"\n",
    "        from agentic.tools.manager import ToolManager\n",
    "        tool_manager = ToolManager()\n",
    "        return tool_manager.get_tools(self.config.tools)\n",
    "    \n",
    "    def _execute_tool_calls(self, tool_calls: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Execute tool calls using registered tools\"\"\"\n",
    "        from agentic.tools.display import ToolExecutionDisplay\n",
    "        display = ToolExecutionDisplay()\n",
    "        \n",
    "        executed_calls = []\n",
    "        \n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call[\"function\"][\"name\"]\n",
    "            arguments = json.loads(tool_call[\"function\"][\"arguments\"])\n",
    "            \n",
    "            # Show tool execution start\n",
    "            display.show_tool_start(function_name, trusted=True)\n",
    "            \n",
    "            if function_name in self.tools_registry:\n",
    "                try:\n",
    "                    result = self.tools_registry[function_name](**arguments)\n",
    "                    tool_call[\"result\"] = result\n",
    "                    executed_calls.append(tool_call)\n",
    "                except Exception as e:\n",
    "                    tool_call[\"error\"] = str(e)\n",
    "                    display.show_tool_error(f\"Error in {function_name}\", str(e))\n",
    "                    executed_calls.append(tool_call)\n",
    "            else:\n",
    "                from ..tools.core import ToolManager\n",
    "                tool_manager = ToolManager()\n",
    "                try:\n",
    "                    result = tool_manager.execute_tool(function_name, arguments)\n",
    "                    tool_call[\"result\"] = result\n",
    "                    executed_calls.append(tool_call)\n",
    "                except Exception as e:\n",
    "                    tool_call[\"error\"] = str(e)\n",
    "                    display.show_tool_error(f\"Error in {function_name}\", str(e))\n",
    "                    executed_calls.append(tool_call)\n",
    "        \n",
    "        return executed_calls\n",
    "    \n",
    "    def _format_messages_for_llm(self) -> List[Dict]:\n",
    "        \"\"\"Convert Message objects to LLM format\"\"\"\n",
    "        messages = []\n",
    "        for msg in self.conversation_history:\n",
    "            message_dict = {\"role\": msg.role, \"content\": msg.content}\n",
    "            if msg.tool_calls:\n",
    "                message_dict[\"tool_calls\"] = msg.tool_calls\n",
    "            if msg.tool_call_id:\n",
    "                message_dict[\"tool_call_id\"] = msg.tool_call_id\n",
    "            messages.append(message_dict)\n",
    "        return messages\n",
    "    \n",
    "    def clear_history(self):\n",
    "        \"\"\"Clear conversation history except system message\"\"\"\n",
    "        system_msg = self.conversation_history[0]\n",
    "        self.conversation_history = [system_msg]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45bc8ad7-1a02-4194-b271-c72e442b4dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage \n",
    "config = AgentConfig(\n",
    "    name=\"demo_agent\",\n",
    "    instructions=\"You are a helpful assistant that can perform calculations.\",\n",
    "    tools=[]\n",
    ")\n",
    "\n",
    "agent = Agent(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce10cde5-5b75-4d92-b4d0-3ab931b7b6ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BaseTool.__init__() missing 1 required positional argument: 'metadata'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m agent.add_tool(\u001b[33m\"\u001b[39m\u001b[33mcalculator\u001b[39m\u001b[33m\"\u001b[39m, calculator)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Test the agent\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m response = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCalculate 15 + 25\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mResponse: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.get(\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mNo content\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 62\u001b[39m, in \u001b[36mAgent.run\u001b[39m\u001b[34m(self, message, **kwargs)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28mself\u001b[39m.conversation_history.append(Message(role=\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, content=message))\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Get available tools\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m available_tools = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_available_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# Create completion\u001b[39;00m\n\u001b[32m     65\u001b[39m messages = \u001b[38;5;28mself\u001b[39m._format_messages_for_llm()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 97\u001b[39m, in \u001b[36mAgent._get_available_tools\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Get OpenAI-formatted tools for the configured tool names\"\"\"\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magentic\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmanager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ToolManager\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m tool_manager = \u001b[43mToolManager\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tool_manager.get_tools(\u001b[38;5;28mself\u001b[39m.config.tools)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/applied-GenAI-lab/agentic/tools/manager.py:32\u001b[39m, in \u001b[36mToolManager.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mself\u001b[39m.registry = ToolRegistry()\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_register_default_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/applied-GenAI-lab/agentic/tools/manager.py:45\u001b[39m, in \u001b[36mToolManager._register_default_tools\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_register_default_tools\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     35\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Register all default tools\"\"\"\u001b[39;00m\n\u001b[32m     36\u001b[39m     default_tools = [\n\u001b[32m     37\u001b[39m         \u001b[38;5;66;03m# Filesystem tools\u001b[39;00m\n\u001b[32m     38\u001b[39m         FsReadTool(),\n\u001b[32m     39\u001b[39m         FsWriteTool(),\n\u001b[32m     40\u001b[39m         \n\u001b[32m     41\u001b[39m         \u001b[38;5;66;03m# System tools\u001b[39;00m\n\u001b[32m     42\u001b[39m         \u001b[38;5;66;03m# ExecuteBashTool(),\u001b[39;00m\n\u001b[32m     43\u001b[39m         \n\u001b[32m     44\u001b[39m         \u001b[38;5;66;03m# Analysis tools\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m         \u001b[43mCodeInterpreterTool\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     46\u001b[39m         CodeQualityTool(),\n\u001b[32m     47\u001b[39m         \n\u001b[32m     48\u001b[39m         \u001b[38;5;66;03m# Intelligence tools\u001b[39;00m\n\u001b[32m     49\u001b[39m         IntrospectTool(),\n\u001b[32m     50\u001b[39m         DebateAgentTool(),\n\u001b[32m     51\u001b[39m         MemoryTool(),\n\u001b[32m     52\u001b[39m         \n\u001b[32m     53\u001b[39m         \u001b[38;5;66;03m# Planning tools\u001b[39;00m\n\u001b[32m     54\u001b[39m         TaskPlannerTool(),\n\u001b[32m     55\u001b[39m         TaskExecutorTool(),\n\u001b[32m     56\u001b[39m         TaskMonitorTool(),\n\u001b[32m     57\u001b[39m \n\u001b[32m     58\u001b[39m         \n\u001b[32m     59\u001b[39m         \u001b[38;5;66;03m# Utility tools\u001b[39;00m\n\u001b[32m     60\u001b[39m         DocGeneratorTool(),\n\u001b[32m     61\u001b[39m     ]\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m default_tools:\n\u001b[32m     64\u001b[39m         \u001b[38;5;28mself\u001b[39m.registry.register_tool(tool)\n",
      "\u001b[31mTypeError\u001b[39m: BaseTool.__init__() missing 1 required positional argument: 'metadata'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Add a simple tool\n",
    "def calculator(operation: str, a: float, b: float) -> dict:\n",
    "    \"\"\"Simple calculator tool\"\"\"\n",
    "    if operation == \"add\":\n",
    "        result = a + b\n",
    "    elif operation == \"subtract\":\n",
    "        result = a - b\n",
    "    elif operation == \"multiply\":\n",
    "        result = a * b\n",
    "    elif operation == \"divide\":\n",
    "        result = a / b if b != 0 else \"Error: Division by zero\"\n",
    "    else:\n",
    "        result = \"Error: Unknown operation\"\n",
    "    \n",
    "    return {\"result\": result, \"operation\": operation, \"inputs\": [a, b]}\n",
    "\n",
    "# Register the tool\n",
    "agent.add_tool(\"calculator\", calculator)\n",
    "\n",
    "# Test the agent\n",
    "response = agent.run(\"Calculate 15 + 25\")\n",
    "print(f\"Response: {response.get('content', 'No content')}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f281e2e-f074-45a4-8b5d-67de5e995c41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
