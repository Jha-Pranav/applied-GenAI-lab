{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a855603-179f-4778-89a2-81554cdc4f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp frontend.client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e69436c-61af-41aa-941b-c6121f1c8c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "from openai import OpenAI\n",
    "from agentic.backend.tools import ToolManager\n",
    "from agentic.backend.schemas import ToolCall, FsReadParams, FsWriteParams, ExecuteBashParams, IntrospectParams, TodoParams\n",
    "from pydantic import ValidationError\n",
    "from typing import List, Dict, Any, Optional\n",
    "from agentic.configs.prompts import SYSTEM_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be75ef93-d99a-4a64-9772-5cc9b2ef05bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "PINK = \"\\033[38;2;255;182;193m\"  # RGB: Light pink\n",
    "RESET = \"\\033[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25d2b75-112d-4256-80ec-cb029ebbd785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buddy CLI with enhanced OpenAI tool calling\n",
      "Commands: /clear (clear history), /history (show history), /quit (exit)\n",
      "Type your message or command:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  Hello, how are you ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ==========================================================================================\n",
      "\u001b[38;2;255;182;193mThe\u001b[0m\u001b[38;2;255;182;193m user\u001b[0m\u001b[38;2;255;182;193m says\u001b[0m\u001b[38;2;255;182;193m hello\u001b[0m\u001b[38;2;255;182;193m.\u001b[0m\u001b[38;2;255;182;193m I\u001b[0m\u001b[38;2;255;182;193m should\u001b[0m\u001b[38;2;255;182;193m respond\u001b[0m\u001b[38;2;255;182;193m as\u001b[0m\u001b[38;2;255;182;193m Buddy\u001b[0m\u001b[38;2;255;182;193m.\u001b[0m\u001b[38;2;255;182;193m Use\u001b[0m\u001b[38;2;255;182;193m friendly\u001b[0m\u001b[38;2;255;182;193m tone\u001b[0m\u001b[38;2;255;182;193m.\u001b[0m\n",
      " ==========================================================================================\n",
      "Hey! I'm doing great—ready to help you with whatever you need. How can I assist you today?\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  what's the project parent dir ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ==========================================================================================\n",
      "\u001b[38;2;255;182;193mWe\u001b[0m\u001b[38;2;255;182;193m need\u001b[0m\u001b[38;2;255;182;193m to\u001b[0m\u001b[38;2;255;182;193m answer\u001b[0m\u001b[38;2;255;182;193m:\u001b[0m\u001b[38;2;255;182;193m what\u001b[0m\u001b[38;2;255;182;193m is\u001b[0m\u001b[38;2;255;182;193m the\u001b[0m\u001b[38;2;255;182;193m project\u001b[0m\u001b[38;2;255;182;193m parent\u001b[0m\u001b[38;2;255;182;193m directory\u001b[0m\u001b[38;2;255;182;193m.\u001b[0m\u001b[38;2;255;182;193m The\u001b[0m\u001b[38;2;255;182;193m current\u001b[0m\u001b[38;2;255;182;193m directory\u001b[0m\u001b[38;2;255;182;193m is\u001b[0m\u001b[38;2;255;182;193m /\u001b[0m\u001b[38;2;255;182;193mhome\u001b[0m\u001b[38;2;255;182;193m/pr\u001b[0m\u001b[38;2;255;182;193man\u001b[0m\u001b[38;2;255;182;193mav\u001b[0m\u001b[38;2;255;182;193m-p\u001b[0m\u001b[38;2;255;182;193mc\u001b[0m\u001b[38;2;255;182;193m/projects\u001b[0m\u001b[38;2;255;182;193m/ap\u001b[0m\u001b[38;2;255;182;193mplied\u001b[0m\u001b[38;2;255;182;193m-\u001b[0m\u001b[38;2;255;182;193mGen\u001b[0m\u001b[38;2;255;182;193mAI\u001b[0m\u001b[38;2;255;182;193m-l\u001b[0m\u001b[38;2;255;182;193mab\u001b[0m\u001b[38;2;255;182;193m/n\u001b[0m\u001b[38;2;255;182;193mbs\u001b[0m\u001b[38;2;255;182;193m/b\u001b[0m\u001b[38;2;255;182;193muddy\u001b[0m\u001b[38;2;255;182;193m/frontend\u001b[0m\u001b[38;2;255;182;193m.\u001b[0m\u001b[38;2;255;182;193m The\u001b[0m\u001b[38;2;255;182;193m parent\u001b[0m\u001b[38;2;255;182;193m dir\u001b[0m\u001b[38;2;255;182;193m would\u001b[0m\u001b[38;2;255;182;193m be\u001b[0m\u001b[38;2;255;182;193m /\u001b[0m\u001b[38;2;255;182;193mhome\u001b[0m\u001b[38;2;255;182;193m/pr\u001b[0m\u001b[38;2;255;182;193man\u001b[0m\u001b[38;2;255;182;193mav\u001b[0m\u001b[38;2;255;182;193m-p\u001b[0m\u001b[38;2;255;182;193mc\u001b[0m\u001b[38;2;255;182;193m/projects\u001b[0m\u001b[38;2;255;182;193m/ap\u001b[0m\u001b[38;2;255;182;193mplied\u001b[0m\u001b[38;2;255;182;193m-\u001b[0m\u001b[38;2;255;182;193mGen\u001b[0m\u001b[38;2;255;182;193mAI\u001b[0m\u001b[38;2;255;182;193m-l\u001b[0m\u001b[38;2;255;182;193mab\u001b[0m\u001b[38;2;255;182;193m/n\u001b[0m\u001b[38;2;255;182;193mbs\u001b[0m\u001b[38;2;255;182;193m/b\u001b[0m\u001b[38;2;255;182;193muddy\u001b[0m\u001b[38;2;255;182;193m.\u001b[0m\u001b[38;2;255;182;193m But\u001b[0m\u001b[38;2;255;182;193m maybe\u001b[0m\u001b[38;2;255;182;193m they\u001b[0m\u001b[38;2;255;182;193m want\u001b[0m\u001b[38;2;255;182;193m the\u001b[0m\u001b[38;2;255;182;193m root\u001b[0m\u001b[38;2;255;182;193m of\u001b[0m\u001b[38;2;255;182;193m the\u001b[0m\u001b[38;2;255;182;193m project\u001b[0m\u001b[38;2;255;182;193m,\u001b[0m\u001b[38;2;255;182;193m which\u001b[0m\u001b[38;2;255;182;193m might\u001b[0m\u001b[38;2;255;182;193m be\u001b[0m\u001b[38;2;255;182;193m applied\u001b[0m\u001b[38;2;255;182;193m-\u001b[0m\u001b[38;2;255;182;193mGen\u001b[0m\u001b[38;2;255;182;193mAI\u001b[0m\u001b[38;2;255;182;193m-l\u001b[0m\u001b[38;2;255;182;193mab\u001b[0m\u001b[38;2;255;182;193m.\u001b[0m\u001b[38;2;255;182;193m So\u001b[0m\u001b[38;2;255;182;193m the\u001b[0m\u001b[38;2;255;182;193m parent\u001b[0m\u001b[38;2;255;182;193m directory\u001b[0m\u001b[38;2;255;182;193m of\u001b[0m\u001b[38;2;255;182;193m current\u001b[0m\u001b[38;2;255;182;193m dir\u001b[0m\u001b[38;2;255;182;193m is\u001b[0m\u001b[38;2;255;182;193m /\u001b[0m\u001b[38;2;255;182;193mhome\u001b[0m\u001b[38;2;255;182;193m/pr\u001b[0m\u001b[38;2;255;182;193man\u001b[0m\u001b[38;2;255;182;193mav\u001b[0m\u001b[38;2;255;182;193m-p\u001b[0m\u001b[38;2;255;182;193mc\u001b[0m\u001b[38;2;255;182;193m/projects\u001b[0m\u001b[38;2;255;182;193m/ap\u001b[0m\u001b[38;2;255;182;193mplied\u001b[0m\u001b[38;2;255;182;193m-\u001b[0m\u001b[38;2;255;182;193mGen\u001b[0m\u001b[38;2;255;182;193mAI\u001b[0m\u001b[38;2;255;182;193m-l\u001b[0m\u001b[38;2;255;182;193mab\u001b[0m\u001b[38;2;255;182;193m/n\u001b[0m\u001b[38;2;255;182;193mbs\u001b[0m\u001b[38;2;255;182;193m/b\u001b[0m\u001b[38;2;255;182;193muddy\u001b[0m\u001b[38;2;255;182;193m.\u001b[0m\u001b[38;2;255;182;193m The\u001b[0m\u001b[38;2;255;182;193m project's\u001b[0m\u001b[38;2;255;182;193m root\u001b[0m\u001b[38;2;255;182;193m likely\u001b[0m\u001b[38;2;255;182;193m /\u001b[0m\u001b[38;2;255;182;193mhome\u001b[0m\u001b[38;2;255;182;193m/pr\u001b[0m\u001b[38;2;255;182;193man\u001b[0m\u001b[38;2;255;182;193mav\u001b[0m\u001b[38;2;255;182;193m-p\u001b[0m\u001b[38;2;255;182;193mc\u001b[0m\u001b[38;2;255;182;193m/projects\u001b[0m\u001b[38;2;255;182;193m/ap\u001b[0m\u001b[38;2;255;182;193mplied\u001b[0m\u001b[38;2;255;182;193m-\u001b[0m\u001b[38;2;255;182;193mGen\u001b[0m\u001b[38;2;255;182;193mAI\u001b[0m\u001b[38;2;255;182;193m-l\u001b[0m\u001b[38;2;255;182;193mab\u001b[0m\u001b[38;2;255;182;193m.\u001b[0m\u001b[38;2;255;182;193m I'd\u001b[0m\u001b[38;2;255;182;193m answer\u001b[0m\u001b[38;2;255;182;193m that\u001b[0m\u001b[38;2;255;182;193m.\u001b[0m\n",
      " ==========================================================================================\n",
      "Your current directory is:\n",
      "\n",
      "```\n",
      "/home/pranav-pc/projects/applied-GenAI-lab/nbs/buddy/frontend\n",
      "```\n",
      "\n",
      "So the immediate parent directory is:\n",
      "\n",
      "```\n",
      "/home/pranav-pc/projects/applied-GenAI-lab/nbs/buddy\n",
      "```\n",
      "\n",
      "If by “project root” you mean the top‑level folder that contains everything, that would be:\n",
      "\n",
      "```\n",
      "/home/pranav-pc/projects/applied-GenAI-lab\n",
      "```\n",
      "\n",
      "Let me know if you need anything else!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# | export\n",
    "class BuddyClient:\n",
    "    def __init__(self, model=\"gpt-oss:20b\", base_url=None, api_key=None):\n",
    "        # Auto-detect base URL from environment or default\n",
    "        if base_url is None:\n",
    "            base_url = os.getenv('OLLAMA_BASE_URL', 'http://localhost:11434/v1')\n",
    "        # Support both OpenAI and Ollama\n",
    "        if base_url == \"openai\":\n",
    "            # Use OpenAI directly\n",
    "            self.client = OpenAI(api_key=api_key)\n",
    "            self.model = model if model != \"gpt-oss:20b\" else \"gpt-4\"\n",
    "        else:\n",
    "            # Use Ollama or other OpenAI-compatible endpoint\n",
    "            self.client = OpenAI(\n",
    "                base_url=base_url,\n",
    "                api_key=api_key or \"ollama\", \n",
    "                timeout=300.0 # 5 minutes\n",
    "            )\n",
    "            self.model = model\n",
    "        \n",
    "        self.tool_manager = ToolManager()\n",
    "        self.auto_approve = False  # Session-wide auto-approval\n",
    "        self.conversation_history = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]  # Session history\n",
    "        \n",
    "    def chat(self, message, tools=None, stream=True):\n",
    "        \"\"\"Enhanced chat with OpenAI tool calling and Pydantic validation\"\"\"\n",
    "        if tools is None:\n",
    "            tools = [\"fs_read\", \"fs_write\", \"execute_bash\", \"introspect\", \"todo\"]\n",
    "        \n",
    "        # Add user message to history\n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": message})\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                # Get OpenAI-formatted tools\n",
    "                openai_tools = self.tool_manager.get_tools(tools)\n",
    "                \n",
    "                response = self.client.chat.completions.create(\n",
    "                    model=self.model,\n",
    "                    messages=self.conversation_history,\n",
    "                    tools=openai_tools,\n",
    "                    tool_choice=\"auto\",\n",
    "                    stream=stream,\n",
    "                    temperature=0.7\n",
    "                )\n",
    "                \n",
    "                if stream:\n",
    "                    result = self._handle_streaming_response(response)\n",
    "                else:\n",
    "                    result = self._process_response(response)\n",
    "                \n",
    "                # Add assistant response to history\n",
    "                assistant_message = {\"role\": \"assistant\", \"content\": result.get(\"content\", \"\")}\n",
    "                if result.get(\"tool_calls\"):\n",
    "                    assistant_message[\"tool_calls\"] = result[\"tool_calls\"]\n",
    "                self.conversation_history.append(assistant_message)\n",
    "                \n",
    "                # If no tool calls, conversation is complete\n",
    "                if not result.get(\"tool_calls\"):\n",
    "                    break\n",
    "                \n",
    "                # Add tool results to history\n",
    "                for tool_call in result.get(\"tool_calls\", []):\n",
    "                    if hasattr(tool_call, 'get') and tool_call.get(\"result\"):\n",
    "                        self.conversation_history.append({\n",
    "                            \"role\": \"tool\",\n",
    "                            \"tool_call_id\": tool_call.get(\"id\", \"\"),\n",
    "                            \"content\": str(tool_call[\"result\"])\n",
    "                        })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error in conversation: {e}\")\n",
    "                print(\"🔄 Attempting to continue...\")\n",
    "                continue\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def clear_history(self):\n",
    "        \"\"\"Clear conversation history\"\"\"\n",
    "        self.conversation_history = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
    "        print(\"🗑️ Conversation history cleared\")\n",
    "    \n",
    "    def show_history(self):\n",
    "        \"\"\"Show conversation history\"\"\"\n",
    "        print(\"\\n📜 Conversation History:\")\n",
    "        for i, msg in enumerate(self.conversation_history[1:], 1):  # Skip system message\n",
    "            role = msg[\"role\"].upper()\n",
    "            content = msg.get(\"content\", \"\")[:100] + \"...\" if len(msg.get(\"content\", \"\")) > 100 else msg.get(\"content\", \"\")\n",
    "            print(f\"{i}. {role}: {content}\")\n",
    "        print()\n",
    "    \n",
    "    def _handle_streaming_response(self, response):\n",
    "        \"\"\"Handle streaming response with proper tool call accumulation\"\"\"\n",
    "        full_content = \"\"\n",
    "        tool_calls = []\n",
    "        first_token = True\n",
    "        print('\\n', \"===\"*30)\n",
    "        for chunk in response:\n",
    "            if chunk.choices and chunk.choices[0].delta:\n",
    "                delta = chunk.choices[0].delta\n",
    "                \n",
    "                # Handle reasoning content\n",
    "                \n",
    "                if hasattr(delta, 'reasoning') and delta.reasoning:\n",
    "                    token = delta.reasoning\n",
    "                    full_content += token\n",
    "                    print(f\"{PINK}{token}{RESET}\", end=\"\", flush=True)\n",
    "\n",
    "                \n",
    "                \n",
    "                # Handle content\n",
    "                if hasattr(delta, 'content') and delta.content:\n",
    "                    if first_token:\n",
    "                        print('\\n', \"===\"*30)\n",
    "                        first_token = False\n",
    "                    content = delta.content\n",
    "                    full_content += content\n",
    "                    print(content, end=\"\", flush=True)\n",
    "                \n",
    "                # Handle tool calls\n",
    "                if hasattr(delta, 'tool_calls') and delta.tool_calls:\n",
    "                    for tool_call_delta in delta.tool_calls:\n",
    "                        if tool_call_delta.index is not None:\n",
    "                            # Ensure we have enough tool calls in our list\n",
    "                            while len(tool_calls) <= tool_call_delta.index:\n",
    "                                tool_calls.append({\n",
    "                                    \"id\": \"\",\n",
    "                                    \"type\": \"function\",\n",
    "                                    \"function\": {\"name\": \"\", \"arguments\": \"\"}\n",
    "                                })\n",
    "                            \n",
    "                            current_tool_call = tool_calls[tool_call_delta.index]\n",
    "                            \n",
    "                            if tool_call_delta.id:\n",
    "                                current_tool_call[\"id\"] = tool_call_delta.id\n",
    "                            \n",
    "                            if tool_call_delta.function:\n",
    "                                if tool_call_delta.function.name:\n",
    "                                    current_tool_call[\"function\"][\"name\"] = tool_call_delta.function.name\n",
    "                                if tool_call_delta.function.arguments:\n",
    "                                    current_tool_call[\"function\"][\"arguments\"] += tool_call_delta.function.arguments\n",
    "        \n",
    "        print()  # New line after streaming\n",
    "        \n",
    "        # Execute tool calls if any\n",
    "        executed_calls = []\n",
    "        if tool_calls:\n",
    "            executed_calls = self._execute_tool_calls(tool_calls)\n",
    "        \n",
    "        return {\"content\": full_content, \"tool_calls\": executed_calls}\n",
    "    \n",
    "\n",
    "    def _process_response(self, response):\n",
    "        \"\"\"Process non-streaming response with tool calls\"\"\"\n",
    "        message = response.choices[0].message\n",
    "        \n",
    "        if hasattr(message, 'content') and message.content:\n",
    "            print(message.content)\n",
    "        \n",
    "        if hasattr(message, 'tool_calls') and message.tool_calls:\n",
    "            tool_calls = []\n",
    "            for tool_call in message.tool_calls:\n",
    "                tool_calls.append({\n",
    "                    \"id\": tool_call.id,\n",
    "                    \"type\": tool_call.type,\n",
    "                    \"function\": {\n",
    "                        \"name\": tool_call.function.name,\n",
    "                        \"arguments\": tool_call.function.arguments\n",
    "                    }\n",
    "                })\n",
    "            \n",
    "            executed_calls = self._execute_tool_calls(tool_calls)\n",
    "            return {\"content\": message.content, \"tool_calls\": executed_calls}\n",
    "        \n",
    "        return {\"content\": message.content, \"tool_calls\": []}\n",
    "    \n",
    "    def _execute_tool_calls(self, tool_calls: List[Dict]):\n",
    "        \"\"\"Execute tool calls with Pydantic validation and user permission\"\"\"\n",
    "        executed_calls = []\n",
    "        \n",
    "        for tool_call in tool_calls:\n",
    "            try:\n",
    "                function_name = tool_call[\"function\"][\"name\"]\n",
    "                arguments_str = tool_call[\"function\"][\"arguments\"]\n",
    "                \n",
    "                # Parse arguments\n",
    "                try:\n",
    "                    arguments = json.loads(arguments_str)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"\\n⚠️ Invalid JSON in tool call: {e}\")\n",
    "                    print(\"🔄 Continuing with next operation...\")\n",
    "                    continue\n",
    "                \n",
    "                # Auto-fix common mode errors for fs_read\n",
    "                if function_name == \"fs_read\" and \"operations\" in arguments:\n",
    "                    for op in arguments[\"operations\"]:\n",
    "                        if \"mode\" in op:\n",
    "                            # Fix common incorrect modes\n",
    "                            mode = op[\"mode\"]\n",
    "                            if mode in [\"File\", \"file\", \"Read\", \"read\"]:\n",
    "                                op[\"mode\"] = \"Line\"\n",
    "                                print(f\"🔧 Auto-corrected mode '{mode}' to 'Line'\")\n",
    "                            elif mode in [\"List\", \"list\", \"Dir\", \"dir\"]:\n",
    "                                op[\"mode\"] = \"Directory\"\n",
    "                                print(f\"🔧 Auto-corrected mode '{mode}' to 'Directory'\")\n",
    "                            elif mode in [\"Find\", \"find\", \"Grep\", \"grep\"]:\n",
    "                                op[\"mode\"] = \"Search\"\n",
    "                                print(f\"🔧 Auto-corrected mode '{mode}' to 'Search'\")\n",
    "                \n",
    "                # Validate with Pydantic\n",
    "                validated_call = self._validate_tool_call(function_name, arguments)\n",
    "                if not validated_call:\n",
    "                    continue\n",
    "                \n",
    "                # Show command and get permission\n",
    "                if not self._get_permission(function_name, arguments):\n",
    "                    print(\"❌ Command cancelled\")\n",
    "                    continue\n",
    "                \n",
    "                # Execute the tool\n",
    "                result = self.tool_manager.execute_tool(function_name, arguments)\n",
    "                \n",
    "                # Format and display result\n",
    "                formatted_result = self._format_tool_result(function_name, result)\n",
    "                print(f\"✅ {formatted_result}\")\n",
    "                \n",
    "                # Store result for conversation continuity\n",
    "                tool_call[\"result\"] = result\n",
    "                executed_calls.append(tool_call)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"\\n⚠️ Tool execution error: {e}\")\n",
    "                print(\"🔄 Continuing with next operation...\")\n",
    "                continue\n",
    "        \n",
    "        return executed_calls\n",
    "    \n",
    "    def _get_permission(self, function_name: str, arguments: Dict[str, Any]) -> bool:\n",
    "        \"\"\"Get user permission before executing commands\"\"\"\n",
    "        if self.auto_approve:\n",
    "            return True\n",
    "        \n",
    "        # Generate command description\n",
    "        description = self._get_command_description(function_name, arguments)\n",
    "        command_preview = self._get_command_preview(function_name, arguments)\n",
    "        \n",
    "        print(f\"\\n🔧 About to execute: {function_name}\")\n",
    "        print(f\"📝 Command: {command_preview}\")\n",
    "        print(f\"💡 Description: {description}\")\n",
    "        \n",
    "        while True:\n",
    "            response = input(\"Execute? (y)es/(n)o/(t)rust always: \").lower().strip()\n",
    "            if response in ['y', 'yes']:\n",
    "                return True\n",
    "            elif response in ['n', 'no']:\n",
    "                return False\n",
    "            elif response in ['t', 'trust']:\n",
    "                self.auto_approve = True\n",
    "                print(\"✅ Auto-approval enabled for this session\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"Please enter 'y', 'n', or 't'\")\n",
    "    \n",
    "    def _get_command_description(self, function_name: str, arguments: Dict[str, Any]) -> str:\n",
    "        \"\"\"Generate one-sentence description of what the command does\"\"\"\n",
    "        if function_name == \"fs_read\":\n",
    "            ops = arguments.get(\"operations\", [])\n",
    "            if ops and ops[0].get(\"mode\") == \"Directory\":\n",
    "                return \"Lists files and directories in the specified path\"\n",
    "            elif ops and ops[0].get(\"mode\") == \"Line\":\n",
    "                return \"Reads the contents of a file\"\n",
    "            elif ops and ops[0].get(\"mode\") == \"Search\":\n",
    "                return f\"Searches for '{ops[0].get('pattern')}' in the specified file\"\n",
    "        elif function_name == \"fs_write\":\n",
    "            cmd = arguments.get(\"command\")\n",
    "            if cmd == \"create\":\n",
    "                return \"Creates a new file with the specified content\"\n",
    "            elif cmd == \"str_replace\":\n",
    "                return \"Replaces text in an existing file\"\n",
    "            elif cmd == \"append\":\n",
    "                return \"Adds content to the end of an existing file\"\n",
    "        elif function_name == \"execute_bash\":\n",
    "            return f\"Runs the bash command: {arguments.get('command')}\"\n",
    "        elif function_name == \"todo\":\n",
    "            action = arguments.get(\"action\")\n",
    "            if action == \"plan\":\n",
    "                return \"Breaks down a complex task into smaller steps\"\n",
    "            elif action == \"execute\":\n",
    "                return \"Executes the next step in the task plan\"\n",
    "        elif function_name == \"introspect\":\n",
    "            return \"Shows information about available CLI capabilities\"\n",
    "        \n",
    "        return \"Executes the specified operation\"\n",
    "    \n",
    "    def _get_command_preview(self, function_name: str, arguments: Dict[str, Any]) -> str:\n",
    "        \"\"\"Generate a preview of the actual command\"\"\"\n",
    "        if function_name == \"fs_read\":\n",
    "            ops = arguments.get(\"operations\", [])\n",
    "            if ops:\n",
    "                op = ops[0]\n",
    "                if op.get(\"mode\") == \"Directory\":\n",
    "                    return f\"ls {op.get('path', '.')}\"\n",
    "                elif op.get(\"mode\") == \"Line\":\n",
    "                    return f\"cat {op.get('path')}\"\n",
    "                elif op.get(\"mode\") == \"Search\":\n",
    "                    return f\"grep '{op.get('pattern')}' {op.get('path')}\"\n",
    "        elif function_name == \"fs_write\":\n",
    "            cmd = arguments.get(\"command\")\n",
    "            path = arguments.get(\"path\")\n",
    "            if cmd == \"create\":\n",
    "                return f\"echo 'content' > {path}\"\n",
    "            elif cmd == \"str_replace\":\n",
    "                return f\"sed -i 's/old/new/g' {path}\"\n",
    "            elif cmd == \"append\":\n",
    "                return f\"echo 'content' >> {path}\"\n",
    "        elif function_name == \"execute_bash\":\n",
    "            return arguments.get(\"command\", \"\")\n",
    "        elif function_name == \"todo\":\n",
    "            return f\"todo {arguments.get('action')} '{arguments.get('task')}'\"\n",
    "        elif function_name == \"introspect\":\n",
    "            return \"buddy --help\"\n",
    "        \n",
    "        return f\"{function_name}({', '.join(f'{k}={v}' for k, v in arguments.items())})\"\n",
    "    \n",
    "    def _validate_tool_call(self, function_name: str, arguments: Dict[str, Any]) -> bool:\n",
    "        \"\"\"Validate tool call parameters with Pydantic\"\"\"\n",
    "        try:\n",
    "            if function_name == \"fs_read\":\n",
    "                FsReadParams(**arguments)\n",
    "            elif function_name == \"fs_write\":\n",
    "                FsWriteParams(**arguments)\n",
    "            elif function_name == \"execute_bash\":\n",
    "                ExecuteBashParams(**arguments)\n",
    "            elif function_name == \"introspect\":\n",
    "                IntrospectParams(**arguments)\n",
    "            elif function_name == \"todo\":\n",
    "                TodoParams(**arguments)\n",
    "            else:\n",
    "                print(f\"\\n⚠️ Unknown tool: {function_name}\")\n",
    "                return False\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except ValidationError as e:\n",
    "            error_msg = str(e)\n",
    "            if \"Input should be 'Line', 'Directory' or 'Search'\" in error_msg:\n",
    "                print(f\"\\n⚠️ Invalid mode for {function_name}. Use 'Line' to read files, 'Directory' to list directories, 'Search' to find patterns.\")\n",
    "            else:\n",
    "                print(f\"\\n⚠️ Validation error for {function_name}: {e}\")\n",
    "            print(\"🔄 Continuing with next operation...\")\n",
    "            return False\n",
    "    \n",
    "    def _format_tool_result(self, function_name: str, result: Dict[str, Any]) -> str:\n",
    "        \"\"\"Format tool results for display\"\"\"\n",
    "        if \"error\" in result:\n",
    "            return f\"Error: {result['error']}\"\n",
    "        \n",
    "        if function_name == \"fs_read\":\n",
    "            if \"results\" in result:\n",
    "                formatted = []\n",
    "                for res in result[\"results\"]:\n",
    "                    if \"items\" in res:\n",
    "                        items = res[\"items\"]\n",
    "                        file_count = sum(1 for item in items if item.get('type') == 'file')\n",
    "                        dir_count = sum(1 for item in items if item.get('type') == 'directory')\n",
    "                        formatted.append(f\"Directory {res['path']}: {file_count} files, {dir_count} directories\")\n",
    "                    elif \"content\" in res:\n",
    "                        lines = len(res[\"content\"].split('\\n'))\n",
    "                        formatted.append(f\"File {res['path']}: {lines} lines\")\n",
    "                    elif \"matches\" in res:\n",
    "                        match_count = len(res[\"matches\"])\n",
    "                        formatted.append(f\"Search in {res['path']}: {match_count} matches\")\n",
    "                return \"; \".join(formatted)\n",
    "        \n",
    "        elif function_name == \"execute_bash\":\n",
    "            if \"stdout\" in result:\n",
    "                output = result[\"stdout\"].strip()\n",
    "                return f\"Exit {result.get('exit_status', 0)}: {output[:100]}{'...' if len(output) > 100 else ''}\"\n",
    "        \n",
    "        elif function_name == \"fs_write\":\n",
    "            if \"success\" in result:\n",
    "                return result[\"message\"]\n",
    "        \n",
    "        elif function_name == \"todo\":\n",
    "            if \"steps\" in result:\n",
    "                return f\"Created plan with {len(result['steps'])} steps\"\n",
    "            elif \"step\" in result:\n",
    "                return f\"Executed step: {result['step']['description']}\"\n",
    "        \n",
    "        return str(result)\n",
    "        \n",
    "\n",
    "\n",
    "# Jupyter-friendly main function\n",
    "def main(model=\"gpt-oss:20b\", base_url=\"http://localhost:11434/v1\", api_key=None, no_stream=False):\n",
    "    \"\"\"Enhanced interface with OpenAI tool calling (adapted for Jupyter)\"\"\"\n",
    "    \n",
    "    # Create a simple object with attributes similar to argparse.Namespace\n",
    "    class Args:\n",
    "        pass\n",
    "    \n",
    "    args = Args()\n",
    "    args.model = model\n",
    "    args.base_url = base_url\n",
    "    args.api_key = api_key\n",
    "    args.no_stream = no_stream\n",
    "\n",
    "    # Now create the client\n",
    "    client = BuddyClient(\n",
    "        model=args.model,\n",
    "        base_url=args.base_url,\n",
    "        api_key=args.api_key\n",
    "    )\n",
    "    \n",
    "\n",
    "    print(\"Buddy CLI with enhanced OpenAI tool calling\")\n",
    "    print(\"Commands: /clear (clear history), /history (show history), /quit (exit)\")\n",
    "    print(\"Type your message or command:\\n\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\">> \").strip()\n",
    "            \n",
    "            if user_input.lower() in ['quit', 'exit', '/quit']:\n",
    "                break\n",
    "            elif user_input.lower() in ['/clear']:\n",
    "                client.clear_history()\n",
    "                continue\n",
    "            elif user_input.lower() in ['/history']:\n",
    "                client.show_history()\n",
    "                continue\n",
    "                \n",
    "            if user_input:\n",
    "                client.chat(user_input, stream=not args.no_stream)\n",
    "                print()\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nGoodbye!\")\n",
    "            break\n",
    "\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132020bf-180a-449d-a34b-61fda82f6045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
