{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0a8d85e-2fde-4f0a-bb1f-c9dc4d3a4ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp backend.llms.response_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ca4b5be-b00f-43f9-a345-f64dde32304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export \n",
    "import json\n",
    "from typing import Dict, Any, Optional\n",
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "from agentic.configs.loader import get_reasoning_config\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37f36ffd-bc05-4230-8924-a6ed2d5db832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Failed to load config from /home/pranav-pc/projects/applied-GenAI-lab/agentic/configs/config.toml: SettingsConfig.__init__() got an unexpected keyword argument 'temperature'\n"
     ]
    }
   ],
   "source": [
    "# | export\n",
    "RESET = \"\\033[0m\"\n",
    "# Get reasoning config\n",
    "reasoning_config = get_reasoning_config()\n",
    "show_thinking = reasoning_config.get('show_thinking', True)\n",
    "thinking_color = reasoning_config.get('thinking_color', 'pink')\n",
    "\n",
    "# Set color based on config with enhanced colors\n",
    "color_codes = {\n",
    "            'pink': \"\\033[38;2;200;100;120m\",     # Darker pink\n",
    "            'blue': \"\\033[38;2;70;130;180m\",      # Steel blue\n",
    "            'green': \"\\033[38;2;60;179;113m\",     # Medium sea green\n",
    "            'yellow': \"\\033[38;2;204;204;0m\",     # Olive-like dark yellow\n",
    "            'purple': \"\\033[38;2;147;112;219m\",   # Medium purple\n",
    "            'cyan': \"\\033[38;2;0;139;139m\"        # Dark cyan\n",
    "        }\n",
    "\n",
    "\n",
    "color_code = color_codes.get(thinking_color.lower(), color_codes['green'])   \n",
    "def show_thinking_header():\n",
    "    \"\"\"Display beautiful thinking header\"\"\"\n",
    "    if show_thinking:\n",
    "        print(f\"\\n{color_code}â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ðŸ¤” Thinking â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®{RESET}\")\n",
    "\n",
    "def show_thinking_footer():\n",
    "    \"\"\"Display beautiful thinking footer\"\"\"\n",
    "    if show_thinking:\n",
    "        print(f\"{color_code}â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯{RESET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55116c87-ca9b-40f0-8d6f-99165ac8a133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class ResponseProcessor:\n",
    "    \"\"\"Handles processing of LLM responses\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.console = Console()\n",
    "    \n",
    "    def process_response(self, response: Any, console: Optional[Console] = None) -> Dict[str, Any]:\n",
    "        \"\"\"Process non-streaming response\"\"\"\n",
    "        if console is None:\n",
    "            console = self.console\n",
    "        \n",
    "        try:\n",
    "            message = response.choices[0].message\n",
    "            \n",
    "            cleaned_content = \"\"\n",
    "            if hasattr(message, 'reasoning') and message.reasoning:\n",
    "                show_thinking_header()\n",
    "                console.print(Markdown(message.reasoning))\n",
    "                show_thinking_footer()\n",
    "            if hasattr(message, 'content') and message.content:\n",
    "                content = message.content\n",
    "        \n",
    "                # Extract <think>...</think> content\n",
    "                think_matches = re.findall(r\"<think>(.*?)</think>\", content, re.DOTALL)\n",
    "        \n",
    "                # Remove <think>...</think> blocks from original content\n",
    "                cleaned_content = re.sub(r\"<think>.*?</think>\", \"\", content, flags=re.DOTALL)\n",
    "    \n",
    "                # Print each <think> block inside the fancy box\n",
    "                for think in think_matches:\n",
    "                    think = think.strip()\n",
    "                    if think:\n",
    "                        show_thinking_header()\n",
    "                        print(f\"{color_code}{think}{RESET}\")\n",
    "                        show_thinking_footer()\n",
    "        \n",
    "                # Print main message content\n",
    "                if cleaned_content.strip():\n",
    "                    console.print(Markdown(cleaned_content.strip()))\n",
    "            \n",
    "            # Extract tool calls\n",
    "            tool_calls = []\n",
    "            if hasattr(message, 'tool_calls') and message.tool_calls:\n",
    "                tool_calls = self._extract_tool_calls(message.tool_calls)\n",
    "            \n",
    "            return {\n",
    "                \"content\": cleaned_content,\n",
    "                \"tool_calls\": tool_calls,\n",
    "                \"usage\": getattr(response, 'usage', None),\n",
    "                \"model\": getattr(response, 'model', None)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            console.print(f\"[red]Error processing response: {e}[/red]\")\n",
    "            return {\"content\": \"\", \"tool_calls\": [], \"error\": str(e)}\n",
    "    \n",
    "    def _extract_tool_calls(self, tool_calls) -> list:\n",
    "        \"\"\"Extract tool calls from response\"\"\"\n",
    "        extracted_calls = []\n",
    "        \n",
    "        for tool_call in tool_calls:\n",
    "            try:\n",
    "                extracted_call = {\n",
    "                    \"id\": tool_call.id,\n",
    "                    \"type\": tool_call.type,\n",
    "                    \"function\": {\n",
    "                        \"name\": tool_call.function.name,\n",
    "                        \"arguments\": tool_call.function.arguments\n",
    "                    }\n",
    "                }\n",
    "                extracted_calls.append(extracted_call)\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting tool call: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return extracted_calls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aa69cc-187d-4768-b26d-916754d42479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f619a68f-8abd-48d0-b24f-d725b749d462",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
