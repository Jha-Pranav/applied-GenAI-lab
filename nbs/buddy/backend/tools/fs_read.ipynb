{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04126151-3813-4ca5-9fda-753c68482c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp backend.tools.fs_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52c52edd-e0f3-42d7-ad4f-363dc1f99710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "from agentic.backend.tools.base import Tool\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42c33336-2f83-40d3-9c1e-38b7213ceaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class FsReadTool(Tool):\n",
    "    def get_tool_schema(self) -> Dict[str, Any]:\n",
    "        \"\"\"Return the OpenAI-compatible schema for fs_read.\"\"\"\n",
    "        return {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"fs_read\",\n",
    "                \"description\": \"File system operations: read files with intelligent chunking, list directories with depth, search patterns, find files, grep across files, and generate tree structures.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"operations\": {\n",
    "                            \"type\": \"array\",\n",
    "                            \"items\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"mode\": {\n",
    "                                        \"type\": \"string\",\n",
    "                                        \"enum\": [\"Line\", \"Directory\", \"Search\", \"Find\", \"Grep\", \"Tree\"],\n",
    "                                        \"description\": \"Operation mode: Line (read file), Directory (list with depth), Search (pattern in file), Find (find files by name), Grep (search across files), Tree (directory tree)\"\n",
    "                                    },\n",
    "                                    \"path\": {\"type\": \"string\", \"description\": \"File or directory path\"},\n",
    "                                    \"pattern\": {\"type\": \"string\", \"description\": \"Search pattern for Search/Grep modes\"},\n",
    "                                    \"name_pattern\": {\"type\": \"string\", \"description\": \"File name pattern for Find mode\"},\n",
    "                                    \"file_pattern\": {\"type\": \"string\", \"description\": \"File pattern for Grep mode (e.g., '*.py')\"},\n",
    "                                    \"depth\": {\"type\": \"integer\", \"description\": \"Directory depth for Directory mode\"},\n",
    "                                    \"max_depth\": {\"type\": \"integer\", \"description\": \"Maximum depth for Find/Tree modes\"},\n",
    "                                    \"context_lines\": {\"type\": \"integer\", \"description\": \"Context lines around matches\"},\n",
    "                                    \"start_line\": {\"type\": \"integer\", \"description\": \"Start line for Line mode\"},\n",
    "                                    \"end_line\": {\"type\": \"integer\", \"description\": \"End line for Line mode (-1 for end)\"},\n",
    "                                    \"show_hidden\": {\"type\": \"boolean\", \"description\": \"Show hidden files/directories\"},\n",
    "                                    \"case_sensitive\": {\"type\": \"boolean\", \"description\": \"Case sensitive search\"},\n",
    "                                    \"recursive\": {\"type\": \"boolean\", \"description\": \"Recursive search for Grep mode\"},\n",
    "                                    \"file_type\": {\"type\": \"string\", \"enum\": [\"file\", \"dir\", \"all\"], \"description\": \"File type filter for Find mode\"},\n",
    "                                    \"smart_chunk\": {\"type\": \"boolean\", \"description\": \"Use intelligent chunking for large files\"}\n",
    "                                },\n",
    "                                \"required\": [\"mode\", \"path\"]\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"operations\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def execute(self, operations: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        \"\"\"Execute fs_read with intelligent chunking and advanced features.\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for op in operations:\n",
    "            mode = op.get(\"mode\")\n",
    "            path = op.get(\"path\")\n",
    "            \n",
    "            try:\n",
    "                if mode == \"Directory\":\n",
    "                    depth = op.get(\"depth\", 1)\n",
    "                    show_hidden = op.get(\"show_hidden\", False)\n",
    "                    items = self._list_directory_tree(path, depth, show_hidden)\n",
    "                    results.append({\"path\": path, \"items\": items, \"depth\": depth})\n",
    "                \n",
    "                elif mode == \"Line\":\n",
    "                    start_line = op.get(\"start_line\", 1)\n",
    "                    end_line = op.get(\"end_line\", -1)\n",
    "                    smart_chunk = op.get(\"smart_chunk\", True)\n",
    "                    content = self._read_file_intelligent(path, start_line, end_line, smart_chunk)\n",
    "                    results.append({\"path\": path, \"content\": content, \"start_line\": start_line, \"end_line\": end_line})\n",
    "                \n",
    "                elif mode == \"Search\":\n",
    "                    pattern = op.get(\"pattern\", \"\")\n",
    "                    context_lines = op.get(\"context_lines\", 2)\n",
    "                    case_sensitive = op.get(\"case_sensitive\", False)\n",
    "                    matches = self._search_in_file(path, pattern, context_lines, case_sensitive)\n",
    "                    results.append({\"path\": path, \"pattern\": pattern, \"matches\": matches})\n",
    "                \n",
    "                elif mode == \"Find\":\n",
    "                    name_pattern = op.get(\"name_pattern\", \"*\")\n",
    "                    file_type = op.get(\"file_type\", \"all\")\n",
    "                    max_depth = op.get(\"max_depth\", 10)\n",
    "                    found_items = self._find_files(path, name_pattern, file_type, max_depth)\n",
    "                    results.append({\"path\": path, \"name_pattern\": name_pattern, \"found\": found_items})\n",
    "                \n",
    "                elif mode == \"Grep\":\n",
    "                    pattern = op.get(\"pattern\", \"\")\n",
    "                    file_pattern = op.get(\"file_pattern\", \"*\")\n",
    "                    recursive = op.get(\"recursive\", True)\n",
    "                    context_lines = op.get(\"context_lines\", 2)\n",
    "                    matches = self._grep_files(path, pattern, file_pattern, recursive, context_lines)\n",
    "                    results.append({\"path\": path, \"pattern\": pattern, \"matches\": matches})\n",
    "                \n",
    "                elif mode == \"Tree\":\n",
    "                    max_depth = op.get(\"max_depth\", 3)\n",
    "                    show_hidden = op.get(\"show_hidden\", False)\n",
    "                    tree_structure = self._generate_tree(path, max_depth, show_hidden)\n",
    "                    results.append({\"path\": path, \"tree\": tree_structure})\n",
    "                \n",
    "            except Exception as e:\n",
    "                results.append({\"path\": path, \"error\": str(e)})\n",
    "        \n",
    "        return {\"results\": results}\n",
    "\n",
    "    def _get_file_info(self, path: str) -> Dict[str, Any]:\n",
    "        \"\"\"Get comprehensive file information for intelligent reading decisions.\"\"\"\n",
    "        path_obj = Path(path)\n",
    "        if not path_obj.exists():\n",
    "            return {\"error\": \"File not found\"}\n",
    "        \n",
    "        stat = path_obj.stat()\n",
    "        file_size = stat.st_size\n",
    "        \n",
    "        file_info = {\n",
    "            \"size\": file_size,\n",
    "            \"lines\": 0,\n",
    "            \"is_binary\": False,\n",
    "            \"encoding\": \"utf-8\",\n",
    "            \"file_type\": path_obj.suffix.lower(),\n",
    "            \"is_large\": file_size > 1024 * 1024,  # > 1MB\n",
    "            \"estimated_lines\": file_size // 50 if file_size > 0 else 0\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            with open(path, 'rb') as f:\n",
    "                chunk = f.read(1024)\n",
    "                if b'\\x00' in chunk:\n",
    "                    file_info[\"is_binary\"] = True\n",
    "                    return file_info\n",
    "        except:\n",
    "            file_info[\"is_binary\"] = True\n",
    "            return file_info\n",
    "        \n",
    "        try:\n",
    "            if file_size < 10 * 1024 * 1024:  # < 10MB\n",
    "                with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                    file_info[\"lines\"] = sum(1 for _ in f)\n",
    "            else:\n",
    "                with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                    sample_lines = sum(1 for _, line in zip(range(10000), f))\n",
    "                    file_info[\"lines\"] = int((file_size / (f.tell() or 1)) * sample_lines)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return file_info\n",
    "\n",
    "    def _decide_read_strategy(self, path: str, start_line: int, end_line: int, file_info: Dict) -> Dict[str, Any]:\n",
    "        \"\"\"Decide how to read the file based on size, type, and request.\"\"\"\n",
    "        strategy = {\n",
    "            \"method\": \"full\",\n",
    "            \"chunk_size\": 1000,\n",
    "            \"sample_ratio\": 0.1,\n",
    "            \"reason\": \"\"\n",
    "        }\n",
    "        \n",
    "        total_lines = file_info.get(\"lines\", 0)\n",
    "        file_size = file_info.get(\"size\", 0)\n",
    "        \n",
    "        if file_info.get(\"is_binary\"):\n",
    "            strategy.update({\"method\": \"binary_info\", \"reason\": \"Binary file detected\"})\n",
    "        elif file_size > 50 * 1024 * 1024:\n",
    "            strategy.update({\"method\": \"head_tail\", \"chunk_size\": 500, \"reason\": \"Very large file, showing head and tail\"})\n",
    "        elif total_lines > 10000 and (end_line - start_line + 1) > 5000:\n",
    "            strategy.update({\"method\": \"sampled\", \"sample_ratio\": 0.2, \"reason\": \"Large file with many requested lines\"})\n",
    "        elif total_lines > 5000 and (start_line == 1 and end_line == total_lines):\n",
    "            strategy.update({\"method\": \"chunked\", \"chunk_size\": 2000, \"reason\": \"Large file, full read requested\"})\n",
    "        elif (end_line - start_line + 1) > 2000:\n",
    "            strategy.update({\"method\": \"chunked\", \"chunk_size\": 1000, \"reason\": \"Many lines requested\"})\n",
    "        else:\n",
    "            strategy.update({\"method\": \"full\", \"reason\": \"Standard read\"})\n",
    "        \n",
    "        return strategy\n",
    "\n",
    "    def _read_file_intelligent(self, path: str, start_line: int = 1, end_line: int = -1, smart_chunk: bool = True) -> str:\n",
    "        \"\"\"Intelligently read file based on size and content type.\"\"\"\n",
    "        if not smart_chunk:\n",
    "            return self._read_file_lines(path, start_line, end_line)\n",
    "        \n",
    "        file_info = self._get_file_info(path)\n",
    "        if \"error\" in file_info:\n",
    "            return file_info[\"error\"]\n",
    "        \n",
    "        if file_info.get(\"is_binary\"):\n",
    "            return f\"[Binary file: {file_info['size']} bytes, type: {file_info.get('file_type', 'unknown')}]\"\n",
    "        \n",
    "        strategy = self._decide_read_strategy(path, start_line, end_line, file_info)\n",
    "        \n",
    "        try:\n",
    "            with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            total_lines = len(lines)\n",
    "            if end_line == -1:\n",
    "                end_line = total_lines\n",
    "            \n",
    "            start_idx = max(0, start_line - 1)\n",
    "            end_idx = min(total_lines, end_line)\n",
    "            \n",
    "            if strategy[\"method\"] == \"full\":\n",
    "                content = ''.join(lines[start_idx:end_idx])\n",
    "            \n",
    "            elif strategy[\"method\"] == \"chunked\":\n",
    "                chunk_size = strategy[\"chunk_size\"]\n",
    "                chunks = []\n",
    "                current_idx = start_idx\n",
    "                \n",
    "                while current_idx < end_idx:\n",
    "                    chunk_end = min(current_idx + chunk_size, end_idx)\n",
    "                    chunk = ''.join(lines[current_idx:chunk_end])\n",
    "                    chunks.append(f\"--- Lines {current_idx + 1}-{chunk_end} ---\\n{chunk}\")\n",
    "                    current_idx = chunk_end\n",
    "                    \n",
    "                    if len(chunks) >= 5:\n",
    "                        remaining = end_idx - current_idx\n",
    "                        if remaining > 0:\n",
    "                            chunks.append(f\"... [{remaining} more lines omitted] ...\")\n",
    "                        break\n",
    "                \n",
    "                content = '\\n'.join(chunks)\n",
    "            \n",
    "            elif strategy[\"method\"] == \"head_tail\":\n",
    "                chunk_size = strategy[\"chunk_size\"]\n",
    "                head = ''.join(lines[start_idx:start_idx + chunk_size])\n",
    "                tail = ''.join(lines[max(start_idx + chunk_size, end_idx - chunk_size):end_idx])\n",
    "                \n",
    "                omitted = end_idx - start_idx - (2 * chunk_size)\n",
    "                content = f\"--- Head (lines {start_idx + 1}-{start_idx + chunk_size}) ---\\n{head}\\n\"\n",
    "                if omitted > 0:\n",
    "                    content += f\"... [{omitted} lines omitted] ...\\n\"\n",
    "                content += f\"--- Tail (lines {end_idx - chunk_size + 1}-{end_idx}) ---\\n{tail}\"\n",
    "            \n",
    "            elif strategy[\"method\"] == \"sampled\":\n",
    "                sample_ratio = strategy[\"sample_ratio\"]\n",
    "                total_requested = end_idx - start_idx\n",
    "                sample_size = int(total_requested * sample_ratio)\n",
    "                \n",
    "                if sample_size < 100:\n",
    "                    sample_size = min(100, total_requested)\n",
    "                \n",
    "                step = max(1, total_requested // sample_size)\n",
    "                sampled_lines = []\n",
    "                \n",
    "                for i in range(start_idx, end_idx, step):\n",
    "                    if len(sampled_lines) >= sample_size:\n",
    "                        break\n",
    "                    sampled_lines.append(f\"{i + 1:6d}: {lines[i]}\")\n",
    "                \n",
    "                content = f\"--- Sampled {len(sampled_lines)} lines from {total_requested} total ---\\n\"\n",
    "                content += ''.join(sampled_lines)\n",
    "            \n",
    "            metadata = f\"\\n--- File Info: {file_info['size']} bytes, {file_info['lines']} lines, Strategy: {strategy['method']} ({strategy['reason']}) ---\"\n",
    "            return content + metadata\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error reading file: {str(e)}\"\n",
    "\n",
    "    def _read_file_lines(self, path: str, start_line: int, end_line: int) -> str:\n",
    "        \"\"\"Simple line-based file reading.\"\"\"\n",
    "        with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        if end_line == -1:\n",
    "            end_line = len(lines)\n",
    "        \n",
    "        start_idx = max(0, start_line - 1)\n",
    "        end_idx = min(len(lines), end_line)\n",
    "        \n",
    "        return ''.join(lines[start_idx:end_idx])\n",
    "\n",
    "    def _list_directory_tree(self, path: str, depth: int, show_hidden: bool) -> List[Dict]:\n",
    "        \"\"\"List directory with depth and metadata.\"\"\"\n",
    "        items = []\n",
    "        path_obj = Path(path)\n",
    "        \n",
    "        if not path_obj.exists() or not path_obj.is_dir():\n",
    "            return items\n",
    "            \n",
    "        def _scan_dir(dir_path: Path, current_depth: int) -> List[Dict]:\n",
    "            dir_items = []\n",
    "            if current_depth > depth:\n",
    "                return dir_items\n",
    "                \n",
    "            try:\n",
    "                for item in sorted(dir_path.iterdir()):\n",
    "                    if not show_hidden and item.name.startswith('.'):\n",
    "                        continue\n",
    "                        \n",
    "                    stat = item.stat()\n",
    "                    item_info = {\n",
    "                        \"name\": item.name,\n",
    "                        \"type\": \"directory\" if item.is_dir() else \"file\",\n",
    "                        \"size\": stat.st_size if item.is_file() else None,\n",
    "                        \"modified\": stat.st_mtime,\n",
    "                        \"permissions\": oct(stat.st_mode)[-3:],\n",
    "                        \"path\": str(item)\n",
    "                    }\n",
    "                    \n",
    "                    if item.is_dir() and current_depth < depth:\n",
    "                        item_info[\"children\"] = _scan_dir(item, current_depth + 1)\n",
    "                    \n",
    "                    dir_items.append(item_info)\n",
    "            except PermissionError:\n",
    "                pass\n",
    "                \n",
    "            return dir_items\n",
    "        \n",
    "        return _scan_dir(path_obj, 0)\n",
    "\n",
    "    def _search_in_file(self, path: str, pattern: str, context_lines: int, case_sensitive: bool) -> List[Dict]:\n",
    "        \"\"\"Search pattern in file with context.\"\"\"\n",
    "        matches = []\n",
    "        \n",
    "        try:\n",
    "            with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                lines = f.readlines()\n",
    "        except:\n",
    "            return matches\n",
    "        \n",
    "        search_pattern = pattern if case_sensitive else pattern.lower()\n",
    "        \n",
    "        for i, line in enumerate(lines):\n",
    "            search_line = line if case_sensitive else line.lower()\n",
    "            \n",
    "            if search_pattern in search_line:\n",
    "                start_ctx = max(0, i - context_lines)\n",
    "                end_ctx = min(len(lines), i + context_lines + 1)\n",
    "                \n",
    "                context = []\n",
    "                for j in range(start_ctx, end_ctx):\n",
    "                    context.append({\n",
    "                        \"line_number\": j + 1,\n",
    "                        \"content\": lines[j].rstrip(),\n",
    "                        \"is_match\": j == i\n",
    "                    })\n",
    "                \n",
    "                matches.append({\n",
    "                    \"line_number\": i + 1,\n",
    "                    \"content\": line.rstrip(),\n",
    "                    \"context\": context\n",
    "                })\n",
    "        \n",
    "        return matches\n",
    "\n",
    "    def _find_files(self, path: str, name_pattern: str, file_type: str, max_depth: int) -> List[Dict]:\n",
    "        \"\"\"Find files by name pattern.\"\"\"\n",
    "        found = []\n",
    "        path_obj = Path(path)\n",
    "        \n",
    "        def _search_recursive(dir_path: Path, current_depth: int):\n",
    "            if current_depth > max_depth:\n",
    "                return\n",
    "                \n",
    "            try:\n",
    "                for item in dir_path.iterdir():\n",
    "                    if fnmatch.fnmatch(item.name, name_pattern):\n",
    "                        if (file_type == \"all\" or \n",
    "                            (file_type == \"file\" and item.is_file()) or\n",
    "                            (file_type == \"dir\" and item.is_dir())):\n",
    "                            \n",
    "                            stat = item.stat()\n",
    "                            found.append({\n",
    "                                \"name\": item.name,\n",
    "                                \"path\": str(item),\n",
    "                                \"type\": \"directory\" if item.is_dir() else \"file\",\n",
    "                                \"size\": stat.st_size if item.is_file() else None,\n",
    "                                \"modified\": stat.st_mtime\n",
    "                            })\n",
    "                    \n",
    "                    if item.is_dir() and current_depth < max_depth:\n",
    "                        _search_recursive(item, current_depth + 1)\n",
    "            except PermissionError:\n",
    "                pass\n",
    "        \n",
    "        if path_obj.is_dir():\n",
    "            _search_recursive(path_obj, 0)\n",
    "        \n",
    "        return found\n",
    "\n",
    "    def _grep_files(self, path: str, pattern: str, file_pattern: str, recursive: bool, context_lines: int) -> List[Dict]:\n",
    "        \"\"\"Grep pattern across multiple files.\"\"\"\n",
    "        matches = []\n",
    "        path_obj = Path(path)\n",
    "        \n",
    "        def _grep_file(file_path: Path):\n",
    "            try:\n",
    "                file_matches = self._search_in_file(str(file_path), pattern, context_lines, False)\n",
    "                if file_matches:\n",
    "                    matches.append({\n",
    "                        \"file\": str(file_path),\n",
    "                        \"matches\": file_matches\n",
    "                    })\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        def _scan_directory(dir_path: Path):\n",
    "            try:\n",
    "                for item in dir_path.iterdir():\n",
    "                    if item.is_file() and fnmatch.fnmatch(item.name, file_pattern):\n",
    "                        _grep_file(item)\n",
    "                    elif item.is_dir() and recursive:\n",
    "                        _scan_directory(item)\n",
    "            except PermissionError:\n",
    "                pass\n",
    "        \n",
    "        if path_obj.is_file():\n",
    "            _grep_file(path_obj)\n",
    "        elif path_obj.is_dir():\n",
    "            _scan_directory(path_obj)\n",
    "        \n",
    "        return matches\n",
    "\n",
    "    def _generate_tree(self, path: str, max_depth: int, show_hidden: bool) -> str:\n",
    "        \"\"\"Generate tree-like directory structure.\"\"\"\n",
    "        tree_lines = []\n",
    "        path_obj = Path(path)\n",
    "        \n",
    "        def _build_tree(dir_path: Path, prefix: str, current_depth: int):\n",
    "            if current_depth > max_depth:\n",
    "                return\n",
    "                \n",
    "            try:\n",
    "                items = sorted(dir_path.iterdir(), key=lambda x: (x.is_file(), x.name.lower()))\n",
    "                if not show_hidden:\n",
    "                    items = [item for item in items if not item.name.startswith('.')]\n",
    "                \n",
    "                for i, item in enumerate(items):\n",
    "                    is_last = i == len(items) - 1\n",
    "                    current_prefix = \"└── \" if is_last else \"├── \"\n",
    "                    tree_lines.append(f\"{prefix}{current_prefix}{item.name}\")\n",
    "                    \n",
    "                    if item.is_dir() and current_depth < max_depth:\n",
    "                        next_prefix = prefix + (\"    \" if is_last else \"│   \")\n",
    "                        _build_tree(item, next_prefix, current_depth + 1)\n",
    "            except PermissionError:\n",
    "                tree_lines.append(f\"{prefix}└── [Permission Denied]\")\n",
    "        \n",
    "        tree_lines.append(str(path_obj))\n",
    "        if path_obj.is_dir():\n",
    "            _build_tree(path_obj, \"\", 0)\n",
    "        \n",
    "        return \"\\n\".join(tree_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324d7e7c-009f-434e-aea8-c777d5379173",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
