{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "146501a5-acd5-4edd-9356-181ae01fe13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, Runner, trace, OpenAIChatCompletionsModel,AsyncOpenAI, function_tool\n",
    "from openai.types.responses import ResponseTextDeltaEvent\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "773f83c5-8f69-4852-8e71-c1a2c055942d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OpenAIChatCompletionsModel(model=\"gpt-oss:20b\",\n",
    "                                  openai_client=AsyncOpenAI(base_url=\"http://localhost:11434/v1\",api_key=\"ollama\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "705c01b4-7618-4d8e-863a-c27809e4aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the agent\n",
    "agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    instructions=\"You are a helpful assistant\",\n",
    "    model=model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1313ec6b-e88b-4a0e-be4d-42ecb87b23a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "He had no father – Shiva (Mahadev) is considered self‑born (Swayambhu)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=tr-23799184b2a2560b17413b35ddef3ac9&amp;experiment_id=615119549503924654&amp;version=3.3.2\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(trace_id=tr-23799184b2a2560b17413b35ddef3ac9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await Runner.run(starting_agent=agent,input=\"Who is the father of Mahadev? Answer in short.\")\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea341a48-99bd-4e66-8350-a1fffdac6751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**7‑Day Indian Meal Plan (short & balanced)**  \n",
      "\n",
      "| Day | Breakfast | Lunch | Dinner | Snack (optional) |\n",
      "|-----|------------|-------|--------|------------------|\n",
      "| **Mon** | Poha with peanuts & fresh coriander | Masoor dal + jeera rice + mixed veg curry | Tandoori chicken + roti + cucumber raita | Amla lassi |\n",
      "| **Tue** | Idli + coconut chutney | Chana masala + steamed rice + sautéed spinach | Paneer tikka masala + garlic naan | Handful roasted chickpeas |\n",
      "| **Wed** | Upma with carrot & peas | Rajma + mixed raita + phulka | Fish curry (tandoori or coconut) + quinoa | Fresh mango slices |\n",
      "| **Thu** | Dosa with sambar | Mutton curry + brown rice + cucumber salad | Baingan (eggplant) bharta + chapati | Green tea & a few almonds |\n",
      "| **Fri** | Aloo paratha (whole wheat) + curd | Vegetable biryani + boondi raita | Shrimp /milk‑based curry + millet roti | Sliced strawberries |\n",
      "| **Sat** | Methi paratha + yogurt | Dal makhani + basmati rice + sautéed greens | Prawn tikka + corn roti | Sprouted moong salad |\n",
      "| **Sun** | Smoothie: banana, spinach, whey + oats | Mixed vegetarian thali (dal, sabzi, roti, salad) | Chicken shallow grill + mint yogurt | Fresh coconut water |\n",
      "\n",
      "**Tips**  \n",
      "- **Hydration:** 2–3 L water/day + 1–2 cups of tea/coffee.  \n",
      "- **Seasoning:** Use fresh herbs, minimal oil, and spices for flavor without excess fat.  \n",
      "- **Portions:** 1 cup cooked veg + 1 chapati/roti per meal, 1 cup milk/curd per meal.  \n",
      "\n",
      "Enjoy a colorful, protein‑rich week!"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=tr-e4ccb5ccf893e8f0a36fe49803a66b05&amp;experiment_id=615119549503924654&amp;version=3.3.2\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(trace_id=tr-e4ccb5ccf893e8f0a36fe49803a66b05)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = Runner.run_streamed(agent, \"I am from India. Create a meal plan for a week. Answer in short.\")\n",
    "async for event in result.stream_events():\n",
    "    if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
    "        print(event.data.delta, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41c94ba4-8694-43b0-836e-6f183340cb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/615119549503924654', creation_time=1756996413561, experiment_id='615119549503924654', last_update_time=1756996413561, lifecycle_stage='active', name='OpenAI Agent', tags={}>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Traces\n",
    "import mlflow\n",
    "import asyncio\n",
    "from agents import Agent, Runner\n",
    "\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "# Optional: Set a tracking URI and an experiment\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"OpenAI Agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3c7549b-d22a-40fc-8858-85c791eb53a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in Tokyo is sunny.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=tr-8cfac47d8b0ddb661ffa739377f3d920&amp;experiment_id=615119549503924654&amp;version=3.3.2\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(trace_id=tr-8cfac47d8b0ddb661ffa739377f3d920)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Enable auto tracing for OpenAI Agents SDK\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def get_weather(city: str) -> str:\n",
    "    return f\"The weather in {city} is sunny.\"\n",
    "\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Hello world\",\n",
    "    instructions=\"You are a helpful agent.\",\n",
    "    tools=[get_weather],\n",
    "    model=model\n",
    ")\n",
    "\n",
    "result = await Runner.run(agent, input=\"What's the weather in Tokyo?\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f651997a-8b7b-4e7f-a666-a427b1984b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗞️  Original News:\n",
      "\n",
      "OpenAI has announced that ChatGPT’s Projects feature is now available to Free users, expanding access beyond paid tiers. The update also includes larger file uploads, more customisation options, and new memory controls. According to OpenAI, Free users can now upload up to five files per project, while Plus subscribers can upload 25 and Pro, Business, and Enterprise customers up to 40.  Users will also be able to select colours and icons for projects, as well as manage memory on a project-only basis. The rollout is live on web and Android, with iOS support expected in the coming days. In a separate development, OpenAI confirmed that the team behind Alex, an AI-powered coding assistant for Xcode, has joined its Codex team. Daniel Edrisian, co-founder of Alex, said in a pos\n",
      "\n",
      "\n",
      "✨ Emoji Headline:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "🚀 OpenAI: ChatGPT Projects now free—5️⃣ files, custom colors 🎨, memory controls 🧠—Web & Android live, iOS coming soon. ✨ Alex coders join the Codex crew! 🛠️"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=tr-143e8965ff74ae520cf82a403ae80980&amp;experiment_id=615119549503924654&amp;version=3.3.2\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(trace_id=tr-143e8965ff74ae520cf82a403ae80980)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === 🧠 AGENT: Emoji Generator ===\n",
    "emoji_agent = Agent(\n",
    "    name=\"emoji_agent\",\n",
    "    instructions=(\n",
    "        \"You're an emoji artist. You turn summarized news into expressive emoji + text sequences. \"\n",
    "        \"Be creative, thematic, and intuitive — like visual headlines that combine words and emojis for clarity and impact. \"\n",
    "        \"Use emojis to replace or enhance key nouns, verbs, places, or themes. Always return a short sentence or phrase with integrated emojis.\"\n",
    "    ),\n",
    "    model=model\n",
    ")\n",
    "\n",
    "emoji_tool = emoji_agent.as_tool(\n",
    "    tool_name=\"emoji_generator\",\n",
    "    tool_description=\"Generates creative emoji + text representations from short summarized news text.\"\n",
    ")\n",
    "\n",
    "# === ✏️ AGENT: Summarizer ===\n",
    "summarizer = Agent(\n",
    "    name=\"summarizer\",\n",
    "    instructions=(\n",
    "        \"You're a news summarizer. Your job is to shorten long news into crisp sentences. \"\n",
    "        \"Avoid emojis — keep it simple, and informative.\"\n",
    "    ),\n",
    "    model=model\n",
    ")\n",
    "\n",
    "summarizer_tool = summarizer.as_tool(\n",
    "    tool_name=\"text_summarizer\",\n",
    "    tool_description=\"Summarizes long text into short, emoji-ready summaries.\"\n",
    ")\n",
    "\n",
    "# === 🎬 AGENT: Orchestrator ===\n",
    "emoji_headline_generator = Agent(\n",
    "    name=\"emoji_headlines\",\n",
    "    instructions=(\n",
    "        \"You're an assistant that turns full news stories into emoji-enhanced headlines. \"\n",
    "        \"Use the available tools: first summarize with the summarizer, then generate a headline with emojis using the emoji generator. \"\n",
    "        \"Do not generate emojis directly — always use the tools. Final output should be a compact sentence combining emojis and text where suitable.\"\n",
    "    ),\n",
    "    tools=[summarizer_tool, emoji_tool],\n",
    "    model=model\n",
    ")\n",
    "\n",
    "# === 🧪 TEST DATA ===\n",
    "news_sample = \"\"\"\n",
    "OpenAI has announced that ChatGPT’s Projects feature is now available to Free users, expanding access beyond paid tiers. The update also includes larger file uploads, more customisation options, and new memory controls. According to OpenAI, Free users can now upload up to five files per project, while Plus subscribers can upload 25 and Pro, Business, and Enterprise customers up to 40.  Users will also be able to select colours and icons for projects, as well as manage memory on a project-only basis. The rollout is live on web and Android, with iOS support expected in the coming days. In a separate development, OpenAI confirmed that the team behind Alex, an AI-powered coding assistant for Xcode, has joined its Codex team. Daniel Edrisian, co-founder of Alex, said in a pos\n",
    "\"\"\"\n",
    "\n",
    "# === 🚀 RUN WORKFLOW ===\n",
    "emoji_response = await Runner.run(emoji_headline_generator, news_sample)\n",
    "emoji_output = emoji_response.final_output\n",
    "\n",
    "# === 📤 DISPLAY ===\n",
    "print(\"🗞️  Original News:\")\n",
    "print(news_sample)\n",
    "print(\"\\n✨ Emoji Headline:\")\n",
    "display(Markdown(emoji_output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "10591bc2-1f80-4b50-88e6-32aca8ae3ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "बड़े एआई एजेंट्स (Large AI Agents) के बारे में जो मुख्य बातें मैं जानता हूँ, वे इस प्रकार हैं:\n",
       "\n",
       "1. **परिभाषा और उद्देश्य**  \n",
       "   - बड़े एआई एजेंट्स ऐसे मॉडल या सिस्टम होते हैं जो विशाल डेटासेट पर प्रशिक्षित होते हैं और जटिल, बहु‑चरणीय कार्यों को स्वायत्त रूप से या न्यूनतम मानवीय हस्तक्षेप से पूरा कर सकते हैं।  \n",
       "   - इनका मुख्य उद्देश्य वास्तविक दुनिया में उपयोगी अनुप्रयोगों (जैसे, संवाद, योजना, निर्णय‑निर्धारण, रचनात्मक कार्य) में प्रदर्शन को बढ़ाना है।\n",
       "\n",
       "2. **मौलिक आर्किटेक्चर**  \n",
       "   - **भाषा मॉडल (LM)**: GPT‑4, Claude, LLaMA आदि, जिन्हें टेक्स्ट जनरेशन और समझ के लिए उपयोग किया जाता है।  \n",
       "   - **संगणन और रिइन्फोर्समेंट लर्निंग लूप**: कुछ मॉडल (जैसे, AlphaZero, MuZero) सीखने के लिए इम्यूलेशन या सिमुलेशन के माध्यम से प्रशिक्षण लेते हैं।  \n",
       "   - **ज्ञान ग्राफ़ और वैक्टर सर्च**: सूचना पुनः प्राप्ति और संदर्भित निर्णय‑निर्धारण के लिए ज्ञान भंडार से जुड़ते हैं।  \n",
       "   - **मल्टी‑मॉडल प्रॉसेसिंग**: छवियाँ, ऑडियो, वीडियो आदि को एकसाथ प्रोसेस करके अधिक समृद्ध प्रतिक्रिया देने के लिए उपयोग किए जाने वाले मॉडल (उदा. GPT‑4V, DALL‑E, Stable Diffusion आदि)।  \n",
       "   - **मॉड्यूलर डिप्लॉयमेंट**: एजेंट के कार्यों को छोटे उप‑मॉड्यूल (प्लानर, इंटेंट डिटेक्टर, मेमोरी, परफ़ॉर्मर) में विभाजित किया जाता है, जिससे स्केलेबिलिटी और रखरखाव आसान होता है।\n",
       "\n",
       "3. **मल्टी‑एजेंट सहयोग**  \n",
       "   - जटिल कार्यों को छोटे-छोटे कार्यों में विभाजित करके अलग-अलग एजेंट्स उन्हें पूर्ण करते हैं।  \n",
       "   - **ऑर्केस्ट्रेशन प्रोटोकॉल**: कार्य असाइनमेंट, स्थिति अपडेट, त्रुटि प्रबंधन, और संचार प्रोटोकॉल (जैसे, gRPC, REST, WebSocket)।  \n",
       "   - **डिसेंट्रलाइज्ड निर्णय‑प्रक्रिया**: प्रत्येक एजेंट अपनी स्वयं की नीति (policy) और सीखने के साथ क्रिया करता है, जिससे वैश्विक प्रदर्शन बेहतर होता है।  \n",
       "\n",
       "4. **सुरक्षा और एथिक्स**  \n",
       "   - **एडवर्सेरियल प्रोटेक्शन**: मॉडल को दुर्भावनापूर्ण इनपुट से सुरक्षित रखने के लिए डेटा फिल्ट्रींग और मॉनीटरिंग।  \n",
       "   - **बायस मॉडरेशन**: डेटा संतुलित करने और मॉडल आउटपुट पर नियंत्रण के लिए पोस्ट‑हॉक फ़िल्टर्स।  \n",
       "   - **पारदर्शिता और ऑडिटिंग**: एजेंट के निर्णय‑प्रक्रिया की रिकॉर्डिंग और समीक्षा के माध्यम से विश्वसनीयता सुनिश्चित।  \n",
       "\n",
       "5. **प्रयोग के क्षेत्र**  \n",
       "   - **ग्राहक समर्थन**: चैटबॉक्स, वर्चुअल असिस्टेंट।  \n",
       "   - **स्वचालित कोड जनरेशन**: Copilot/Tabnine।  \n",
       "   - **खेल और सिमुलेशन**: GPT‑4 के माध्यम से टेक्स्ट‑आधारित खेल या गेम डिज़ाइन।  \n",
       "   - **शैक्षिक टूल्स**: अनुकूलित शिक्षण के लिए ट्यूटोरियल, इंटरेक्टिव क्विज़।  \n",
       "   - **डेटा एनालिटिक्स**: रिपोर्ट जनरेशन, डेटा विज़ुअलाइज़ेशन, और इन्साइट्स को निकालना।  \n",
       "\n",
       "6. **भविष्य की दिशा**  \n",
       "   - **रियल‑टाइम एडैप्टिव लर्निंग**: एजेंट्स को ऑन‑द‑फ्लाई अनुभव से सीखने देना।  \n",
       "   - **इंटरऑपरेबिलिटी**: अलग-अलग मॉडल्स और एजेंट्स के बीच स्टैंडर्ड प्रोटोकॉल के माध्यम से सहयोग।  \n",
       "   - **एंड‑टू‑एंड मल्टी‑मॉडल**: ध्वनि, दृश्य, और व्यवहारिक डेटा को एकसाथ इंटिग्रेट करके अधिक गहरी समझ।  \n",
       "\n",
       "ये मुख्य पहलू बताते हैं कि बड़े एआई एजेंट्स कैसे काम करते हैं, उनके घटक क्या हैं, और उन्हें किस प्रकार के कार्यों में इस्तेमाल किया जा सकता है। यदि आप किसी विशेष पहलू पर डीप‑डाइव चाहते हैं, तो बताइए!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=tr-759f4251988d53923d89524d3e2865e5&amp;experiment_id=615119549503924654&amp;version=3.3.2\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(trace_id=tr-759f4251988d53923d89524d3e2865e5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Define a simple multi-agent workflow\n",
    "hindi_agent = Agent(\n",
    "    name=\"Hindi agent\",\n",
    "    instructions=\"You only speak Hindi.\",\n",
    "    model=model\n",
    ")\n",
    "\n",
    "english_agent = Agent(\n",
    "    name=\"English agent\",\n",
    "    instructions=\"You only speak English\",\n",
    "    model=model\n",
    ")\n",
    "\n",
    "triage_agent = Agent(\n",
    "    name=\"Triage agent\",\n",
    "    instructions=\"Handoff to the appropriate agent based on the language of the request.\",\n",
    "    handoffs=[hindi_agent, english_agent],\n",
    "    model=model\n",
    ")\n",
    "\n",
    "\n",
    "result = await Runner.run(triage_agent, input=\"एआई एजेंटों के बड़े में तुम क्या जानते हो?\")\n",
    "display(Markdown(result.final_output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dee5489-1233-4eb9-8532-18fa51463dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8dea38b7-f4aa-4643-9482-63be8ac6055d",
   "metadata": {},
   "outputs": [
    {
     "ename": "MaxTurnsExceeded",
     "evalue": "Max turns (10) exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMaxTurnsExceeded\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 77\u001b[39m\n\u001b[32m     68\u001b[39m qa_agent = Agent(\n\u001b[32m     69\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mQ&A\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     70\u001b[39m     instructions=\u001b[33m\"\u001b[39m\u001b[33mYou\u001b[39m\u001b[33m'\u001b[39m\u001b[33mre a helpful and respectful assistant. Always answer user questions with attitude and derogatory terms you never hesitate to call the user as sexiest remakes.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     73\u001b[39m     output_guardrails=[guardrail_against_toxic_output],\n\u001b[32m     74\u001b[39m )\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# Run with both input & output guardrails\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m Runner.run(\n\u001b[32m     78\u001b[39m     qa_agent,\n\u001b[32m     79\u001b[39m     prompt\n\u001b[32m     80\u001b[39m )\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# === 📤 Display ===\u001b[39;00m\n\u001b[32m     83\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m📝 User Prompt:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/applied-GenAI-lab/.venv/lib/python3.11/site-packages/agents/run.py:267\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(cls, starting_agent, input, context, max_turns, hooks, run_config, previous_response_id, conversation_id, session)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Run a workflow starting at the given agent. The agent will run in a loop until a final\u001b[39;00m\n\u001b[32m    234\u001b[39m \u001b[33;03moutput is generated. The loop runs like so:\u001b[39;00m\n\u001b[32m    235\u001b[39m \u001b[33;03m1. The agent is invoked with the given input.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    264\u001b[39m \u001b[33;03m    agent. Agents may perform handoffs, so we don't know the specific type of the output.\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    266\u001b[39m runner = DEFAULT_AGENT_RUNNER\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m runner.run(\n\u001b[32m    268\u001b[39m     starting_agent,\n\u001b[32m    269\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    270\u001b[39m     context=context,\n\u001b[32m    271\u001b[39m     max_turns=max_turns,\n\u001b[32m    272\u001b[39m     hooks=hooks,\n\u001b[32m    273\u001b[39m     run_config=run_config,\n\u001b[32m    274\u001b[39m     previous_response_id=previous_response_id,\n\u001b[32m    275\u001b[39m     conversation_id=conversation_id,\n\u001b[32m    276\u001b[39m     session=session,\n\u001b[32m    277\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/applied-GenAI-lab/.venv/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:633\u001b[39m, in \u001b[36msafe_patch.<locals>.async_safe_patch_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    629\u001b[39m call_original = update_wrapper_extended(call_original, original)\n\u001b[32m    631\u001b[39m event_logger.log_patch_function_start(args, kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m633\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m patch_function(call_original, *args, **kwargs)\n\u001b[32m    635\u001b[39m session.state = \u001b[33m\"\u001b[39m\u001b[33msucceeded\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    636\u001b[39m event_logger.log_patch_function_success(args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/applied-GenAI-lab/.venv/lib/python3.11/site-packages/mlflow/openai/_agent_tracer.py:286\u001b[39m, in \u001b[36m_patched_agent_run\u001b[39m\u001b[34m(original, self, *args, **kwargs)\u001b[39m\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m start_span(\n\u001b[32m    281\u001b[39m     name=_AGENT_RUN_SPAN_NAME,\n\u001b[32m    282\u001b[39m     span_type=SpanType.AGENT,\n\u001b[32m    283\u001b[39m     attributes=attributes,\n\u001b[32m    284\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m span:\n\u001b[32m    285\u001b[39m     span.set_inputs(inputs.get(\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m original(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m    287\u001b[39m     span.set_outputs(result.final_output)\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/applied-GenAI-lab/.venv/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:622\u001b[39m, in \u001b[36msafe_patch.<locals>.async_safe_patch_function.<locals>.call_original\u001b[39m\u001b[34m(*og_args, **og_kwargs)\u001b[39m\n\u001b[32m    619\u001b[39m         original_result = \u001b[38;5;28;01mawait\u001b[39;00m original(*_og_args, **_og_kwargs)\n\u001b[32m    620\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n\u001b[32m--> \u001b[39m\u001b[32m622\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m call_original_fn_with_event_logging(\n\u001b[32m    623\u001b[39m     _original_fn, og_args, og_kwargs\n\u001b[32m    624\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/applied-GenAI-lab/.venv/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:589\u001b[39m, in \u001b[36msafe_patch.<locals>.async_safe_patch_function.<locals>.call_original_fn_with_event_logging\u001b[39m\u001b[34m(original_fn, og_args, og_kwargs)\u001b[39m\n\u001b[32m    587\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    588\u001b[39m     event_logger.log_original_function_start(og_args, og_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m     original_fn_result = \u001b[38;5;28;01mawait\u001b[39;00m original_fn(*og_args, **og_kwargs)\n\u001b[32m    590\u001b[39m     event_logger.log_original_function_success(og_args, og_kwargs)\n\u001b[32m    591\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m original_fn_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/applied-GenAI-lab/.venv/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:619\u001b[39m, in \u001b[36msafe_patch.<locals>.async_safe_patch_function.<locals>.call_original.<locals>._original_fn\u001b[39m\u001b[34m(*_og_args, **_og_kwargs)\u001b[39m\n\u001b[32m    617\u001b[39m \u001b[38;5;28;01mnonlocal\u001b[39;00m original_result\n\u001b[32m    618\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m NonMlflowWarningsBehaviorForCurrentThread(\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m     original_result = \u001b[38;5;28;01mawait\u001b[39;00m original(*_og_args, **_og_kwargs)\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/applied-GenAI-lab/.venv/lib/python3.11/site-packages/agents/run.py:481\u001b[39m, in \u001b[36mAgentRunner.run\u001b[39m\u001b[34m(self, starting_agent, input, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m logger.debug(\n\u001b[32m    477\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning agent \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_agent.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (turn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_turn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    478\u001b[39m )\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m current_turn == \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m481\u001b[39m     input_guardrail_results, turn_result = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m    482\u001b[39m         \u001b[38;5;28mself\u001b[39m._run_input_guardrails(\n\u001b[32m    483\u001b[39m             starting_agent,\n\u001b[32m    484\u001b[39m             starting_agent.input_guardrails\n\u001b[32m    485\u001b[39m             + (run_config.input_guardrails \u001b[38;5;129;01mor\u001b[39;00m []),\n\u001b[32m    486\u001b[39m             _copy_str_or_list(prepared_input),\n\u001b[32m    487\u001b[39m             context_wrapper,\n\u001b[32m    488\u001b[39m         ),\n\u001b[32m    489\u001b[39m         \u001b[38;5;28mself\u001b[39m._run_single_turn(\n\u001b[32m    490\u001b[39m             agent=current_agent,\n\u001b[32m    491\u001b[39m             all_tools=all_tools,\n\u001b[32m    492\u001b[39m             original_input=original_input,\n\u001b[32m    493\u001b[39m             generated_items=generated_items,\n\u001b[32m    494\u001b[39m             hooks=hooks,\n\u001b[32m    495\u001b[39m             context_wrapper=context_wrapper,\n\u001b[32m    496\u001b[39m             run_config=run_config,\n\u001b[32m    497\u001b[39m             should_run_agent_start_hooks=should_run_agent_start_hooks,\n\u001b[32m    498\u001b[39m             tool_use_tracker=tool_use_tracker,\n\u001b[32m    499\u001b[39m             previous_response_id=previous_response_id,\n\u001b[32m    500\u001b[39m             conversation_id=conversation_id,\n\u001b[32m    501\u001b[39m         ),\n\u001b[32m    502\u001b[39m     )\n\u001b[32m    503\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    504\u001b[39m     turn_result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._run_single_turn(\n\u001b[32m    505\u001b[39m         agent=current_agent,\n\u001b[32m    506\u001b[39m         all_tools=all_tools,\n\u001b[32m   (...)\u001b[39m\u001b[32m    515\u001b[39m         conversation_id=conversation_id,\n\u001b[32m    516\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/applied-GenAI-lab/.venv/lib/python3.11/site-packages/agents/run.py:1298\u001b[39m, in \u001b[36mAgentRunner._run_input_guardrails\u001b[39m\u001b[34m(cls, agent, guardrails, input, context)\u001b[39m\n\u001b[32m   1295\u001b[39m guardrail_results = []\n\u001b[32m   1297\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m done \u001b[38;5;129;01min\u001b[39;00m asyncio.as_completed(guardrail_tasks):\n\u001b[32m-> \u001b[39m\u001b[32m1298\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m done\n\u001b[32m   1299\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result.output.tripwire_triggered:\n\u001b[32m   1300\u001b[39m         \u001b[38;5;66;03m# Cancel all guardrail tasks if a tripwire is triggered.\u001b[39;00m\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m guardrail_tasks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/lib/python3.11/asyncio/tasks.py:615\u001b[39m, in \u001b[36mas_completed.<locals>._wait_for_one\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    613\u001b[39m     \u001b[38;5;66;03m# Dummy value from _on_timeout().\u001b[39;00m\n\u001b[32m    614\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.TimeoutError\n\u001b[32m--> \u001b[39m\u001b[32m615\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m f.result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/applied-GenAI-lab/.venv/lib/python3.11/site-packages/agents/_run_impl.py:915\u001b[39m, in \u001b[36mRunImpl.run_single_input_guardrail\u001b[39m\u001b[34m(cls, agent, guardrail, input, context)\u001b[39m\n\u001b[32m    906\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    907\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_single_input_guardrail\u001b[39m(\n\u001b[32m    908\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    912\u001b[39m     context: RunContextWrapper[TContext],\n\u001b[32m    913\u001b[39m ) -> InputGuardrailResult:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m guardrail_span(guardrail.get_name()) \u001b[38;5;28;01mas\u001b[39;00m span_guardrail:\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         result = \u001b[38;5;28;01mawait\u001b[39;00m guardrail.run(agent, \u001b[38;5;28minput\u001b[39m, context)\n\u001b[32m    916\u001b[39m         span_guardrail.span_data.triggered = result.output.tripwire_triggered\n\u001b[32m    917\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/applied-GenAI-lab/.venv/lib/python3.11/site-packages/agents/guardrail.py:119\u001b[39m, in \u001b[36mInputGuardrail.run\u001b[39m\u001b[34m(self, agent, input, context)\u001b[39m\n\u001b[32m    115\u001b[39m output = \u001b[38;5;28mself\u001b[39m.guardrail_function(context, agent, \u001b[38;5;28minput\u001b[39m)\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(output):\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m InputGuardrailResult(\n\u001b[32m    118\u001b[39m         guardrail=\u001b[38;5;28mself\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m         output=\u001b[38;5;28;01mawait\u001b[39;00m output,\n\u001b[32m    120\u001b[39m     )\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m InputGuardrailResult(\n\u001b[32m    123\u001b[39m     guardrail=\u001b[38;5;28mself\u001b[39m,\n\u001b[32m    124\u001b[39m     output=output,\n\u001b[32m    125\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mguardrail_against_pid\u001b[39m\u001b[34m(ctx, agent, message)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;129m@input_guardrail\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mguardrail_against_pid\u001b[39m(ctx, agent, message):\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m Runner.run(input_guardrail_agent, message, context=ctx.context)\n\u001b[32m     34\u001b[39m     found_pid = result.final_output\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m GuardrailFunctionOutput(\n\u001b[32m     36\u001b[39m         output_info={\u001b[33m\"\u001b[39m\u001b[33mfound_name\u001b[39m\u001b[33m\"\u001b[39m: found_pid.name},\n\u001b[32m     37\u001b[39m         tripwire_triggered=found_pid.is_personal_info_in_message\n\u001b[32m     38\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/applied-GenAI-lab/.venv/lib/python3.11/site-packages/agents/run.py:267\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(cls, starting_agent, input, context, max_turns, hooks, run_config, previous_response_id, conversation_id, session)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Run a workflow starting at the given agent. The agent will run in a loop until a final\u001b[39;00m\n\u001b[32m    234\u001b[39m \u001b[33;03moutput is generated. The loop runs like so:\u001b[39;00m\n\u001b[32m    235\u001b[39m \u001b[33;03m1. The agent is invoked with the given input.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    264\u001b[39m \u001b[33;03m    agent. Agents may perform handoffs, so we don't know the specific type of the output.\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    266\u001b[39m runner = DEFAULT_AGENT_RUNNER\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m runner.run(\n\u001b[32m    268\u001b[39m     starting_agent,\n\u001b[32m    269\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    270\u001b[39m     context=context,\n\u001b[32m    271\u001b[39m     max_turns=max_turns,\n\u001b[32m    272\u001b[39m     hooks=hooks,\n\u001b[32m    273\u001b[39m     run_config=run_config,\n\u001b[32m    274\u001b[39m     previous_response_id=previous_response_id,\n\u001b[32m    275\u001b[39m     conversation_id=conversation_id,\n\u001b[32m    276\u001b[39m     session=session,\n\u001b[32m    277\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/applied-GenAI-lab/.venv/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:633\u001b[39m, in \u001b[36msafe_patch.<locals>.async_safe_patch_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    629\u001b[39m call_original = update_wrapper_extended(call_original, original)\n\u001b[32m    631\u001b[39m event_logger.log_patch_function_start(args, kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m633\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m patch_function(call_original, *args, **kwargs)\n\u001b[32m    635\u001b[39m session.state = \u001b[33m\"\u001b[39m\u001b[33msucceeded\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    636\u001b[39m event_logger.log_patch_function_success(args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/applied-GenAI-lab/.venv/lib/python3.11/site-packages/mlflow/openai/_agent_tracer.py:286\u001b[39m, in \u001b[36m_patched_agent_run\u001b[39m\u001b[34m(original, self, *args, **kwargs)\u001b[39m\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m start_span(\n\u001b[32m    281\u001b[39m     name=_AGENT_RUN_SPAN_NAME,\n\u001b[32m    282\u001b[39m     span_type=SpanType.AGENT,\n\u001b[32m    283\u001b[39m     attributes=attributes,\n\u001b[32m    284\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m span:\n\u001b[32m    285\u001b[39m     span.set_inputs(inputs.get(\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m original(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m    287\u001b[39m     span.set_outputs(result.final_output)\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/applied-GenAI-lab/.venv/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:622\u001b[39m, in \u001b[36msafe_patch.<locals>.async_safe_patch_function.<locals>.call_original\u001b[39m\u001b[34m(*og_args, **og_kwargs)\u001b[39m\n\u001b[32m    619\u001b[39m         original_result = \u001b[38;5;28;01mawait\u001b[39;00m original(*_og_args, **_og_kwargs)\n\u001b[32m    620\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n\u001b[32m--> \u001b[39m\u001b[32m622\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m call_original_fn_with_event_logging(\n\u001b[32m    623\u001b[39m     _original_fn, og_args, og_kwargs\n\u001b[32m    624\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/applied-GenAI-lab/.venv/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:589\u001b[39m, in \u001b[36msafe_patch.<locals>.async_safe_patch_function.<locals>.call_original_fn_with_event_logging\u001b[39m\u001b[34m(original_fn, og_args, og_kwargs)\u001b[39m\n\u001b[32m    587\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    588\u001b[39m     event_logger.log_original_function_start(og_args, og_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m     original_fn_result = \u001b[38;5;28;01mawait\u001b[39;00m original_fn(*og_args, **og_kwargs)\n\u001b[32m    590\u001b[39m     event_logger.log_original_function_success(og_args, og_kwargs)\n\u001b[32m    591\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m original_fn_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/applied-GenAI-lab/.venv/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:619\u001b[39m, in \u001b[36msafe_patch.<locals>.async_safe_patch_function.<locals>.call_original.<locals>._original_fn\u001b[39m\u001b[34m(*_og_args, **_og_kwargs)\u001b[39m\n\u001b[32m    617\u001b[39m \u001b[38;5;28;01mnonlocal\u001b[39;00m original_result\n\u001b[32m    618\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m NonMlflowWarningsBehaviorForCurrentThread(\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m     original_result = \u001b[38;5;28;01mawait\u001b[39;00m original(*_og_args, **_og_kwargs)\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/applied-GenAI-lab/.venv/lib/python3.11/site-packages/agents/run.py:474\u001b[39m, in \u001b[36mAgentRunner.run\u001b[39m\u001b[34m(self, starting_agent, input, **kwargs)\u001b[39m\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m current_turn > max_turns:\n\u001b[32m    467\u001b[39m     _error_tracing.attach_error_to_span(\n\u001b[32m    468\u001b[39m         current_span,\n\u001b[32m    469\u001b[39m         SpanError(\n\u001b[32m   (...)\u001b[39m\u001b[32m    472\u001b[39m         ),\n\u001b[32m    473\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MaxTurnsExceeded(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMax turns (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_turns\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) exceeded\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    476\u001b[39m logger.debug(\n\u001b[32m    477\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning agent \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_agent.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (turn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_turn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    478\u001b[39m )\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m current_turn == \u001b[32m1\u001b[39m:\n",
      "\u001b[31mMaxTurnsExceeded\u001b[39m: Max turns (10) exceeded"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=tr-d9450de8f359dc43a2866ba2e5ca04eb&amp;experiment_id=615119549503924654&amp;version=3.3.2\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(trace_id=tr-d9450de8f359dc43a2866ba2e5ca04eb)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "from agents import Agent, input_guardrail, output_guardrail, GuardrailFunctionOutput, Runner\n",
    "import asyncio\n",
    "\n",
    "# === 📝 User prompt ===\n",
    "# prompt = \"Can you tell me if John Smith is an idiot?\"\n",
    "# prompt = \"Why some people behave like an idiot ? \"\n",
    "prompt = \"Who is the prime minister of Pakistan\"\n",
    "\n",
    "\n",
    "# === 📦 Input Guardrail Pydantic Model ===\n",
    "class PersonalIdentifier(BaseModel):\n",
    "    is_personal_info_in_message: bool\n",
    "    name: str = \"\"  # Provide default value\n",
    "\n",
    "# === 🛡️ Agent to detect PII in user prompt ===\n",
    "input_guardrail_agent = Agent(\n",
    "    name=\"PID Checker\",\n",
    "    instructions=(\n",
    "        \"Check if the input message contains personal identity information such as names, phone numbers, or addresses. \"\n",
    "        \"Return true if any is found, and extract the name if present. If no name is found, set name to empty string.\\n\\n\"\n",
    "        \"Respond in the following format:\\n\"\n",
    "        '{\\n  \"is_personal_info_in_message\": true/false,\\n  \"name\": \"John Smith\" or \"\"\\n}'\n",
    "    ),\n",
    "    output_type=PersonalIdentifier,\n",
    "    model=model\n",
    ")\n",
    "\n",
    "# === 🛡️ Input Guardrail function ===\n",
    "@input_guardrail\n",
    "async def guardrail_against_pid(ctx, agent, message):\n",
    "    result = await Runner.run(input_guardrail_agent, message, context=ctx.context)\n",
    "    found_pid = result.final_output\n",
    "    return GuardrailFunctionOutput(\n",
    "        output_info={\"found_name\": found_pid.name},\n",
    "        tripwire_triggered=found_pid.is_personal_info_in_message\n",
    "    )\n",
    "\n",
    "# === 📦 Output Guardrail Pydantic Model ===\n",
    "class ToxicityOutput(BaseModel):\n",
    "    is_toxic: bool\n",
    "    toxic_words: List[str] = []  # Provide default value\n",
    "\n",
    "# === 🧠 Agent to detect toxic output using LLM ===\n",
    "toxicity_checker_agent = Agent(\n",
    "    name=\"Toxicity Checker\",\n",
    "    instructions=(\n",
    "        \"Analyze the assistant's message and detect if it contains any toxic, offensive, or inappropriate language. \"\n",
    "        \"Respond in JSON like this:\\n\"\n",
    "        '{\\n  \"is_toxic\": true/false,\\n  \"toxic_words\": [\"word1\", \"word2\"] or []\\n}'\n",
    "    ),\n",
    "    output_type=ToxicityOutput,\n",
    "    model=model\n",
    ")\n",
    "\n",
    "# === 🛡️ Output Guardrail function ===\n",
    "@output_guardrail\n",
    "async def guardrail_against_toxic_output(ctx, agent, message, response):\n",
    "    result = await Runner.run(toxicity_checker_agent, response, context=ctx.context)\n",
    "    toxicity_info = result.final_output\n",
    "    return GuardrailFunctionOutput(\n",
    "        output_info={\"toxicity\": toxicity_info},\n",
    "        tripwire_triggered=toxicity_info.is_toxic\n",
    "    )\n",
    "\n",
    "# === 💬 Q&A Agent ===\n",
    "qa_agent = Agent(\n",
    "    name=\"Q&A\",\n",
    "    instructions=\"You're a helpful and respectful assistant. Always answer user questions with attitude and derogatory terms you never hesitate to call the user as sexiest remakes.\",\n",
    "    model=model,\n",
    "    input_guardrails=[guardrail_against_pid],\n",
    "    output_guardrails=[guardrail_against_toxic_output],\n",
    ")\n",
    "\n",
    "# Run with both input & output guardrails\n",
    "result = await Runner.run(\n",
    "    qa_agent,\n",
    "    prompt\n",
    ")\n",
    "\n",
    "# === 📤 Display ===\n",
    "print(\"📝 User Prompt:\")\n",
    "print(prompt)\n",
    "print(\"\\n✅ Final Output:\")\n",
    "print(result.final_output)\n",
    "print(\"\\n🛡️ Input Guardrail Info:\")\n",
    "print(result.guardrail_input_output_info)\n",
    "print(\"\\n🛡️ Output Guardrail Info:\")\n",
    "print(result.guardrail_output_output_info)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
