{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "165c8f65-ba02-4f05-9c6f-9150150f2943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b39024f1-6bf9-4d29-b6c7-96760c70d557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHAT YOU SEND vs WHAT MODEL SEES\n",
      "============================================================\n",
      "1. WHAT YOU SEND:\n",
      "------------------------------\n",
      "Messages: [\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"What's the weather in Paris?\"\n",
      "  }\n",
      "]\n",
      "Tools: [\n",
      "  {\n",
      "    \"type\": \"function\",\n",
      "    \"function\": {\n",
      "      \"name\": \"get_weather\",\n",
      "      \"description\": \"Get weather for a city\",\n",
      "      \"parameters\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "          \"city\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"City name\"\n",
      "          }\n",
      "        },\n",
      "        \"required\": [\n",
      "          \"city\"\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "]\n",
      "\n",
      "2. WHAT MODEL ACTUALLY SEES:\n",
      "------------------------------\n",
      "Role: system\n",
      "Content: You are a helpful assistant with access to functions. Use them when appropriate.\n",
      "\n",
      "# Available Functions\n",
      "\n",
      "## get_weather\n",
      "**Description:** Get weather for a city\n",
      "**Parameters:**\n",
      "- city (string, required...\n",
      "\n",
      "Role: user\n",
      "Content: What's the weather in Paris?...\n",
      "\n",
      "\n",
      "============================================================\n",
      "SPECIAL TOKEN INJECTION\n",
      "============================================================\n",
      "THEORY: OpenAI uses special tokens like:\n",
      "----------------------------------------\n",
      "  <|function_start|>\n",
      "  <|function_name|>get_weather<|/function_name|>\n",
      "  <|function_description|>Get weather for a city<|/function_description|>\n",
      "  <|function_parameters|>\n",
      "  <|param_name|>city<|/param_name|>\n",
      "  <|param_type|>string<|/param_type|>\n",
      "  <|param_required|>true<|/param_required|>\n",
      "  <|/function_parameters|>\n",
      "  <|function_end|>\n",
      "\n",
      "These tokens:\n",
      "- Don't count toward your token limit\n",
      "- Are invisible in the API\n",
      "- Help the model understand function structure\n",
      "- Enable precise function calling behavior\n",
      "\n",
      "============================================================\n",
      "TOOL INJECTION DEMONSTRATION\n",
      "============================================================\n",
      "BEFORE INJECTION:\n",
      "--------------------\n",
      "Messages: 1\n",
      "  1. user: What's the weather in Tokyo and calculate 15 + 25?...\n",
      "\n",
      "AFTER INJECTION:\n",
      "--------------------\n",
      "Messages: 2\n",
      "  1. system: You are a helpful assistant with access to functions. Use them when appropriate.  # Available Functi...\n",
      "  2. user: What's the weather in Tokyo and calculate 15 + 25?...\n",
      "\n",
      "FULL INJECTED SYSTEM MESSAGE:\n",
      "------------------------------\n",
      "You are a helpful assistant with access to functions. Use them when appropriate.\n",
      "\n",
      "# Available Functions\n",
      "\n",
      "## get_weather\n",
      "**Description:** Get current weather for a city\n",
      "**Parameters:**\n",
      "- city (string, required): City name\n",
      "- units (string): \n",
      "  Options: ['celsius', 'fahrenheit']\n",
      "\n",
      "## calculate\n",
      "**Description:** Perform mathematical calculations\n",
      "**Parameters:**\n",
      "- expression (string, required): Math expression to evaluate\n",
      "\n",
      "\n",
      "# Function Calling Format\n",
      "When you need to call a function, respond with JSON in this exact format:\n",
      "{\"tool_calls\": [{\"id\": \"call_1\", \"type\": \"function\", \"function\": {\"name\": \"function_name\", \"arguments\": \"{\"param\": \"value\"}\"}}]}\n",
      "\n",
      "Important:\n",
      "- Generate unique call IDs (call_1, call_2, etc.)\n",
      "- Arguments must be a JSON string, not an object\n",
      "- You can call multiple functions in one response\n",
      "- Only call functions when the user's request requires it\n",
      "\n",
      "============================================================\n",
      "TOKEN COUNT IMPACT\n",
      "============================================================\n",
      "system message: 153 tokens\n",
      "user message: 7 tokens\n",
      "\n",
      "Original: 7 tokens\n",
      "With tools: 160 tokens\n",
      "Overhead: 153 tokens (2185.7% increase)\n",
      "\n",
      "============================================================\n",
      "THE COMPLETE PICTURE\n",
      "============================================================\n",
      "\n",
      "HOW OPENAI INJECTS TOOLS:\n",
      "\n",
      "1. YOU SEND:\n",
      "   ├── messages: [{\"role\": \"user\", \"content\": \"...\"}]\n",
      "   └── tools: [{\"type\": \"function\", \"function\": {...}}]\n",
      "\n",
      "2. OPENAI PROCESSES:\n",
      "   ├── Parses tool JSON schemas\n",
      "   ├── Converts to natural language descriptions  \n",
      "   ├── Adds function calling instructions\n",
      "   ├── Injects into system message\n",
      "   └── May add special tokens (invisible to you)\n",
      "\n",
      "3. MODEL SEES:\n",
      "   ├── System message with tool descriptions\n",
      "   ├── Instructions on how to call functions\n",
      "   ├── Your original user message\n",
      "   └── Possibly special tokens for structure\n",
      "\n",
      "4. MODEL RESPONDS:\n",
      "   ├── Understands available functions\n",
      "   ├── Decides when to call them\n",
      "   ├── Generates structured JSON responses\n",
      "   └── Follows the injected format instructions\n",
      "\n",
      "5. OPENAI PARSES:\n",
      "   ├── Extracts function calls from response\n",
      "   ├── Converts to tool_calls format\n",
      "   └── Returns to you\n",
      "\n",
      "KEY INSIGHT: Your tools become part of the model's context\n",
      "through sophisticated prompt engineering and possibly special tokens.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 1. WHAT YOU SEND vs WHAT THE MODEL SEES\n",
    "# ============================================================================\n",
    "\n",
    "def show_what_you_send_vs_what_model_sees():\n",
    "    \"\"\"Show the difference between your request and what the model actually sees\"\"\"\n",
    "    \n",
    "    print(\"WHAT YOU SEND vs WHAT MODEL SEES\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # What you send\n",
    "    your_request = {\n",
    "        \"model\": \"gpt-4\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"What's the weather in Paris?\"}\n",
    "        ],\n",
    "        \"tools\": [\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"get_weather\",\n",
    "                    \"description\": \"Get weather for a city\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"city\": {\"type\": \"string\", \"description\": \"City name\"}\n",
    "                        },\n",
    "                        \"required\": [\"city\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    print(\"1. WHAT YOU SEND:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Messages:\", json.dumps(your_request[\"messages\"], indent=2))\n",
    "    print(\"Tools:\", json.dumps(your_request[\"tools\"], indent=2))\n",
    "    \n",
    "    # What the model actually sees (OpenAI's internal transformation)\n",
    "    actual_model_context = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"You are a helpful assistant with access to functions. Use them when appropriate.\n",
    "\n",
    "# Available Functions\n",
    "\n",
    "## get_weather\n",
    "**Description:** Get weather for a city\n",
    "**Parameters:**\n",
    "- city (string, required): City name\n",
    "\n",
    "When you need to call a function, respond with:\n",
    "<function_calls>\n",
    "<invoke name=\"get_weather\">\n",
    "<parameter name=\"city\">value</parameter>\n",
    "</invoke>\n",
    "</function_calls>\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"What's the weather in Paris?\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n2. WHAT MODEL ACTUALLY SEES:\")\n",
    "    print(\"-\" * 30)\n",
    "    for msg in actual_model_context:\n",
    "        print(f\"Role: {msg['role']}\")\n",
    "        print(f\"Content: {msg['content'][:200]}...\")\n",
    "        print()\n",
    "\n",
    "# ============================================================================\n",
    "# 2. OPENAI'S INTERNAL TOOL INJECTION PROCESS\n",
    "# ============================================================================\n",
    "\n",
    "def inject_tools_into_system_prompt(messages: List[Dict], tools: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"Simulate OpenAI's internal tool injection process\"\"\"\n",
    "    \n",
    "    if not tools:\n",
    "        return messages\n",
    "    \n",
    "    # Generate tool descriptions\n",
    "    tool_descriptions = []\n",
    "    for tool in tools:\n",
    "        if tool[\"type\"] == \"function\":\n",
    "            func = tool[\"function\"]\n",
    "            \n",
    "            desc = f\"## {func['name']}\\n\"\n",
    "            desc += f\"**Description:** {func['description']}\\n\"\n",
    "            \n",
    "            if \"parameters\" in func and \"properties\" in func[\"parameters\"]:\n",
    "                desc += \"**Parameters:**\\n\"\n",
    "                props = func[\"parameters\"][\"properties\"]\n",
    "                required = func[\"parameters\"].get(\"required\", [])\n",
    "                \n",
    "                for param_name, param_info in props.items():\n",
    "                    param_type = param_info.get(\"type\", \"string\")\n",
    "                    param_desc = param_info.get(\"description\", \"\")\n",
    "                    req_text = \", required\" if param_name in required else \"\"\n",
    "                    desc += f\"- {param_name} ({param_type}{req_text}): {param_desc}\\n\"\n",
    "                    \n",
    "                    if \"enum\" in param_info:\n",
    "                        desc += f\"  Options: {param_info['enum']}\\n\"\n",
    "            \n",
    "            tool_descriptions.append(desc)\n",
    "    \n",
    "    # Create system message with tools\n",
    "    system_content = \"\"\"You are a helpful assistant with access to functions. Use them when appropriate.\n",
    "\n",
    "# Available Functions\n",
    "\n",
    "\"\"\" + \"\\n\".join(tool_descriptions) + \"\"\"\n",
    "\n",
    "# Function Calling Format\n",
    "When you need to call a function, respond with JSON in this exact format:\n",
    "{\"tool_calls\": [{\"id\": \"call_1\", \"type\": \"function\", \"function\": {\"name\": \"function_name\", \"arguments\": \"{\\\"param\\\": \\\"value\\\"}\"}}]}\n",
    "\n",
    "Important:\n",
    "- Generate unique call IDs (call_1, call_2, etc.)\n",
    "- Arguments must be a JSON string, not an object\n",
    "- You can call multiple functions in one response\n",
    "- Only call functions when the user's request requires it\"\"\"\n",
    "    \n",
    "    # Inject into messages\n",
    "    modified_messages = []\n",
    "    \n",
    "    # Check if there's already a system message\n",
    "    has_system = messages and messages[0][\"role\"] == \"system\"\n",
    "    \n",
    "    if has_system:\n",
    "        # Prepend to existing system message\n",
    "        existing_content = messages[0][\"content\"]\n",
    "        modified_messages.append({\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_content + \"\\n\\n\" + existing_content\n",
    "        })\n",
    "        modified_messages.extend(messages[1:])\n",
    "    else:\n",
    "        # Add new system message\n",
    "        modified_messages.append({\"role\": \"system\", \"content\": system_content})\n",
    "        modified_messages.extend(messages)\n",
    "    \n",
    "    return modified_messages\n",
    "\n",
    "# ============================================================================\n",
    "# 3. SPECIAL TOKENS AND FORMATTING\n",
    "# ============================================================================\n",
    "\n",
    "def show_special_token_injection():\n",
    "    \"\"\"Show how OpenAI might use special tokens for function calling\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SPECIAL TOKEN INJECTION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # OpenAI likely uses special tokens that aren't visible in the API\n",
    "    print(\"THEORY: OpenAI uses special tokens like:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    special_tokens = [\n",
    "        \"<|function_start|>\",\n",
    "        \"<|function_name|>get_weather<|/function_name|>\", \n",
    "        \"<|function_description|>Get weather for a city<|/function_description|>\",\n",
    "        \"<|function_parameters|>\",\n",
    "        \"<|param_name|>city<|/param_name|>\",\n",
    "        \"<|param_type|>string<|/param_type|>\",\n",
    "        \"<|param_required|>true<|/param_required|>\",\n",
    "        \"<|/function_parameters|>\",\n",
    "        \"<|function_end|>\"\n",
    "    ]\n",
    "    \n",
    "    for token in special_tokens:\n",
    "        print(f\"  {token}\")\n",
    "    \n",
    "    print(\"\\nThese tokens:\")\n",
    "    print(\"- Don't count toward your token limit\")\n",
    "    print(\"- Are invisible in the API\")\n",
    "    print(\"- Help the model understand function structure\")\n",
    "    print(\"- Enable precise function calling behavior\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. DEMONSTRATE THE INJECTION\n",
    "# ============================================================================\n",
    "\n",
    "def demonstrate_tool_injection():\n",
    "    \"\"\"Demonstrate the complete tool injection process\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TOOL INJECTION DEMONSTRATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Original messages (what you send)\n",
    "    original_messages = [\n",
    "        {\"role\": \"user\", \"content\": \"What's the weather in Tokyo and calculate 15 + 25?\"}\n",
    "    ]\n",
    "    \n",
    "    # Tools (what you send)\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_weather\",\n",
    "                \"description\": \"Get current weather for a city\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"city\": {\"type\": \"string\", \"description\": \"City name\"},\n",
    "                        \"units\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"], \"default\": \"fahrenheit\"}\n",
    "                    },\n",
    "                    \"required\": [\"city\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"function\", \n",
    "            \"function\": {\n",
    "                \"name\": \"calculate\",\n",
    "                \"description\": \"Perform mathematical calculations\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"expression\": {\"type\": \"string\", \"description\": \"Math expression to evaluate\"}\n",
    "                    },\n",
    "                    \"required\": [\"expression\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"BEFORE INJECTION:\")\n",
    "    print(\"-\" * 20)\n",
    "    print(f\"Messages: {len(original_messages)}\")\n",
    "    for i, msg in enumerate(original_messages):\n",
    "        print(f\"  {i+1}. {msg['role']}: {msg['content'][:50]}...\")\n",
    "    \n",
    "    # Apply injection\n",
    "    injected_messages = inject_tools_into_system_prompt(original_messages, tools)\n",
    "    \n",
    "    print(f\"\\nAFTER INJECTION:\")\n",
    "    print(\"-\" * 20)\n",
    "    print(f\"Messages: {len(injected_messages)}\")\n",
    "    for i, msg in enumerate(injected_messages):\n",
    "        content_preview = msg['content'][:100].replace('\\n', ' ')\n",
    "        print(f\"  {i+1}. {msg['role']}: {content_preview}...\")\n",
    "    \n",
    "    print(f\"\\nFULL INJECTED SYSTEM MESSAGE:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(injected_messages[0]['content'])\n",
    "\n",
    "# ============================================================================\n",
    "# 5. TOKEN COUNT IMPACT\n",
    "# ============================================================================\n",
    "\n",
    "def show_token_impact():\n",
    "    \"\"\"Show how tool injection affects token count\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TOKEN COUNT IMPACT\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        import tiktoken\n",
    "        encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "        \n",
    "        # Original message\n",
    "        original = \"What's the weather in Tokyo?\"\n",
    "        original_tokens = len(encoding.encode(original))\n",
    "        \n",
    "        # With tools injected\n",
    "        tools = [{\"type\": \"function\", \"function\": {\"name\": \"get_weather\", \"description\": \"Get weather\", \"parameters\": {\"type\": \"object\", \"properties\": {\"city\": {\"type\": \"string\"}}, \"required\": [\"city\"]}}}]\n",
    "        injected = inject_tools_into_system_prompt([{\"role\": \"user\", \"content\": original}], tools)\n",
    "        \n",
    "        total_tokens = 0\n",
    "        for msg in injected:\n",
    "            tokens = len(encoding.encode(msg['content']))\n",
    "            total_tokens += tokens\n",
    "            print(f\"{msg['role']} message: {tokens} tokens\")\n",
    "        \n",
    "        print(f\"\\nOriginal: {original_tokens} tokens\")\n",
    "        print(f\"With tools: {total_tokens} tokens\")\n",
    "        print(f\"Overhead: {total_tokens - original_tokens} tokens ({((total_tokens - original_tokens) / original_tokens * 100):.1f}% increase)\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"Install tiktoken to see token counts: pip install tiktoken\")\n",
    "\n",
    "# ============================================================================\n",
    "# 6. THE COMPLETE PICTURE\n",
    "# ============================================================================\n",
    "\n",
    "def show_complete_picture():\n",
    "    \"\"\"Show the complete picture of how tool injection works\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"THE COMPLETE PICTURE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\"\"\n",
    "HOW OPENAI INJECTS TOOLS:\n",
    "\n",
    "1. YOU SEND:\n",
    "   ├── messages: [{\"role\": \"user\", \"content\": \"...\"}]\n",
    "   └── tools: [{\"type\": \"function\", \"function\": {...}}]\n",
    "\n",
    "2. OPENAI PROCESSES:\n",
    "   ├── Parses tool JSON schemas\n",
    "   ├── Converts to natural language descriptions  \n",
    "   ├── Adds function calling instructions\n",
    "   ├── Injects into system message\n",
    "   └── May add special tokens (invisible to you)\n",
    "\n",
    "3. MODEL SEES:\n",
    "   ├── System message with tool descriptions\n",
    "   ├── Instructions on how to call functions\n",
    "   ├── Your original user message\n",
    "   └── Possibly special tokens for structure\n",
    "\n",
    "4. MODEL RESPONDS:\n",
    "   ├── Understands available functions\n",
    "   ├── Decides when to call them\n",
    "   ├── Generates structured JSON responses\n",
    "   └── Follows the injected format instructions\n",
    "\n",
    "5. OPENAI PARSES:\n",
    "   ├── Extracts function calls from response\n",
    "   ├── Converts to tool_calls format\n",
    "   └── Returns to you\n",
    "\n",
    "KEY INSIGHT: Your tools become part of the model's context\n",
    "through sophisticated prompt engineering and possibly special tokens.\n",
    "    \"\"\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Show the comparison\n",
    "    show_what_you_send_vs_what_model_sees()\n",
    "    \n",
    "    # Show special tokens theory\n",
    "    show_special_token_injection()\n",
    "    \n",
    "    # Demonstrate injection\n",
    "    demonstrate_tool_injection()\n",
    "    \n",
    "    # Show token impact\n",
    "    show_token_impact()\n",
    "    \n",
    "    # Show complete picture\n",
    "    show_complete_picture()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bae647f-8253-4e22-bf29-7a9465c0198e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
